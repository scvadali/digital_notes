* * * * * * * *                                                                             

<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head><title>Digital Notes for Prelims FA2025</title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='digital_notes.css' rel='stylesheet' type='text/css' /> 
<meta content='digital_notes.tex' name='src' /> 
<script>window.MathJax = { tex: { tags: "ams", }, }; </script> 
 <script async='async' id='MathJax-script' src='https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js' type='text/javascript'></script>  
</head><body>
   <div class='maketitle'>
                                                                                               
                                                                                               
                                                                                               
                                                                                               

<h2 class='titleHead'>Digital Notes for Prelims FA2025</h2>
<div class='author'><span class='cmr-12'>Chandrahaas Vadali</span></div>
<br />
<div class='date'><span class='cmr-12'>December 29, 2025</span></div>
   </div>
   <h3 class='likesectionHead' id='contents'><a id='x1-1000'></a>Contents</h3>
   <div class='tableofcontents'>
   <span class='sectionToc'>1 <a href='#basic-concepts' id='QQ2-1-2'>Basic Concepts</a></span>
<br />   <span class='subsectionToc'>1.1 <a href='#cost' id='QQ2-1-3'>Cost</a></span>
<br />   <span class='subsectionToc'>1.2 <a href='#robustness' id='QQ2-1-4'>Robustness</a></span>
<br />   <span class='subsectionToc'>1.3 <a href='#fanin-and-fanout' id='QQ2-1-8'>Fan-In and Fan-Out</a></span>
<br />   <span class='subsectionToc'>1.4 <a href='#delay' id='QQ2-1-10'>Delay</a></span>
<br />   <span class='subsectionToc'>1.5 <a href='#mosfet' id='QQ2-1-12'>MOSFET</a></span>
<br />   <span class='subsubsectionToc'>1.5.1 <a href='#mosfet-in-triode' id='QQ2-1-13'>MOSFET in triode</a></span>
<br />   <span class='subsubsectionToc'>1.5.2 <a href='#mosfet-in-saturation' id='QQ2-1-14'>MOSFET in saturation</a></span>
<br />   <span class='subsubsectionToc'>1.5.3 <a href='#subthreshold-conduction' id='QQ2-1-15'>Subthreshold conduction</a></span>
<br />   <span class='subsubsectionToc'>1.5.4 <a href='#gate-leakage' id='QQ2-1-17'>Gate Leakage</a></span>
<br />   <span class='subsubsectionToc'>1.5.5 <a href='#junction-leakage' id='QQ2-1-18'>Junction leakage</a></span>
<br />   <span class='subsubsectionToc'>1.5.6 <a href='#temperature-dependence' id='QQ2-1-19'>Temperature dependence</a></span>
<br />   <span class='subsubsectionToc'>1.5.7 <a href='#channel-capacitances' id='QQ2-1-22'>Channel capacitances</a></span>
<br />   <span class='subsubsectionToc'>1.5.8 <a href='#junction-capacitances' id='QQ2-1-24'>Junction capacitances</a></span>
<br />   <span class='subsubsectionToc'>1.5.9 <a href='#vt-variations' id='QQ2-1-25'>\(V_T\) variations</a></span>
<br />   <span class='subsubsectionToc'>1.5.10 <a href='#mobility-degradation-and-velocity-saturation' id='QQ2-1-27'>Mobility degradation and Velocity Saturation</a></span>
<br />   <span class='subsectionToc'>1.6 <a href='#cmos-latchup' id='QQ2-1-29'>CMOS Latchup</a></span>
<br />   <span class='subsectionToc'>1.7 <a href='#scaling' id='QQ2-1-31'>Scaling</a></span>
<br />   <span class='subsectionToc'>1.8 <a href='#inverter-vtc' id='QQ2-1-33'>Inverter VTC</a></span>
<br />   <span class='subsectionToc'>1.9 <a href='#pass-xtor-characteristics' id='QQ2-1-35'>Pass xtor characteristics</a></span>
<br />   <span class='sectionToc'>2 <a href='#logical-effort' id='QQ2-1-37'>Logical Effort</a></span>
<br />   <span class='subsectionToc'>2.1 <a href='#inverter-delay' id='QQ2-1-38'>Inverter Delay</a></span>
<br />   <span class='subsectionToc'>2.2 <a href='#inverter-chain-optimization' id='QQ2-1-41'>Inverter Chain Optimization</a></span>
                                                                                               
                                                                                               
<br />   <span class='subsectionToc'>2.3 <a href='#generalizing-inverter-delay' id='QQ2-1-44'>Generalizing Inverter Delay</a></span>
<br />   <span class='subsectionToc'>2.4 <a href='#gate-sizing-example' id='QQ2-1-47'>Gate Sizing Example</a></span>
<br />   <span class='subsectionToc'>2.5 <a href='#path-efforts' id='QQ2-1-49'>Path efforts</a></span>
<br />   <span class='subsectionToc'>2.6 <a href='#logical-effort-of-a-transmission-gate' id='QQ2-1-50'>Logical Effort of a Transmission gate</a></span>
<br />   <span class='subsectionToc'>2.7 <a href='#logical-effort-less-than-' id='QQ2-1-55'>Logical Effort less than 1</a></span>
<br />   <span class='subsectionToc'>2.8 <a href='#velocity-saturated-devices' id='QQ2-1-57'>Velocity saturated devices</a></span>
<br />   <span class='subsectionToc'>2.9 <a href='#limitations-of-logical-effort' id='QQ2-1-59'>Limitations of Logical Effort</a></span>
<br />   <span class='subsectionToc'>2.10 <a href='#fixed-side-loads' id='QQ2-1-61'>Fixed side loads</a></span>
<br />   <span class='subsectionToc'>2.11 <a href='#reconvergent-fanout-example' id='QQ2-1-62'>Reconvergent fanout example</a></span>
<br />   <span class='subsectionToc'>2.12 <a href='#important-lessons-from-this-section' id='QQ2-1-64'>Important lessons from this section</a></span>
<br />   <span class='sectionToc'>3 <a href='#timing' id='QQ2-1-65'>Timing</a></span>
<br />   <span class='subsectionToc'>3.1 <a href='#types-of-systems' id='QQ2-1-66'>Types of systems</a></span>
<br />   <span class='subsectionToc'>3.2 <a href='#timing-metrics' id='QQ2-1-69'>Timing metrics</a></span>
<br />   <span class='subsectionToc'>3.3 <a href='#clk-nonidealities' id='QQ2-1-74'>Clk non-idealities</a></span>
<br />   <span class='subsectionToc'>3.4 <a href='#race-conditions' id='QQ2-1-77'>Race conditions</a></span>
<br />   <span class='subsectionToc'>3.5 <a href='#latch-timing' id='QQ2-1-79'>Latch timing</a></span>
<br />   <span class='subsectionToc'>3.6 <a href='#slack-passingtime-borrowing' id='QQ2-1-82'>Slack passing/Time borrowing</a></span>
<br />   <span class='subsectionToc'>3.7 <a href='#ckts-in-feedback' id='QQ2-1-85'>Ckts in feedback</a></span>
<br />   <span class='subsectionToc'>3.8 <a href='#selftimed-logic' id='QQ2-1-87'>Self-timed logic</a></span>
<br />   <span class='subsubsectionToc'>3.8.1 <a href='#generating-the-done-signal' id='QQ2-1-89'>Generating the done signal</a></span>
<br />   <span class='subsubsectionToc'>3.8.2 <a href='#selftimed-signaling' id='QQ2-1-93'>Self-timed signaling</a></span>
<br />   <span class='subsubsectionToc'>3.8.3 <a href='#examples-where-selftimed-logic-is-useful' id='QQ2-1-98'>Examples where self-timed logic is useful</a></span>
<br />   <span class='subsectionToc'>3.9 <a href='#synchronizers' id='QQ2-1-99'>Synchronizers</a></span>
<br />   <span class='subsubsectionToc'>3.9.1 <a href='#metastability' id='QQ2-1-100'>Metastability</a></span>
<br />   <span class='subsubsectionToc'>3.9.2 <a href='#a-simple-synchronizer' id='QQ2-1-101'>A simple synchronizer</a></span>
<br />   <span class='subsubsectionToc'>3.9.3 <a href='#gray-codes' id='QQ2-1-103'>Gray codes</a></span>
<br />   <span class='subsubsectionToc'>3.9.4 <a href='#synchronizer-pitfalls' id='QQ2-1-104'>Synchronizer pitfalls</a></span>
<br />   <span class='subsectionToc'>3.10 <a href='#arbiters' id='QQ2-1-105'>Arbiters</a></span>
<br />   <span class='subsectionToc'>3.11 <a href='#retiming' id='QQ2-1-108'>Retiming</a></span>
<br />   <span class='sectionToc'>4 <a href='#phase-locked-loops' id='QQ2-1-111'>Phase Locked Loops</a></span>
<br />   <span class='subsectionToc'>4.1 <a href='#monstable-ckt' id='QQ2-1-112'>Monstable Ckt</a></span>
<br />   <span class='subsectionToc'>4.2 <a href='#astable-ckts-oscillators' id='QQ2-1-114'>Astable ckts - Oscillators</a></span>
<br />   <span class='subsubsectionToc'>4.2.1 <a href='#ring-oscillator' id='QQ2-1-115'>Ring Oscillator</a></span>
<br />   <span class='subsubsectionToc'>4.2.2 <a href='#differential-vco' id='QQ2-1-117'>Differential VCO</a></span>
<br />   <span class='subsectionToc'>4.3 <a href='#basic-concept-of-a-pll' id='QQ2-1-119'>Basic concept of a PLL</a></span>
<br />   <span class='subsubsectionToc'>4.3.1 <a href='#building-blocks-of-a-pll' id='QQ2-1-121'>Building blocks of a PLL</a></span>
<br />   <span class='subsubsectionToc'>4.3.2 <a href='#phase-detector' id='QQ2-1-122'>Phase detector</a></span>
<br />   <span class='subsubsectionToc'>4.3.3 <a href='#charge-pump' id='QQ2-1-125'>Charge pump</a></span>
                                                                                               
                                                                                               
<br />   <span class='subsectionToc'>4.4 <a href='#delay-locked-loops' id='QQ2-1-127'>Delay Locked Loops</a></span>
<br />   <span class='sectionToc'>5 <a href='#latches-and-registers' id='QQ2-1-129'>Latches and Registers</a></span>
<br />   <span class='subsectionToc'>5.1 <a href='#sequencing-methods' id='QQ2-1-130'>Sequencing methods</a></span>
<br />   <span class='subsectionToc'>5.2 <a href='#static-sequencing-elements' id='QQ2-1-132'>Static sequencing elements</a></span>
<br />   <span class='subsectionToc'>5.3 <a href='#sr-latch' id='QQ2-1-134'>SR Latch</a></span>
<br />   <span class='subsectionToc'>5.4 <a href='#muxbased-latches' id='QQ2-1-137'>MUX-based latches</a></span>
<br />   <span class='subsectionToc'>5.5 <a href='#leaderfollower-flipflop' id='QQ2-1-139'>Leader-Follower Flip-flop</a></span>
<br />   <span class='subsectionToc'>5.6 <a href='#clk-overlap' id='QQ2-1-142'>Clk overlap</a></span>
<br />   <span class='subsectionToc'>5.7 <a href='#dynamic-transmission-gatebased-registers' id='QQ2-1-144'>Dynamic Transmission gate-based registers</a></span>
<br />   <span class='subsectionToc'>5.8 <a href='#cmos' id='QQ2-1-146'>C2MOS</a></span>
<br />   <span class='subsectionToc'>5.9 <a href='#dualedge-registers' id='QQ2-1-150'>Dual-edge registers</a></span>
<br />   <span class='subsectionToc'>5.10 <a href='#true-singlephase-clocked-register-tspcr' id='QQ2-1-152'>True Single-Phase Clocked Register (TSPCR)</a></span>
<br />   <span class='subsectionToc'>5.11 <a href='#pulse-registers' id='QQ2-1-155'>Pulse Registers</a></span>
<br />   <span class='subsectionToc'>5.12 <a href='#sense-amplifier-based-registers' id='QQ2-1-160'>Sense Amplifier based Registers</a></span>
<br />   <span class='subsectionToc'>5.13 <a href='#enabling-logic-in-latches-and-registers' id='QQ2-1-163'>Enabling logic in latches and registers</a></span>
<br />   <span class='subsubsectionToc'>5.13.1 <a href='#reset' id='QQ2-1-164'>Reset</a></span>
<br />   <span class='subsubsectionToc'>5.13.2 <a href='#enable' id='QQ2-1-166'>Enable</a></span>
<br />   <span class='subsectionToc'>5.14 <a href='#dual-edgetriggered-flipflops' id='QQ2-1-168'>Dual edge-triggered flip-flops</a></span>
<br />   <span class='subsectionToc'>5.15 <a href='#schmitt-trigger' id='QQ2-1-171'>Schmitt Trigger</a></span>
<br />   <span class='subsectionToc'>5.16 <a href='#pipelining' id='QQ2-1-175'>Pipelining</a></span>
<br />   <span class='subsubsectionToc'>5.16.1 <a href='#noracmos-for-pipelining' id='QQ2-1-176'>NORA-CMOS for pipelining</a></span>
<br />   <span class='sectionToc'>6 <a href='#sram' id='QQ2-1-179'>SRAM</a></span>
<br />   <span class='subsectionToc'>6.1 <a href='#tsram' id='QQ2-1-180'>6T-SRAM</a></span>
<br />   <span class='subsectionToc'>6.2 <a href='#read-operation-and-nominal-device-sizing' id='QQ2-1-182'>READ operation and nominal device sizing</a></span>
<br />   <span class='subsectionToc'>6.3 <a href='#write-operation-and-nominal-device-sizing' id='QQ2-1-183'>WRITE operation and nominal device sizing</a></span>
<br />   <span class='subsectionToc'>6.4 <a href='#switching-threshold-of-an-inverter' id='QQ2-1-185'>Switching threshold of an inverter</a></span>
<br />   <span class='subsectionToc'>6.5 <a href='#stability' id='QQ2-1-188'>Stability</a></span>
<br />   <span class='subsubsectionToc'>6.5.1 <a href='#hold-stability' id='QQ2-1-189'>HOLD stability</a></span>
<br />   <span class='subsubsectionToc'>6.5.2 <a href='#read-stability' id='QQ2-1-191'>READ stability</a></span>
<br />   <span class='subsubsectionToc'>6.5.3 <a href='#write-stability' id='QQ2-1-192'>WRITE stability</a></span>
<br />   <span class='subsectionToc'>6.6 <a href='#read-assists' id='QQ2-1-193'>READ assists</a></span>
<br />   <span class='subsectionToc'>6.7 <a href='#write-assists' id='QQ2-1-194'>WRITE assists</a></span>
<br />   <span class='subsectionToc'>6.8 <a href='#how-do-we-implement-these-assist-ckts' id='QQ2-1-195'>How do we implement these assist ckts?</a></span>
<br />   <span class='subsubsectionToc'>6.8.1 <a href='#negative-rail-generation' id='QQ2-1-196'>Negative rail generation</a></span>
<br />   <span class='subsubsectionToc'>6.8.2 <a href='#higher-than-vdd-rail-generation' id='QQ2-1-198'>Higher than \(V_{DD}\) rail generation</a></span>
<br />   <span class='subsubsectionToc'>6.8.3 <a href='#level-converter' id='QQ2-1-201'>Level Converter</a></span>
<br />   <span class='subsubsectionToc'>6.8.4 <a href='#pulse-width-modulation' id='QQ2-1-204'>Pulse width modulation</a></span>
<br />   <span class='subsectionToc'>6.9 <a href='#pvt-corners' id='QQ2-1-205'>PVT corners</a></span>
                                                                                               
                                                                                               
<br />   <span class='subsectionToc'>6.10 <a href='#row-circuitry' id='QQ2-1-206'>Row circuitry</a></span>
<br />   <span class='subsectionToc'>6.11 <a href='#column-circuitry' id='QQ2-1-210'>Column circuitry</a></span>
<br />   <span class='subsubsectionToc'>6.11.1 <a href='#sense-amplifier' id='QQ2-1-211'>Sense Amplifier</a></span>
<br />   <span class='sectionToc'>7 <a href='#power-energy-and-delay' id='QQ2-1-213'>Power, Energy, and Delay</a></span>
<br />   <span class='subsectionToc'>7.1 <a href='#charging-and-discharging-a-capacitor' id='QQ2-1-214'>Charging and discharging a capacitor</a></span>
<br />   <span class='subsubsectionToc'>7.1.1 <a href='#activity-factor' id='QQ2-1-216'>Activity factor</a></span>
<br />   <span class='subsubsectionToc'>7.1.2 <a href='#example-transistor-sizing-for-minimum-energy' id='QQ2-1-219'>Example - transistor sizing for minimum energy</a></span>
<br />   <span class='subsubsectionToc'>7.1.3 <a href='#clk-gating' id='QQ2-1-222'>Clk gating</a></span>
<br />   <span class='subsubsectionToc'>7.1.4 <a href='#state-retention-registers' id='QQ2-1-224'>State retention registers</a></span>
<br />   <span class='subsectionToc'>7.2 <a href='#short-ckt-power-dissipation' id='QQ2-1-226'>Short ckt power dissipation</a></span>
<br />   <span class='subsectionToc'>7.3 <a href='#static-consumption' id='QQ2-1-227'>Static consumption</a></span>
<br />   <span class='subsectionToc'>7.4 <a href='#energydelay-product' id='QQ2-1-228'>Energy-Delay product</a></span>
<br />   <span class='subsubsectionToc'>7.4.1 <a href='#gate-sizing-under-a-delay-constraint' id='QQ2-1-231'>Gate sizing under a delay constraint</a></span>
<br />   <span class='subsectionToc'>7.5 <a href='#interconnects' id='QQ2-1-232'>Interconnects</a></span>
<br />   <span class='subsubsectionToc'>7.5.1 <a href='#skin-effect' id='QQ2-1-234'>Skin effect</a></span>
<br />   <span class='subsubsectionToc'>7.5.2 <a href='#distributed-rc-line' id='QQ2-1-235'>Distributed RC line</a></span>
<br />   <span class='subsectionToc'>7.6 <a href='#elmore-delay' id='QQ2-1-238'>Elmore Delay</a></span>
<br />   <span class='subsubsectionToc'>7.6.1 <a href='#branched-ckts' id='QQ2-1-240'>Branched ckts</a></span>
<br />   <span class='subsectionToc'>7.7 <a href='#transmission-line' id='QQ2-1-242'>Transmission line</a></span>
<br />   <span class='subsubsectionToc'>7.7.1 <a href='#termination' id='QQ2-1-244'>Termination</a></span>
<br />   <span class='subsubsectionToc'>7.7.2 <a href='#capacitive-termination' id='QQ2-1-246'>Capacitive termination</a></span>
<br />   <span class='subsectionToc'>7.8 <a href='#interconnect-engineering' id='QQ2-1-248'>Interconnect engineering</a></span>
<br />   <span class='subsubsectionToc'>7.8.1 <a href='#wire-rebufferingrepeaters' id='QQ2-1-249'>Wire rebuffering/Repeaters</a></span>
<br />   <span class='subsubsectionToc'>7.8.2 <a href='#regenerators' id='QQ2-1-250'>Regenerators</a></span>
<br />   <span class='subsectionToc'>7.9 <a href='#power-gating' id='QQ2-1-252'>Power gating</a></span>
<br />   <span class='subsectionToc'>7.10 <a href='#dvfs' id='QQ2-1-254'>DVFS</a></span>
<br />   <span class='subsectionToc'>7.11 <a href='#multivt-cells' id='QQ2-1-256'>Multi-Vt cells</a></span>
<br />   <span class='subsectionToc'>7.12 <a href='#pvt-corners1' id='QQ2-1-257'>PVT corners</a></span>
<br />   <span class='sectionToc'>8 <a href='#verilog-basics' id='QQ2-1-258'>Verilog Basics</a></span>
<br />   <span class='subsectionToc'>8.1 <a href='#blocking-vs-nonblocking-assignments' id='QQ2-1-259'>Blocking vs Non-blocking assignments</a></span>
<br />   <span class='subsectionToc'>8.2 <a href='#always-blocks' id='QQ2-1-260'>always blocks</a></span>
<br />   <span class='sectionToc'>9 <a href='#adders-and-multipliers' id='QQ2-1-261'>Adders and Multipliers</a></span>
<br />   <span class='sectionToc'>10 <a href='#dynamic-logic' id='QQ2-1-262'>Dynamic Logic</a></span>
<br />   <span class='subsectionToc'>10.1 <a href='#domino-logic' id='QQ2-1-263'>Domino logic</a></span>
<br />   <span class='subsectionToc'>10.2 <a href='#keeper-circuit' id='QQ2-1-264'>Keeper circuit</a></span>
<br />   <span class='sectionToc'><a href='#references' id='QQ2-1-265'>References</a></span>
   </div>
                                                                                               
                                                                                               
<!-- l. 28 --><p class='indent'>
                                                                                               
                                                                                               
</p>
   <h3 class='sectionHead' id='basic-concepts'><span class='titlemark'>1   </span> <a id='x1-20001'></a>Basic Concepts</h3>
<!-- l. 33 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='cost'><span class='titlemark'>1.1   </span> <a id='x1-30001.1'></a>Cost</h4>
<!-- l. 35 --><p class='noindent'>Cost per IC can be given by
</p><!-- l. 40 --><p class='indent'>   \begin {equation}  \label {eqn:cost_ic} \mathrm {cost \hspace {1 mm} per \hspace {1 mm}IC} = \mathrm {variable\hspace {1 mm} cost \hspace {1 mm}per\hspace {1 mm} IC} + \bigg ( \frac {\mathrm {fixed \hspace {1 mm}cost}}{\mathrm {volume}} \bigg )  \end {equation}<a id='x1-3001r1'></a>
</p><!-- l. 42 --><p class='indent'>   Fixed cost dominates for small-volume products. Variable cost can be given by
</p><!-- l. 47 --><p class='indent'>   \begin {equation}  \label {eqn:variable_cost_ic} \mathrm {variable \hspace {1 mm} cost} = \frac {\mathrm {cost \hspace {1 mm} of \hspace {1 mm} die + cost \hspace {1 mm} of \hspace {1 mm} die \hspace {1 mm} test + cost \hspace {1 mm} of \hspace {1 mm} packaging}}{\mathrm {final \hspace {1 mm} test \hspace {1 mm} yield}}  \end {equation}<a id='x1-3002r2'></a>
</p><!-- l. 49 --><p class='indent'>   The die cost depends on the number of good dies on a wafer and the percentage of those that are functional. The
number of dies is simply the area of the wafer divided by the area of each die.
</p><!-- l. 54 --><p class='indent'>   \begin {equation}  \label {eqn:die_cost_ic} \mathrm {die \hspace {1 mm} cost} = \frac {\mathrm {cost \hspace {1 mm} of \hspace {1 mm} wafer }}{\mathrm {dies \hspace {1 mm} per \hspace {1 mm} wafer \times die \hspace {1 mm} yield}}  \end {equation}<a id='x1-3003r3'></a>
</p><!-- l. 56 --><p class='indent'>   The cost of die increases with die area, roughly to the fourth power [<a id='x1-3004'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. Die yield is given in defects/area (typically \(\mathrm {cm^2}\))
and is modeled as follows
</p><!-- l. 62 --><p class='indent'>   \begin {equation}  \label {eqn:die_yield_ic} \mathrm {die \hspace {1 mm} yield} = \bigg (1 + \frac {\mathrm {defects \hspace {1 mm} per \hspace {1 mm} unit \hspace {1 mm } area } \times \mathrm {die \hspace {1mm} area}}{\alpha } \bigg ) ^ {-\alpha }  \end {equation}<a id='x1-3005r4'></a>
</p><!-- l. 64 --><p class='indent'>   \(\alpha = 3\) is a good estimate for today’s CMOS processes [<a href='#cite.0_rabaey_digital_1996'>11</a>].
</p><!-- l. 66 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='robustness'><span class='titlemark'>1.2   </span> <a id='x1-40001.2'></a>Robustness</h4>
<!-- l. 68 --><p class='noindent'>Most noise in a digital system is internally generated, and the noise value is proportional to the signal swing
[<a href='#cite.0_rabaey_digital_1996'>11</a>].
</p>
   <figure class='figure' id='x1-40011'><span id='noise-sources-in-digital-ckts-rabaeydigital'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 72 --><p class='noindent'><img alt='PIC' height='150' src='images/noise_sources.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 1: </span><span class='content'>Noise sources in digital ckts [<a id='x1-4002'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]</span></figcaption><!-- tex4ht:label?: x1-40011  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 77 --><p class='indent'>   As shown in figure <a href='#noise-sources-in-digital-ckts-rabaeydigital'>1<!-- tex4ht:ref: fig:noise_sources  --></a>, the capacitive and inductive coupling arises from the parasitics within the system while the power
and GND bounce comes externally and doesn’t depend on signal swing.
</p>
   <figure class='figure' id='x1-40032'><span id='left-inverter-vtc-right-defining-vil-and-vih-'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 82 --><p class='noindent'><img alt='PIC' height='150' src='images/inverter_vtc.png' width='150' /><img alt='PIC' height='275' src='images/vih_vil_tw.png' width='275' />
</p>
<figcaption class='caption'><span class='id'>Figure 2: </span><span class='content'>(Left) Inverter VTC (Right) Defining \(V_{IL}\) and \(V_{IH}\) </span></figcaption><!-- tex4ht:label?: x1-40032  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 87 --><p class='indent'>   In figure <a href='#left-inverter-vtc-right-defining-vil-and-vih-'>2<!-- tex4ht:ref: fig:inverter_vtc  --></a>, we see the output of an inverter for a range of input voltages. This is called the voltage transfer
characteristic of the inverter. The switching threshold (\(V_M\)) is the point where the VTC curve intersects the line \(V_{out} = V_{in}\) or midrail.
We define \(V_{OH}\) and \(V_{OL}\) as the nominal voltage values for logic levels 1 and 0. Accounting for noise, we often specify a
<span class='cmti-10'>range </span>of values instead of a single point. We define \(V_{IH}\)/\( V_{IL}\) as the lowest/highest voltage value which can still
represent the logic level 1/0. These points are obtained from the VTC where \(d V_{out} / d V_{in} = -1\) as shown on the right in figure
<a href='#left-inverter-vtc-right-defining-vil-and-vih-'>2<!-- tex4ht:ref: fig:inverter_vtc  --></a>.
</p><!-- l. 93 --><p class='indent'>   A measure of sensitivity of a given logic gate to noise is given by noise margins. We can define
</p><!-- l. 97 --><p class='indent'>   \begin {equation}  NM_L = V_{IL} - V_{OL}  \end {equation}<a id='x1-4004r5'></a>
</p><!-- l. 101 --><p class='indent'>   \begin {equation}  NM_H = V_{OH} - V_{IH}  \end {equation}<a id='x1-4005r6'></a>
</p><!-- l. 103 --><p class='indent'>   These values represent how much noise is tolerated at the input of the gate without flipping the bit. Noise margins
should be greater than 0 when designing the system. The undefined region in figure <a href='#left-inverter-vtc-right-defining-vil-and-vih-'>2<!-- tex4ht:ref: fig:inverter_vtc  --></a> is also called the transtion
region.
</p><!-- l. 106 --><p class='indent'>   An ideal gate, therefore, has an infinite gain in the transition region (\(dV_{out} / dV_{in}\) is infinite), midrail switching threshold,
noise margins equal to half the input swing, infinite input impedance and zero output impedance (infinite
fanout).
</p><!-- l. 110 --><p class='indent'>   Modern processors dynamically change voltage and clk frequency to extract the maximum performance at minimum
energy consumption given the work load. They use a razor flip-flop as shown in figure <a href='#razor-flipflop-for-error-detection-'>3<!-- tex4ht:ref: fig:razor_ff  --></a> to detect if the clk is too
fast or the supply too low. The idea is to sample the data twice and verify if the outputs agree with each
other. If they don’t, we missed a setup or hold time somewhere on the data path. The data path is slower
but a transparent latch in parallel is in a faster route. If the data arrives before the setup time on the data
path, both the latch’s output and the register’s output settle to the same value leaving ERR low. If the data
arrives later, the register will miss the data but the latch has an additional half cycle to capture it - and
therefore, can assert ERR high. The data is then relauched by slowing down the clk or increasing the supply
voltage.
</p>
   <figure class='figure' id='x1-40063'><span id='razor-flipflop-for-error-detection-'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 118 --><p class='noindent'><img alt='PIC' height='150' src='images/razor_ff.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 3: </span><span class='content'>Razor flip-flop for error detection </span></figcaption><!-- tex4ht:label?: x1-40063  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='fanin-and-fanout'><span class='titlemark'>1.3   </span> <a id='x1-50001.3'></a>Fan-In and Fan-Out</h4>
<!-- l. 125 --><p class='noindent'>The fan-out denotes the number of load gates N that are connected to the output of the driving gate. Increasing fan-out can
make the driving gate drive the output slower (dynamic perfomance is impacted). The fan-in of a gate is defined as the
number of inputs to the gate. Gates with large fan-in tend to be more complex, which often results in inferior static and
dynamic properties.
</p>
   <figure class='figure' id='x1-50014'><span id='left-fanout-right-fanin-'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 131 --><p class='noindent'><img alt='PIC' height='150' src='images/fin_fout.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 4: </span><span class='content'>(Left) Fanout (Right) Fan-in </span></figcaption><!-- tex4ht:label?: x1-50014  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='delay'><span class='titlemark'>1.4   </span> <a id='x1-60001.4'></a>Delay</h4>
<!-- l. 138 --><p class='noindent'>Performance in a digital system is expressed in terms of the clk frequency. This is set by a lot of factors, but primarily, is
determined by the delays through the combinational and sequential elements. We define propagation delay as the time
between when the voltage at the input is at 50% and when the output is at 50% as shown in figure <a href='#different-delays'>5<!-- tex4ht:ref: fig:diff_delays  --></a>. If the switching
threshold is skewed (not at 50%), we then measure the time between these switching threshold values at
the input and output. The propagation delay can be different for a high-to-low and low-to-high transition.
</p><figure class='figure' id='x1-60015'><span id='different-delays'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 144 --><p class='noindent'><img alt='PIC' height='150' src='images/prop_delay.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 5: </span><span class='content'>Different delays</span></figcaption><!-- tex4ht:label?: x1-60015  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 149 --><p class='indent'>   The propagation delay is a function of the slopes of the signals at the input and output. We can define rise and fall times
as the time it takes for the signal at the output to transition between 10% and 90% (or vice versa) of the full-scale voltage.
The rise and fall times are determined by the strength of the driving gate and the fanout and parasitics the gate has to
drive at the output. RC delay models approximate the nonlinear I-V and C-V characteristics with an average resistance and
capacitance over the switching range of the gate [<a id='x1-6002'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. Effective resistance of a xtor is inversely proportional to its width and
directly proportional to its length. In a velocity-saturated device, the current, hence the resistance, is independent of
channel length. Series transistors are less velocity-saturated as they experience smaller \(V_{DS}\) drops, and hence, have
smaller resistance than the sum of the two series resistances [<a href='#cite.0_weste_cmos_2011'>15</a>]. Wider xtors have proportionally larger gate
and diffusion capacitances but increasing length only increases the gate capacitance and not the diffusion
capacitance.
</p>
   <h4 class='subsectionHead' id='mosfet'><span class='titlemark'>1.5   </span> <a id='x1-70001.5'></a>MOSFET</h4>
<!-- l. 160 --><p class='noindent'>A simple model of a MOSFET assumes that the device is not conducting below \(V_{GS} &lt; V_{th}\) and above the threshold voltage - —the
larger the voltage difference between gate and source, the smaller the resistance of the conducting channel and the larger
the current. Strong inversion of the channel is said to occur at twice the Fermi potential, a point where the substrate’s
surface is inverted (n-type in an NMOS).
</p><!-- l. 164 --><p class='indent'>   \[\phi _F = -\frac {kT}{q} \mathrm {ln}\bigg ( \frac {N_A}{n_i}\bigg )\]
</p><!-- l. 166 --><p class='indent'>   The above equation gives the Fermi potential as a function of temperature, doping concentration, and intrinsic carrier
concentration. Further increasing gate voltage doesn’t change the depletion layer width in the channel but draws additional
electrons [<a id='x1-7001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. The threshold voltage is then defined as
</p><!-- l. 172 --><p class='indent'>   \begin {equation}  \label {eqn:threshold_voltage_mosfet} V_T = V_{T0} + \gamma (\sqrt {|V_{SB}-2\phi _F|} - \sqrt {|-2\phi _F|})  \end {equation}<a id='x1-7002r7'></a>
</p><!-- l. 174 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='mosfet-in-triode'><span class='titlemark'>1.5.1   </span> <a id='x1-80001.5.1'></a>MOSFET in triode</h5>
<!-- l. 176 --><p class='noindent'>Say \(V_{GS} &gt; V_T\) and \(V_{DS}\) is small enough that the xtor is in triode region. The charge in the channel depends on \(V_{GS}-V_T-V(x)\) at every \(x\) and the drift
velocity depends on the \(V_{DS}\).
</p><!-- l. 182 --><p class='indent'>   \begin {equation}  \label {eqn:ids_triode_derivation} \frac {I_{DS}}{W} = \mu _n \frac {dV}{dX} C_{ox} (V_{GS}-V_T-V(x))  \end {equation}<a id='x1-8001r8'></a>
</p><!-- l. 188 --><p class='indent'>   \begin {equation}  \label {eqn:ids_triode} I_{DS} = \mu _n C_{ox} \frac {W}{L} \bigg [(V_{GS}-V_T)V_{DS}-\frac {V^2_{DS}}{2} \bigg ]  \end {equation}<a id='x1-8002r9'></a>
</p><!-- l. 191 --><p class='indent'>   For small \(V_{DS}\), the quadratic term in eqn <a href='#x1-8002r9'>9<!-- tex4ht:ref: eqn:ids_triode  --></a> can be neglected, giving a linear current-voltage relationship. Hence, this regime
of operation is also known as linear regime or resistive regime.
</p><!-- l. 193 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='mosfet-in-saturation'><span class='titlemark'>1.5.2   </span> <a id='x1-90001.5.2'></a>MOSFET in saturation</h5>
<!-- l. 195 --><p class='noindent'>In the case of triode region, every point in the channel obeyed the inequality
</p><!-- l. 197 --><p class='indent'>   \[V_{GS} - V(x) &gt; V_T \]
</p><!-- l. 199 --><p class='indent'>   i.e., the channel was invereted throughout. If we increase \(V_{DS}\) further, this assumption fails. At the drain, the channel is said
to be pinched off and
</p><!-- l. 205 --><p class='indent'>   \begin {equation}  \label {eqn:sat_condition} V_{GS} - V_{DS} \leq V_T  \end {equation}<a id='x1-9001r10'></a>
                                                                                               
                                                                                               
</p><!-- l. 208 --><p class='indent'>   The channel is said to be saturated and the key point is that the voltage difference between any point in the channel and
the source is now \(V_{GS}-V_T\). We can substitute \(V_{DS} = V_{GS}-V_T\) in eqn <a href='#x1-8002r9'>9<!-- tex4ht:ref: eqn:ids_triode  --></a> to get the expression for the drain current in saturation
regime
</p><!-- l. 215 --><p class='indent'>   \begin {equation}  \label {eqn:ids_sat} I_{DS} = \mu _n C_{ox} \frac {W}{2L} ( V_{GS}-V_T)^2  \end {equation}<a id='x1-9002r11'></a>
</p><!-- l. 217 --><p class='indent'>   Note that eqn <a href='#x1-17005r16'>16<!-- tex4ht:ref: eqn:ids_sat  --></a> is valid for long channel MOSFETs that do not have channel length modulation. Here, the drain
current is independent of \(V_{DS}\). This is not true in the case of short channel MOSFETs which have a finite output impedance -
or channel length modulation.
</p><!-- l. 220 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='subthreshold-conduction'><span class='titlemark'>1.5.3   </span> <a id='x1-100001.5.3'></a>Subthreshold conduction</h5>
<!-- l. 222 --><p class='noindent'>In the previous models, we made an approximation that the drain current is zero when \(V_{GS} &lt; V_T\).
</p>
   <figure class='figure' id='x1-100016'><span id='id-vs-vgs'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 227 --><p class='noindent'><img alt='PIC' height='150' src='images/id_vs_vgs.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 6: </span><span class='content'>\(I_D\) vs \(V_{GS}\)</span></figcaption><!-- tex4ht:label?: x1-100016  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 232 --><p class='indent'>   This assumption is not quite true as seen in figure <a href='#id-vs-vgs'>6<!-- tex4ht:ref: fig:id_vgs  --></a>. In fact, the current exponentially rises as given
below
</p><!-- l. 237 --><p class='indent'>   \begin {equation}  \label {eqn:ids_subvt} I_{DS} = I_S \hspace {1mm} \mathrm {exp} \bigg ( \frac {V_{GS}}{nkT/q} \bigg ) ( 1- \exp \bigg ( \frac {V-{DS}}{kT/q} \bigg ) )  \end {equation}<a id='x1-10002r12'></a>
</p><!-- l. 239 --><p class='indent'>   The subthreshold slope (S = nkT/q) defines how steeply the current turns off with decreasing \(V_{GS}\). We want a higher slope
(ideally 60 mV/decade for planar MOSFETs) and a lower lkg value at \(V_{GS} = 0V\).
</p>
   <h5 class='subsubsectionHead' id='gate-leakage'><span class='titlemark'>1.5.4   </span> <a id='x1-110001.5.4'></a>Gate Leakage</h5>
<!-- l. 244 --><p class='noindent'>There are two gate tunneling mechanisms - Fowler-Nordheim tunneling and direct tunneling - of which the former is used to
program EEPROMs and is only important at high voltages and moderate oxide thicknesses [<a id='x1-11001'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. Direct tunneling is the
most important mechanism for gate leakage in thin oxides and is given by
</p><!-- l. 251 --><p class='indent'>   \begin {equation}  \label {eqn:gate_lkg} I_{lkg} = WA \bigg ( \frac {V_{DD}}{t_{ox}}\bigg )^2 \exp \big ( -B\frac {t_ox}{V_DD} \big )  \end {equation}<a id='x1-11002r13'></a>
</p><!-- l. 253 --><p class='indent'>   where \(A\) and \(B\) are technology-dependent constants.
</p><!-- l. 255 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='junction-leakage'><span class='titlemark'>1.5.5   </span> <a id='x1-120001.5.5'></a>Junction leakage</h5>
<!-- l. 257 --><p class='noindent'>Heaviky droped source/drain are subject to band-to-band tunneling (BTBT) nad gate-induced drain leakage (GIDL).
BTBT occurs between the source/drain and the body the junction is reverse biased (which it is under normal operation).
Higher body concentration decreases subthreshold leakage but can increase BTBT leakage. Trap-assisted tunneling due to
the defects in silicon can exacerbate this kind of leakage.
</p><!-- l. 261 --><p class='indent'>   GIDL occurs where the gate and drain partially overlap. The gate can deplete the \(n^+\) drain region when \(V_{GD} &lt; 0\) (or gate has a
negative voltage w.r.t source as in the case of DRAM turning off). BTBT tunneling occurs from gate to drain. It can be
ignored for \(V_{GD} \ll V_{DD}\) [<a href='#cite.0_weste_cmos_2011'>15</a>].
</p><!-- l. 264 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='temperature-dependence'><span class='titlemark'>1.5.6   </span> <a id='x1-130001.5.6'></a>Temperature dependence</h5>
<!-- l. 266 --><p class='noindent'>Carrier mobility decreases with temperature. Threshold also decreases nearly linearly with temperature. Drain current at
high \(V_{DD}\) decreases with increasing temperature but subthreshold leakage increases exponentially with temperature. BTBT
increases slowly with temperature whule gate leakage is almost independent of temperature. This is summarized in table <a href='#temperature-dependence-of-key-mosfet-parameters'>1<!-- tex4ht:ref: tab:temp_dependence  --></a>.
Cooling helps system perfomance.
</p>
   <figure class='figure' id='x1-130017'><span id='id-vs-vgs-at-different-temperatures'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 273 --><p class='noindent'><img alt='PIC' height='150' src='images/ion_vs_T.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 7: </span><span class='content'>\(I_D\) vs \(V_{GS}\) at different temperatures</span></figcaption><!-- tex4ht:label?: x1-130017  -->
                                                                                               
                                                                                               
   </figure>
   <div class='table'>
                                                                                               
                                                                                               
<!-- l. 278 --><p class='indent' id='temperature-dependence-of-key-mosfet-parameters'>   <a id='x1-130021'></a></p><figure class='float'>
                                                                                               
                                                                                               
<div class='tabular'> <table class='tabular' id='TBL-2'><colgroup id='TBL-2-1g'><col id='TBL-2-1' /><col id='TBL-2-2' /></colgroup><tr class='hline'><td></td><td></td></tr><tr id='TBL-2-1-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-1-1' style='white-space:nowrap; text-align:left;'><span class='cmbx-10'>Parameter                       </span></td><td class='td11' id='TBL-2-1-2' style='white-space:nowrap; text-align:left;'><span class='cmbx-10'>Temperature Dependence               </span></td>
</tr><tr class='hline'><td></td><td></td></tr><tr id='TBL-2-2-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-2-1' style='white-space:nowrap; text-align:left;'>Carrier mobility                      </td><td class='td11' id='TBL-2-2-2' style='white-space:nowrap; text-align:left;'>Decreases with temperature                    </td>
</tr><tr id='TBL-2-3-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-3-1' style='white-space:nowrap; text-align:left;'>Threshold voltage                    </td><td class='td11' id='TBL-2-3-2' style='white-space:nowrap; text-align:left;'>Decreases nearly linearly with temperature</td>
</tr><tr id='TBL-2-4-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-4-1' style='white-space:nowrap; text-align:left;'>Drain current (high \(V_{DD}\))               </td><td class='td11' id='TBL-2-4-2' style='white-space:nowrap; text-align:left;'>Decreases with increasing temperature      </td>
</tr><tr id='TBL-2-5-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-5-1' style='white-space:nowrap; text-align:left;'>Subthreshold leakage                </td><td class='td11' id='TBL-2-5-2' style='white-space:nowrap; text-align:left;'>Increases exponentially with temperature  </td>
</tr><tr id='TBL-2-6-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-6-1' style='white-space:nowrap; text-align:left;'>Band-to-band tunneling (BTBT)</td><td class='td11' id='TBL-2-6-2' style='white-space:nowrap; text-align:left;'>Increases slowly with temperature            </td>
</tr><tr id='TBL-2-7-' style='vertical-align:baseline;'><td class='td11' id='TBL-2-7-1' style='white-space:nowrap; text-align:left;'>Gate leakage                           </td><td class='td11' id='TBL-2-7-2' style='white-space:nowrap; text-align:left;'>Almost independent of temperature         </td>
</tr><tr class='hline'><td></td><td></td></tr></table>                                                                  </div>
<figcaption class='caption'><span class='id'>Table 1: </span><span class='content'>Temperature dependence of key MOSFET parameters.</span></figcaption><!-- tex4ht:label?: x1-130021  -->
                                                                                               
                                                                                               
   </figure>
   </div>
   <h5 class='subsubsectionHead' id='channel-capacitances'><span class='titlemark'>1.5.7   </span> <a id='x1-140001.5.7'></a>Channel capacitances</h5>
<!-- l. 307 --><p class='noindent'>The gate oxide has a capacitance per unit area given by \(C_{ox} = \epsilon _{ox} / t_{ox}\). From a drain current perspective, it is desirable to have a high
\(C_{ox}\).
</p>
   <figure class='figure' id='x1-140018'><span id='capacitances-in-different-operation-regimes'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 312 --><p class='noindent'><img alt='PIC' height='200' src='images/moscaps.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 8: </span><span class='content'>Capacitances in different operation regimes</span></figcaption><!-- tex4ht:label?: x1-140018  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 317 --><p class='indent'>   In figure <a href='#capacitances-in-different-operation-regimes'>8<!-- tex4ht:ref: fig:moscaps  --></a>, when \(V_{DS}=0\) and \(V_{GS}\) is ramped up, the total capacitance initially is just \(WLC_{ox}\) with \(V_{GS} = 0\). As the gate voltage
increases, there is a depletion region that forms under the channel that pushes the charge centroid away from the
channel, thus, decreasing the effective capacitance. At \(V_{GS} = V_T\), the channel inverts and the body terminal is now
shielded from the gate by the channel, \(C_{GC,B}=0\). Since \(V_{DS}=0\), the total cap is now split equally between the source and drain,
\(C_{GC,S} =C_{GC,D} = WLC_{ox}/2\).
</p><!-- l. 321 --><p class='indent'>   Once the xtor is on the distribution of charge in the channel depends on \(V_{DS}\). If we use \(V_{DS}/(V_{GS}-V_T)\) as a proxy for the degree of
saturation, we see in figure <a href='#capacitances-in-different-operation-regimes'>8<!-- tex4ht:ref: fig:moscaps  --></a> on the right, that \(C_{GC,D}\) falls to 0 at higher saturation levels, while \(C_{GC,S}\) increases to \(2/3WLC_{ox}\). The total gate cap
falls off from \(WLC_{ox}\) to \(2/3WLC_{ox}\).
</p><!-- l. 324 --><p class='indent'>   We can also include a constant overlap capacitance term to the above expressions to model the physical overlap between
the gate and S/D - \(C_{ov}\).
</p>
   <h5 class='subsubsectionHead' id='junction-capacitances'><span class='titlemark'>1.5.8   </span> <a id='x1-150001.5.8'></a>Junction capacitances</h5>
<!-- l. 329 --><p class='noindent'>The reverse biased source-body and drain-body pn junctions contribute to junction (or diffusion) capacitance. The diffusion
capacitance has two components - the bottom plate junction formed by the source/drain doping and the substrate doping,
and the side-wall junction, formed by the source/drain doping and the \(p^+\) channel stop implant (basically defines the
dimension of S/D into the plane). The total capacitance can be evalulated by knowing the area of each of these junctions at
a depth of \(x_j\)
</p><!-- l. 332 --><p class='indent'>   \[C_{diff} = C_jL_sW + C_{jsw}x_j(2L_s+W)\]
</p><!-- l. 334 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='vt-variations'><span class='titlemark'>1.5.9   </span> <a id='x1-160001.5.9'></a>\(V_T\) variations</h5>
<!-- l. 336 --><p class='noindent'>We discuss two kinds of \(V_T\) variation - decrease in \(V_T\) with channel length, and drain-induced barrier lowering (DIBL). We are
going to ignore \(V_T\) changes dues to \(V_{SB}\).
</p>
   <figure class='figure' id='x1-160019'><span id='vt-variations1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 340 --><p class='noindent'><img alt='PIC' height='250' src='images/vt_variations.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 9: </span><span class='content'>\(V_T\) variations</span></figcaption><!-- tex4ht:label?: x1-160019  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 345 --><p class='indent'>   In a long channel device, we assume that the channel under the gate is depleted only by \(V_{GS}\). This ignores the depletion
region formed by the substrate and source/drain regions. As channel length decreases, the fraction of these depletion widths
become larger and now the gate has to effectively flip a shorter channel (or amount of charge) to invert the channel.
This is called \(V_T\)-rolloff in smaller channel lengths since the gate can invert the channel at a lower voltage for
the same doping concentration in the substrate for short channel devices as compared to longer channel
ones.
</p><!-- l. 349 --><p class='indent'>   Similarly, the drain-junction depletion region increases with \(V_{DS}\) and shrinks the channel in a short channel device. Once
again, this causes a decrease in threshold voltage as \(V_{DS}\) is increased. This is called DIBL. For very high \(V_{DS}\) or short channels, this
depletion region can short out the channel and the gate loses control of the device operation - the device is only modulated
by \(V_{DS}\) then. This is known as punch-through.
</p>
   <h5 class='subsubsectionHead' id='mobility-degradation-and-velocity-saturation'><span class='titlemark'>1.5.10   </span> <a id='x1-170001.5.10'></a>Mobility degradation and Velocity Saturation</h5>
<!-- l. 355 --><p class='noindent'>In long channel devices, the velocity of the carriers is directly proportional to lateral electric field or \(V_{DS}\). At
high electric fields, the mobility of carriers saturates due to collisions with atoms and other carriers in the
channel. In typical planar p-channel MOSFETs, the saturation electric field is around 1.5 \(V/\mu m\) and the saturation
velocity of the electrons is approximately \(10^5\) m/s. Holes in an n-channel device saturate at the same velocity but
need a higher field strength to saturate [<a id='x1-17001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. Hence, velocity saturation effects are lesser in planar PMOS
devices.
</p>
   <figure class='figure' id='x1-1700210'><span id='velocity-saturation-effect'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 363 --><p class='noindent'><img alt='PIC' height='150' src='images/vel_sat_mosfet.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 10: </span><span class='content'>Velocity saturation effect</span></figcaption><!-- tex4ht:label?: x1-1700210  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 368 --><p class='indent'>   The critical electric field is given by
</p><!-- l. 373 --><p class='indent'>   \begin {equation}  \label {eqn:crit_E_vel_sat} E_c = \frac {2v_sat}{\mu _{eff}}  \end {equation}<a id='x1-17003r14'></a>
</p><!-- l. 375 --><p class='indent'>   where \(\mu _{eff}\) is the slope of the constant mobility region in figure <a href='#velocity-saturation-effect'>10<!-- tex4ht:ref: fig:vel_sat_mosfet  --></a>. If we define \(V_c = E_cL\), we can write
</p><!-- l. 381 --><p class='indent'>   \begin {equation}  \label {eqn:vds_sat} V_{DS,sat} = \frac {(V_{GS}-V_T)V_c }{(V_{GS}-V_T) + V_c}  \end {equation}<a id='x1-17004r15'></a>
</p><!-- l. 383 --><p class='indent'>   From eqn <a href='#x1-17004r15'>15<!-- tex4ht:ref: eqn:vds_sat  --></a>, we can write an approximate expression for the saturated drain current
</p><!-- l. 390 --><p class='indent'>   \begin {equation}  \label {eqn:ids_sat} I_{DS,sat} \approx WC_{ox}v_{sat}(V_{GS}-V_T)  \end {equation}<a id='x1-17005r16'></a>
</p><!-- l. 392 --><p class='indent'>   We see that in velocity saturation, the saturated current is not quadratically changing with overdrive voltage anymore
but varies linearly.
</p><!-- l. 394 --><p class='indent'>   Another consequence of velocity saturation is that transistors when placed in series drop lesser voltage across their
source/drain as compared to individual transistors. This makes them less prone to velocity saturation and makes series
transistors faster than expected [<a id='x1-17006'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. For example, two stacked NMOS xtors deliver more than half the current
of a single transistor of same width (so resistance is less than 2R - which a simple stacking model would
give).
</p>
   <h4 class='subsectionHead' id='cmos-latchup'><span class='titlemark'>1.6   </span> <a id='x1-180001.6'></a>CMOS Latchup</h4>
   <figure class='figure' id='x1-1800111'><span id='cmos-latchup1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 405 --><p class='noindent'><img alt='PIC' height='250' src='images/cmos_latchup.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 11: </span><span class='content'>CMOS latchup</span></figcaption><!-- tex4ht:label?: x1-1800111  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='scaling'><span class='titlemark'>1.7   </span> <a id='x1-190001.7'></a>Scaling</h4>
<!-- l. 414 --><p class='noindent'>Table <a href='#scaling-relations-for-various-parameters'>2<!-- tex4ht:ref: tab:scaling  --></a> reviews different scaling models. In full scaling, we keep the electric field constant as the device scales. This ensures
there is no breakdown or secondary effects in the shorter channel device due to high electric field. Note that such
scaling improves power by \(1/S^2\) where \(S\) is the scaling factor for both device dimensions and voltages. On the
other hand, fixed-voltage scaling defines a supply voltage and then scales the dimensions alone. In this case,
there is no improvement in power as there is no decrease in current. However, power density does go up
quadratically with the scaling factor. In general, there are different scaling factors for the xtor dimensions and the
voltages - since the voltage-scaling is fundamentally limited by the threshold voltage (therefore, \(S&gt;U&gt;1\) in the table
<a href='#scaling-relations-for-various-parameters'>2<!-- tex4ht:ref: tab:scaling  --></a>).
</p>
   <div class='table'>
                                                                                               
                                                                                               
<!-- l. 419 --><p class='indent' id='scaling-relations-for-various-parameters'>   <a id='x1-190012'></a></p><figure class='float'>
                                                                                               
                                                                                               
<div class='tabular'> <table class='tabular' id='TBL-3'><colgroup id='TBL-3-1g'><col id='TBL-3-1' /></colgroup><colgroup id='TBL-3-2g'><col id='TBL-3-2' /></colgroup><colgroup id='TBL-3-3g'><col id='TBL-3-3' /></colgroup><colgroup id='TBL-3-4g'><col id='TBL-3-4' /></colgroup><colgroup id='TBL-3-5g'><col id='TBL-3-5' /></colgroup><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-1-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-1-1' style='white-space:nowrap; text-align:left;'><span class='cmbx-10'>Parameter    </span></td><td class='td11' id='TBL-3-1-2' style='white-space:nowrap; text-align:left;'><span class='cmbx-10'>Relation</span></td><td class='td11' id='TBL-3-1-3' style='white-space:nowrap; text-align:center;'><span class='cmbx-10'>Full Scaling</span></td><td class='td11' id='TBL-3-1-4' style='white-space:nowrap; text-align:center;'><span class='cmbx-10'>General Scaling</span></td><td class='td11' id='TBL-3-1-5' style='white-space:nowrap; text-align:center;'><span class='cmbx-10'>Fixed-Voltage Scaling</span></td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-2-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-2-1' style='white-space:nowrap; text-align:left;'>\(W, L, t_{ox}\)              </td><td class='td11' id='TBL-3-2-2' style='white-space:nowrap; text-align:left;'>        </td><td class='td11' id='TBL-3-2-3' style='white-space:nowrap; text-align:center;'>      \(1/S\)      </td><td class='td11' id='TBL-3-2-4' style='white-space:nowrap; text-align:center;'>        \(1/S\)        </td><td class='td11' id='TBL-3-2-5' style='white-space:nowrap; text-align:center;'>          \(1/S\)          </td></tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-3-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-3-1' style='white-space:nowrap; text-align:left;'>\(V_{DD}, V_T\) </td><td class='td11' id='TBL-3-3-2' style='white-space:nowrap; text-align:left;'> </td><td class='td11' id='TBL-3-3-3' style='white-space:nowrap; text-align:center;'>  \(1/S\) </td><td class='td11' id='TBL-3-3-4' style='white-space:nowrap; text-align:center;'>  \(1/U\) </td><td class='td11' id='TBL-3-3-5' style='white-space:nowrap; text-align:center;'> 1</td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-4-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-4-1' style='white-space:nowrap; text-align:left;'>\(N_{SUB}\)              </td><td class='td11' id='TBL-3-4-2' style='white-space:nowrap; text-align:left;'>\(V / W_{depl}^2\)        </td><td class='td11' id='TBL-3-4-3' style='white-space:nowrap; text-align:center;'>      \(S\)      </td><td class='td11' id='TBL-3-4-4' style='white-space:nowrap; text-align:center;'>        \(S^2 / U\)        </td><td class='td11' id='TBL-3-4-5' style='white-space:nowrap; text-align:center;'>          \(S^2\)          </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-5-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-5-1' style='white-space:nowrap; text-align:left;'><span class='cmti-10'>Area</span>/Device     </td><td class='td11' id='TBL-3-5-2' style='white-space:nowrap; text-align:left;'>\(WL\)        </td><td class='td11' id='TBL-3-5-3' style='white-space:nowrap; text-align:center;'>      \(1/S^2\)      </td><td class='td11' id='TBL-3-5-4' style='white-space:nowrap; text-align:center;'>        \(1/S^2\)        </td><td class='td11' id='TBL-3-5-5' style='white-space:nowrap; text-align:center;'>          \(1/S^2\)          </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-6-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-6-1' style='white-space:nowrap; text-align:left;'>\(C_{ox}\)              </td><td class='td11' id='TBL-3-6-2' style='white-space:nowrap; text-align:left;'>\(1/t_{ox}\)        </td><td class='td11' id='TBL-3-6-3' style='white-space:nowrap; text-align:center;'>      \(S\)      </td><td class='td11' id='TBL-3-6-4' style='white-space:nowrap; text-align:center;'>        \(S\)        </td><td class='td11' id='TBL-3-6-5' style='white-space:nowrap; text-align:center;'>          \(S\)          </td></tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-7-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-7-1' style='white-space:nowrap; text-align:left;'>\(C_{gate}\) </td><td class='td11' id='TBL-3-7-2' style='white-space:nowrap; text-align:left;'>\(C_{ox} WL\) </td><td class='td11' id='TBL-3-7-3' style='white-space:nowrap; text-align:center;'>  \(1/S\) </td><td class='td11' id='TBL-3-7-4' style='white-space:nowrap; text-align:center;'>  \(1/S\) </td><td class='td11' id='TBL-3-7-5' style='white-space:nowrap; text-align:center;'>  \(1/S\)</td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-8-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-8-1' style='white-space:nowrap; text-align:left;'>\(k_n, k_p\)              </td><td class='td11' id='TBL-3-8-2' style='white-space:nowrap; text-align:left;'>\(C_{ox} W/L\)        </td><td class='td11' id='TBL-3-8-3' style='white-space:nowrap; text-align:center;'>      \(S\)      </td><td class='td11' id='TBL-3-8-4' style='white-space:nowrap; text-align:center;'>        \(S\)        </td><td class='td11' id='TBL-3-8-5' style='white-space:nowrap; text-align:center;'>          \(S\)          </td></tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-9-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-9-1' style='white-space:nowrap; text-align:left;'>\(I_{sat}\) </td><td class='td11' id='TBL-3-9-2' style='white-space:nowrap; text-align:left;'>\(C_{ox} WV\) </td><td class='td11' id='TBL-3-9-3' style='white-space:nowrap; text-align:center;'>  \(1/S\) </td><td class='td11' id='TBL-3-9-4' style='white-space:nowrap; text-align:center;'>  \(1/U\) </td><td class='td11' id='TBL-3-9-5' style='white-space:nowrap; text-align:center;'> 1</td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-10-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-10-1' style='white-space:nowrap; text-align:left;'><span class='cmti-10'>Current Density</span></td><td class='td11' id='TBL-3-10-2' style='white-space:nowrap; text-align:left;'>\(I_{sat}/Area\)        </td><td class='td11' id='TBL-3-10-3' style='white-space:nowrap; text-align:center;'>      \(S\)      </td><td class='td11' id='TBL-3-10-4' style='white-space:nowrap; text-align:center;'>        \(S^2 / U\)        </td><td class='td11' id='TBL-3-10-5' style='white-space:nowrap; text-align:center;'>          \(S^2\)          </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-11-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-11-1' style='white-space:nowrap; text-align:left;'>\(R_{on}\)              </td><td class='td11' id='TBL-3-11-2' style='white-space:nowrap; text-align:left;'>\(V / I_{sat}\)        </td><td class='td11' id='TBL-3-11-3' style='white-space:nowrap; text-align:center;'>     1        </td><td class='td11' id='TBL-3-11-4' style='white-space:nowrap; text-align:center;'>       1           </td><td class='td11' id='TBL-3-11-5' style='white-space:nowrap; text-align:center;'>          1                </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-12-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-12-1' style='white-space:nowrap; text-align:left;'>\(P\)              </td><td class='td11' id='TBL-3-12-2' style='white-space:nowrap; text-align:left;'>\(I_{sat} V\)        </td><td class='td11' id='TBL-3-12-3' style='white-space:nowrap; text-align:center;'>      \(1 / S^2\)      </td><td class='td11' id='TBL-3-12-4' style='white-space:nowrap; text-align:center;'>        \(1 / U^2\)        </td><td class='td11' id='TBL-3-12-5' style='white-space:nowrap; text-align:center;'>          1                </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-13-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-13-1' style='white-space:nowrap; text-align:left;'><span class='cmti-10'>Power Density  </span></td><td class='td11' id='TBL-3-13-2' style='white-space:nowrap; text-align:left;'>\(P / Area\)        </td><td class='td11' id='TBL-3-13-3' style='white-space:nowrap; text-align:center;'>     1        </td><td class='td11' id='TBL-3-13-4' style='white-space:nowrap; text-align:center;'>        \(S^2 / U^2\)        </td><td class='td11' id='TBL-3-13-5' style='white-space:nowrap; text-align:center;'>          \(S^2\)          </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-14-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-14-1' style='white-space:nowrap; text-align:left;'><span class='cmti-10'>Intrinsic delay  </span></td><td class='td11' id='TBL-3-14-2' style='white-space:nowrap; text-align:left;'>\(R_{on}C_{gate}\)        </td><td class='td11' id='TBL-3-14-3' style='white-space:nowrap; text-align:center;'>     1/\(S\)       </td><td class='td11' id='TBL-3-14-4' style='white-space:nowrap; text-align:center;'>       1/\(S\)          </td><td class='td11' id='TBL-3-14-5' style='white-space:nowrap; text-align:center;'>         1/\(S\)               </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-15-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-15-1' style='white-space:nowrap; text-align:left;'><span class='cmti-10'>Intrinsic energy </span></td><td class='td11' id='TBL-3-15-2' style='white-space:nowrap; text-align:left;'>\(C_{gate}V^2_{DD}\)        </td><td class='td11' id='TBL-3-15-3' style='white-space:nowrap; text-align:center;'>     1/\(S^3\)       </td><td class='td11' id='TBL-3-15-4' style='white-space:nowrap; text-align:center;'>       1/\(SU^2\)          </td><td class='td11' id='TBL-3-15-5' style='white-space:nowrap; text-align:center;'>         1/\(S\)               </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr><tr id='TBL-3-16-' style='vertical-align:baseline;'><td class='td11' id='TBL-3-16-1' style='white-space:nowrap; text-align:left;'><span class='cmti-10'>Wire resistance </span></td><td class='td11' id='TBL-3-16-2' style='white-space:nowrap; text-align:left;'>\(1/(W*T)\)        </td><td class='td11' id='TBL-3-16-3' style='white-space:nowrap; text-align:center;'>      \(S^2\)      </td><td class='td11' id='TBL-3-16-4' style='white-space:nowrap; text-align:center;'>        \(S^2\)        </td><td class='td11' id='TBL-3-16-5' style='white-space:nowrap; text-align:center;'>          \(S^2\)          </td>
</tr><tr class='hline'><td></td><td></td><td></td><td></td><td></td></tr></table>                                                                                </div>
<figcaption class='caption'><span class='id'>Table 2: </span><span class='content'>Scaling relations for various parameters</span></figcaption><!-- tex4ht:label?: x1-190012  -->
                                                                                               
                                                                                               
   </figure>
   </div>
<!-- l. 451 --><p class='indent'>   Increased field in while keeping \(V_{DD}\) constant is increasing velocity saturation effects.
</p>
   <h4 class='subsectionHead' id='inverter-vtc'><span class='titlemark'>1.8   </span> <a id='x1-200001.8'></a>Inverter VTC</h4>
<!-- l. 456 --><p class='noindent' id='basic-concepts'>Some important static CMOS characteristics [<a id='x1-20001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]
</p><!-- l. 458 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-20003x1'>Rail-to-rail input and output swings, therefore, high noise margins can be achieved
     </li>
<li class='enumerate' id='x1-20005x2'>We’d like to have low output impedance for the inverter (low equivalent resitance)
     </li>
<li class='enumerate' id='x1-20007x3'>Ideally, infinite input impedance</li></ol>
<!-- l. 464 --><p class='indent'>   Figure <a href='#vtc-of-a-static-cmos-inverter'>95<!-- tex4ht:ref: fig:vtc_inverter  --></a> shows the voltage transfer characteristics (VTC) of an inverter. At \(V_{in} =0\), the NMOS device is off and the PMOS is
in linear regime. As \(V_{in}\) increases, the NMOS device turns on in saturation region (\(V_{GS}\) is small but \(V_{DS}\) is large) and the PMOS slowly
drops to saturation as well. The PMOS slowly turns off as the input is further increased and the NMOS falls into linear
regime at \(V_{in} = V_{DD}\). The switching threshold is the point where \(V_{in}=V_{out}\). More on this is discussed in the SRAM chapter. Increasing the
strength of the NMOS makes the switching threshold closer to GND while making the PMOS wider makes the switching
threshold closer to \(V_{DD}\).
</p>
   <figure class='figure' id='x1-2000812'><span id='piecewise-linear-model-for-an-inverter-vtc'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 472 --><p class='noindent'><img alt='PIC' height='150' src='images/pwl_vtc_inverter.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 12: </span><span class='content'>Piece-wise linear model for an inverter VTC</span></figcaption><!-- tex4ht:label?: x1-2000812  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 478 --><p class='indent'>   Figure <a href='#piecewise-linear-model-for-an-inverter-vtc'>12<!-- tex4ht:ref: fig:pwl_vtc_inv  --></a> shows the piece-wise linear model for the inverter VTC.
</p>
   <h4 class='subsectionHead' id='pass-xtor-characteristics'><span class='titlemark'>1.9   </span> <a id='x1-210001.9'></a>Pass xtor characteristics</h4>
<!-- l. 483 --><p class='noindent'>From figure <a href='#pass-xtor-threshold-drop'>13<!-- tex4ht:ref: fig:pass_xtor_drop  --></a>, we see that an NMOS can weakly pass a ‘1’ since the source voltage can only go as high as allowed by \(V_{GS} &gt; V_T\).
Similarly, a PMOS weakly passes a ‘0’. Note that when we stack xtors in series, the drops <span class='cmti-10'>don’t </span>stack since the drop
depends on \(V_{GS}\) and not the drain voltage. On the other hand, if a degraded xtor drives the gate of another device, the drops
stack up.
</p>
   <figure class='figure' id='x1-2100113'><span id='pass-xtor-threshold-drop'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 489 --><p class='noindent'><img alt='PIC' height='150' src='images/pass_xtor.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 13: </span><span class='content'>Pass xtor threshold drop</span></figcaption><!-- tex4ht:label?: x1-2100113  -->
                                                                                               
                                                                                               
   </figure>
                                                                                               
                                                                                               
   <h3 class='sectionHead' id='logical-effort'><span class='titlemark'>2   </span> <a id='x1-220002'></a>Logical Effort</h3>
<!-- l. 500 --><p class='noindent'>I like Prof. Sophia Shao’s lectures on logical efforts. Here are the relevant links
</p><!-- l. 502 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-22002x1'>FA22 class website - <a href='https://inst.eecs.berkeley.edu/~eecs151/fa22/'>Link</a>
     </li>
<li class='enumerate' id='x1-22004x2'>SP22 Class website - <a href='https://inst.eecs.berkeley.edu/~eecs151/sp22/'>Link</a>
     </li>
<li class='enumerate' id='x1-22006x3'>Lecture recording on YouTube - <a href='https://www.youtube.com/watch?v=napJsae659MURL'>Link FA22</a>, <a href='https://www.youtube.com/watch?v=tOBClpj1Pgo'>Link SP22</a></li></ol>
<!-- l. 508 --><p class='indent'>   The SP22 version has branching effort in the slides.
</p><!-- l. 510 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='inverter-delay'><span class='titlemark'>2.1   </span> <a id='x1-230002.1'></a>Inverter Delay</h4>
<!-- l. 512 --><p class='noindent'>Let’s start with a simple inverter and find its output delay. For a high-to-low transition, the equivalent resistance of the
NMOS matters while for the low-to-high transition, the equivalent resistance of PMOS matters - basically whichever switch
is on and is forming an RC-network. When we say equivalent resistance - we take some kind of average from the \(I_D-V_{DS}\)
curves.
</p>
   <figure class='figure' id='x1-2300114'><span id='inverter-delay-and-effect-of-rise-and-fall-times-at-the-input-on-the-chargingdischarging-curves'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 517 --><p class='noindent'><img alt='PIC' height='250' src='images/req_inv_delay.png' width='250' /> <img alt='PIC' height='225' src='images/req_inv_delay_rise_fall.png' width='225' />
</p>
<figcaption class='caption'><span class='id'>Figure 14: </span><span class='content'>Inverter delay and effect of rise and fall times at the input on the charging/discharging curves</span></figcaption><!-- tex4ht:label?: x1-2300114  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 522 --><p class='indent'>   When there is a rise/fall time at the input, the gradual rise in the gate voltage causes an increase in current but it never
quite reaches the peak as when there was no rise/fall time since the capacitor discharges a little (\(V_{DS}\) drops a little).
Therefore, the discharging/charging is slower due to rise/fall times when compared to their absence at the
input.
</p><!-- l. 527 --><p class='indent'>   For the capacitance, we model the parasitics at the drains as \(C_d = \gamma C_{in}\). \(C_{in}\) is set by the width of the gate. Say the load cap is \(C_L\). We
now have inverter RC delay below in eqn <a href='#x1-23002r17'>17<!-- tex4ht:ref: eqn:inv_delay  --></a>
</p><!-- l. 533 --><p class='indent'>   \begin {equation}  \label {eqn:inv_delay} t_p = \ln 2\ R_{eq} (C_p +C_L) = \ln 2\ R_{eq} (\gamma C_{in} +C_L)  \end {equation}<a id='x1-23002r17'></a>
</p><!-- l. 535 --><p class='indent'>   We define <span class='cmbx-10'>Fanout </span>(\(f\)) as ratio of load cap to the gate input cap.
</p><!-- l. 537 --><p class='indent'>   \[f = \frac {C_L}{C_{in}}\]
</p><!-- l. 539 --><p class='indent'>   We can now rewrite eqn <a href='#x1-23002r17'>17<!-- tex4ht:ref: eqn:inv_delay  --></a> as follows with \(\tau _{inv}\) is independent of xtor sizing (width increases, R goes down and C goes up
and this RC constant remains the same) - \begin {equation}  \label {eqn:inv_delay_fanout} t_p = \ln 2\ R_{eq} C_{in} (\gamma + f) = \tau _{inv} (\gamma + f)  \end {equation}<a id='x1-23003r18'></a>
</p>
   <figure class='figure' id='x1-2300415'><span id='inverter-delay-normalized-to-delay-at-v-vdd-as-a-function-of-vdd'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 549 --><p class='noindent'><img alt='PIC' height='150' src='images/inv_delay_vs_vdd.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 15: </span><span class='content'>Inverter delay (normalized to delay at 2.5 V \(V_{DD}\)) as a function of \(V_{DD}\)</span></figcaption><!-- tex4ht:label?: x1-2300415  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 554 --><p class='indent'>   In figure <a href='#inverter-delay-normalized-to-delay-at-v-vdd-as-a-function-of-vdd'>15<!-- tex4ht:ref: fig:inv_delay_vs_vdd  --></a>, we see that the delay decreases rapidly initially as \(V_{DD}\) increases - this is due to the decrease in the ON
resistance of the devices. The improvement tapers for larger \(V_{DD}\), however.
</p>
   <h4 class='subsectionHead' id='inverter-chain-optimization'><span class='titlemark'>2.2   </span> <a id='x1-240002.2'></a>Inverter Chain Optimization</h4>
<!-- l. 560 --><p class='noindent'>Say we have a chain of N inverters and we want to optimize for the delay across the chain. We first define a normalized
delay
</p><!-- l. 565 --><p class='indent'>   \begin {equation}  \label {eqn:inv_delay_normalized} D = \frac {t_p}{\tau _{inv}} = \gamma + f  \end {equation}<a id='x1-24001r19'></a>
</p><!-- l. 567 --><p class='indent'>   We now define path delay across the chain as \(\sum _{i=1}^{n} D_i \). \(\gamma \) is a process defined parameter and is sizing-independent. If each stage
has a fanout of \(f_i\), then we have total delay \(D\) given by
</p><!-- l. 574 --><p class='indent'>   \begin {equation}  \label {eqn:inv_delay_path} D = \sum _{i=1}^{n} D_i = N \sum _{i=1}^{n} f_i + N \gamma  \end {equation}<a id='x1-24002r20'></a>
</p><!-- l. 576 --><p class='indent'>   The only part in eqn <a href='#x1-24002r20'>20<!-- tex4ht:ref: eqn:inv_delay_path  --></a> that we can optimize is the fanout part. We define <span class='cmbx-10'>Path Fanout </span>(\(F\)) as the product of each
stage’s fanout (\(F = \prod _{i=1}^{n} f_i\)) and by applying AM-GM inequality, we conclude that for min delay across the entire chain, we need to
have each stage’s fanout equal to \(f_{opt} = \sqrt [n]{F}\). An example is shown in fig <a href='#example-of-inverter-chain-sizing-using-optimal-fanout'>16<!-- tex4ht:ref: fig:opt_fanout_ex  --></a>
</p>
   <figure class='figure' id='x1-2400316'><span id='example-of-inverter-chain-sizing-using-optimal-fanout'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 582 --><p class='noindent'><img alt='PIC' height='250' src='images/inv_chain_ex.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 16: </span><span class='content'>Example of inverter chain sizing using optimal fanout</span></figcaption><!-- tex4ht:label?: x1-2400316  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 588 --><p class='indent'>   Now that we have an optimal fanout per stage, the total normalized delay from eqn <a href='#x1-24002r20'>20<!-- tex4ht:ref: eqn:inv_delay_path  --></a> can be rewritten as
follows
</p><!-- l. 595 --><p class='indent'>   \begin {equation}  \label {eqn:inv_delay_path_rewrite} D = NF^{1/N} + N \gamma  \end {equation}<a id='x1-24004r21'></a>
</p><!-- l. 597 --><p class='indent'>   We can now use eqn <a href='#x1-24004r21'>21<!-- tex4ht:ref: eqn:inv_delay_path_rewrite  --></a> to find the optimal number of stages (\(N_{opt}\)) to drive a load, given we have an estimate for \(\gamma \). Figure <a href='#normalized-delay-vs-number-of-stages-for-a-given-path-fanout'>17<!-- tex4ht:ref: fig:opt_stages  --></a>
shows a shallow minima around 4 stages for an inverter chain with an example path fanout of 64. We also did a similar
excercise is HW8 in 251A class. This can also be extended to other logic gates and we can find the optimal number of
stages.
</p>
   <figure class='figure' id='x1-2400517'><span id='normalized-delay-vs-number-of-stages-for-a-given-path-fanout'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 603 --><p class='noindent'><img alt='PIC' height='250' src='plot_D_vs_N.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 17: </span><span class='content'>Normalized delay vs number of stages for a given path fanout</span></figcaption><!-- tex4ht:label?: x1-2400517  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='generalizing-inverter-delay'><span class='titlemark'>2.3   </span> <a id='x1-250002.3'></a>Generalizing Inverter Delay</h4>
<!-- l. 613 --><p class='noindent'>We can generalize eqn <a href='#x1-23002r17'>17<!-- tex4ht:ref: eqn:inv_delay  --></a> to other logic gates and write an expression for normalized delay w.r.t to \(\tau _{inv}\).
</p><!-- l. 618 --><p class='indent'>   \begin {equation}  D \ (gate) \ = \frac {t_{p,gate}}{\tau _{inv}} = P + LE * FO \label {eqn:norm_delay}  \end {equation}<a id='x1-25001r22'></a>
</p><!-- l. 620 --><p class='indent'>   where \(P\) is the normalized parasitic delay given by ratio of \( \ln 2 \ R_{eq,gate}C_{p,gate}\) to the parasitic delay of an inverter, \(FO\) is the fanout, i.e, ratio of
load cap to the input cap of that particular logic gate, and \(LE\) is the logical effort. Let’s take a moment to define logical
effort.
</p>
   <figure class='figure' id='x1-2500218'><span id='defining-logical-effort-by-extending-inverter-delay'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 625 --><p class='noindent'><img alt='PIC' height='250' src='images/le_funda.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 18: </span><span class='content'>Defining logical effort by extending inverter delay</span></figcaption><!-- tex4ht:label?: x1-2500218  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 631 --><p class='indent'>   From figure <a href='#defining-logical-effort-by-extending-inverter-delay'>18<!-- tex4ht:ref: fig:le_funda  --></a>, we see that logical effort is defined as the ratio of RC delays that come out as a result of design choices -
sizing of the logic gates. To remove dependence on \(R_{eq}\), we size the logic gate such that it has the same drive strength
as the inverter. Now \(LE\) just becomes the ratios of the input capacitances of the logical gate to that of the
inverter.
</p>
   <figure class='figure' id='x1-2500319'><span id='calculating-le-of-a-nand-gate'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 636 --><p class='noindent'><img alt='PIC' height='250' src='images/le_nand2_ex.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 19: </span><span class='content'>Calculating \(LE\) of a NAND2 gate</span></figcaption><!-- tex4ht:label?: x1-2500319  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 642 --><p class='indent'>   The whole excercise we did was so that given a gate - we have a scaling factor for the delay of this gate w.r.t an inverter
which is <span class='cmbx-10'>independent </span>of the widths, i.e., the same gate but with different sizing will have the same logical effort. <span class='cmbx-10'>Logical
effort is fixed for a gate/topology.</span>
</p><!-- l. 645 --><p class='indent'>   Another thing to note is that the parasitic delay, \(P\), is calculated only by taking \(C_d\) of the gate and this is not
counted in the fanout of that stage (basically parasitic cap is not counted as load in \(FO\) calculations). In figure
<a href='#defining-logical-effort-by-extending-inverter-delay'>18<!-- tex4ht:ref: fig:le_funda  --></a>, we see that we assumed \(C_{p,inv} = C_{in,inv}\) or \(\gamma = 1\). Similar to logical effort, \(P\) <span class='cmbx-10'>is independent of sizing as well </span>since it is
normalized to the delay of an inverter. [<a id='x1-25004'></a><a href='#cite.0_horowitz_logical_effort_revisited_1998'>7</a>] notes that exact parasitic delay calculation depends on which
input in transitioning (since that decides which parasitc caps need to be charged/discharged). Parasitic delay
grows linearly in case of parallel xtors but quadratically with series transistors (n xtors each n times larger to
make \(R_{eq}\) equal to inverter drive). Increasing xtor size to the first order doesn’t change parasitic delay since the
capacitance goes up but the resistance goes down [<a id='x1-25005'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. Wider xtors can be folded in layout to further reduce their
parasitics.
</p>
   <div class='tcolorbox tcolorbox' id='tcolobox-1'>     
<div class='tcolorbox-title'>
   </div> 
<div class='tcolorbox-content'><!-- l. 652 --><p class='noindent'>Finally, we note that in eqn <a href='#x1-25001r22'>22<!-- tex4ht:ref: eqn:norm_delay  --></a>, once we have a combinational circuit defined, we can only play with the
fanout - \(LE\) and \(P\) are already defined by the gates we used to synthesize the circuit. </p> 
</div> 
</div>
   <h4 class='subsectionHead' id='gate-sizing-example'><span class='titlemark'>2.4   </span> <a id='x1-260002.4'></a>Gate Sizing Example</h4>
<!-- l. 659 --><p class='noindent'>Given a random chain of \(N\) gates, we can use eqn <a href='#x1-25001r22'>22<!-- tex4ht:ref: eqn:norm_delay  --></a> to find out the total delay from input to the output
</p><!-- l. 664 --><p class='indent'>   \begin {equation}  \label {eqn:single_stage_delay} \ Delay \ = \sum _{i=1}^{N} (P_i + LE_i*FO_i)  \end {equation}<a id='x1-26001r23'></a>
</p><!-- l. 666 --><p class='indent'>   From the previous optimizaiton for an inverter chain, we see that the AM-GM inequality can be applied to solve for the
min delay through the chain of random gates. This motivates us to define a few more terms that are the <span class='cmti-10'>products </span>of
individual stage parameters (as opposed to sum). We also know that the normalized parasitic delay is well defined for each
gate - and we cannot optimize it [<a id='x1-26002'></a><a href='#cite.0_sutherland_logical_effort_ch1'>14</a>].
</p><!-- l. 670 --><p class='indent'>   Therefore, we only have individual stage effort to optimize - \(SE_i = LE_i*FO_i\). Let’s also introduce branching. There is an additional
branching effort now - we need to drive the gates not on the path of interest too! Figure <a href='#gate-sizing-examples'>20<!-- tex4ht:ref: fig:gate_sizing  --></a> summarizes the use of logical
effort method to size the gates optimmally for min delay.
</p>
   <figure class='figure' id='x1-2600320'><span id='gate-sizing-examples'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 676 --><p class='noindent'><img alt='PIC' height='250' src='images/gate_sizing_no_branch.png' width='250' /><img alt='PIC' height='250' src='images/gate_sizing_branching.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 20: </span><span class='content'>Gate sizing examples</span></figcaption><!-- tex4ht:label?: x1-2600320  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='path-efforts'><span class='titlemark'>2.5   </span> <a id='x1-270002.5'></a>Path efforts</h4>
<!-- l. 683 --><p class='noindent'>From eqn <a href='#x1-26001r23'>23<!-- tex4ht:ref: eqn:single_stage_delay  --></a>, can we extend this to a multistage logic network? Let us consider the example in figure <a href='#gate-sizing-examples'>20<!-- tex4ht:ref: fig:gate_sizing  --></a>. Since the logical
effort does not depend on sizing of each logic gate, we can define a path logical effort, \(G\), which is the product of logical efforts
of each stage.
</p><!-- l. 686 --><p class='indent'>   \[G = \Pi g_i\]
</p><!-- l. 688 --><p class='indent'>   Why product? Remember from previous section, we can only optimize for stage effort, or \(LE_i*FO_i\). The parasitc delay comes
as an unwanted consequence of the topology/gates chosen. We can, therefore, also define a path fanout,
\(H\),
</p><!-- l. 691 --><p class='indent'>   \[H = \Pi h_i = \frac {C_{out}}{C_{in}}\]
</p><!-- l. 693 --><p class='indent'>   A total path effort can be defined now, similar to stage effort, \(F\),
</p><!-- l. 695 --><p class='indent'>   \[F = GH\]
</p><!-- l. 697 --><p class='indent'>   We can also define a branching effort,
</p><!-- l. 699 --><p class='indent'>   \[b = \frac {C_{onpath}+C_{offpath}}{C_{onpath}}\]
</p><!-- l. 701 --><p class='indent'>   and consequently, a path branching effort, \(B\)
</p><!-- l. 703 --><p class='indent'>   \[B = \Pi b_i\]
</p><!-- l. 705 --><p class='indent'>   We rewrite the path effort,
</p><!-- l. 707 --><p class='indent'>   \[F= \Pi f_i = GBH\]
</p><!-- l. 709 --><p class='indent'>   From the above equation, we see that the product of the stage efforts is a constant and depends on the topology and the
input and output capacitances. The delay, however, is the <span class='cmti-10'>sum </span>of these stage efforts. We can use the AM-GM inequality to
arrive at the same eqn as for a chain of inverters in eqn <a href='#x1-24002r20'>20<!-- tex4ht:ref: eqn:inv_delay_path  --></a>. Differentiating the same eqn w.r.t number of
stages, we see that the delay is minimized rougly for a stage effort of 4 (\(SE_i =4\)) and the total number of stages
is
</p><!-- l. 716 --><p class='indent'>   \begin {equation}  \label {eqn:ideal_num_stages} N = \log _\rho F  \end {equation}<a id='x1-27001r24'></a>
</p><!-- l. 718 --><p class='indent'>   Note that eqn <a href='#x1-27001r24'>24<!-- tex4ht:ref: eqn:ideal_num_stages  --></a> is a function of \(\gamma \) as shown in figure <a href='#normalized-delay-vs-number-of-stages-for-a-given-path-fanout'>17<!-- tex4ht:ref: fig:opt_stages  --></a>. For a smaller \(\gamma \), the curve is shallow and we can choose greater
number of stages.
</p><!-- l. 721 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='logical-effort-of-a-transmission-gate'><span class='titlemark'>2.6   </span> <a id='x1-280002.6'></a>Logical Effort of a Transmission gate</h4>
<!-- l. 723 --><p class='noindent'>So far each logic gate was driving the gate cap of another logic gate. How do we size a transmission gate? It can only be
done in some context of another gate [<a id='x1-28001'></a><a href='#cite.0_horowitz_logical_effort_revisited_1998'>7</a>]. This is because when we talk about logical effort, we are interested in the
equivalent resistance that the gate presents to the charging of the load cap. A transmission gate cannot
drive any load by itself and therefore, there is no meaning in calculating its logical effort in a standalone
scenario.
</p><!-- l. 726 --><p class='indent'>   This <a href='https://www.youtube.com/watch?v=49MJosEPu4U'>video</a> does a good job of explaining how to calculate logical effort in case of an inverter driving the output through
a transmission gate. First key idea is that in a transmission gate, the NMOS is good at passing a zero while the PMOS,
at passing a one. So, when we ask the NMOS to pass a one (input at drain), it can only pass \(V_{DD} - V_{th}\) - we model
this by saying that the resistance from low-to-high transition is twice that of high-to-low (when the NMOS
is asked to pass a zero). Likewise for PMOS. This is explained in 251B slides from my year (SP2025) as
shown in figure <a href='#equivalent-resistance-of-xtors-in-a-transmission-gate'>21<!-- tex4ht:ref: fig:req_xmission_gate  --></a>. Note that in this figure, widths of the N and PMOS are not mentioned - I used [<a href='#cite.0_horowitz_logical_effort_revisited_1998'>7</a>] as
                                                                                               
                                                                                               
reference and worked through a couple of examples in extracting LE for a given gate and transmission gate
combo.
</p>
   <figure class='figure' id='x1-2800221'><span id='equivalent-resistance-of-xtors-in-a-transmission-gate'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 733 --><p class='noindent'><img alt='PIC' height='250' src='images/req_xmission_gate.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 21: </span><span class='content'>Equivalent resistance of xtors in a transmission gate</span></figcaption><!-- tex4ht:label?: x1-2800221  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 738 --><p class='indent'>   Using figure <a href='#equivalent-resistance-of-xtors-in-a-transmission-gate'>21<!-- tex4ht:ref: fig:req_xmission_gate  --></a>, we first develop an equivalent resistance model for NMOS and PMOS individually for LH and HL
transitions. Say for a given technology, NMOS is twice as strong as PMOS, i.e., a normal CMOS inverter has width \(W\) for
NMOS and \(2W\) for PMOS. Let us build a transmission gate where the NMOS and PMOS have same widths of \(W\). The NMOS in
HL transition has a resitance \(R\) while a LH resistance of \(2R\). Similarly, a PMOS will have a LH resistance of \(2R\) (since its width is
W and not 2W), and a HL resistance of \(4R\). This is summarized in figure <a href='#equivalent-resistance-of-a-transmission-gate-with-a-given-size-of-n-and-pmos-devices'>22<!-- tex4ht:ref: fig:xgate_req_derivation  --></a>. Since the N and PMOS devices are in parallel, we
take the average resistance each devices contributes over the HL and LH transitions and put them in parallel. Finally, for
this sizing and strengths of the devices used, we get an equivalent resistance (\(R{eq}\)) for the transmission gate of
\(R\).
</p>
   <figure class='figure' id='x1-2800322'><span id='equivalent-resistance-of-a-transmission-gate-with-a-given-size-of-n-and-pmos-devices'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 746 --><p class='noindent'><img alt='PIC' height='250' src='images/xgate_req_derivation.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 22: </span><span class='content'>Equivalent resistance of a transmission gate with a given size of N and PMOS devices</span></figcaption><!-- tex4ht:label?: x1-2800322  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 751 --><p class='indent'>   Let us now drive the transmission gate with two logic gates and calculate the logical effort through each signal path.
Another key idea here is that, we need to pick a reference inverter whose sizes match the equivalent resistance from \(V_{DD}\)
to GND to that of the gate. What I mean is that - we cannot do logical effort calculations when the drive
strengths of the reference inverter and the combo of the logic gate and transmission gate are different. Figure <a href='#left-deriving-the-sizes-of-the-reference-inverter-right-logical-effort-calculation-for-different-gates-driving-a-transmission-gate'>23<!-- tex4ht:ref: fig:xgate_ref_inv  --></a>
illustrates this point and proceeds to calculate the logical effort for each gate. The results are verified from
[<a id='x1-28004'></a><a href='#cite.0_horowitz_logical_effort_revisited_1998'>7</a>].
</p>
   <figure class='figure' id='x1-2800523'><span id='left-deriving-the-sizes-of-the-reference-inverter-right-logical-effort-calculation-for-different-gates-driving-a-transmission-gate'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 757 --><p class='noindent'><img alt='PIC' height='250' src='images/xgate_ref_inv.png' width='250' /><img alt='PIC' height='250' src='images/gate_xgate_le_derive.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 23: </span><span class='content'>(Left) Deriving the sizes of the reference inverter. (Right) Logical effort calculation for different gates
driving a transmission gate.</span></figcaption><!-- tex4ht:label?: x1-2800523  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 763 --><p class='indent'>   Finally, we end the discussion on this topic with calculations of the parasitic delay. Let’s take the example
of an inverter plus a transmission gate combo. There are two parasitic components - one at the output of
the super gate and another at the internal node between these two gates. For the one at the output of the
two gates, the calculation is straightforward since the reference inverter is the same as what we used in the
logical effort calculations. However, for the internal node, the signal path is not going from \(V_{DD}\) to GND via the
output - the equivalent resistance is different. In fact, the equivalent resistance is just \(R\) since the internal
node only sees the inverter part driving charge onto it. The reference inverter is therefore identical to the
inverter used in the super gate. This is illustrated in figure <a href='#calculating-parasitic-components'>24<!-- tex4ht:ref: fig:xgate_par_delay  --></a> along with the derivation of the parasitic
delay.
</p>
   <figure class='figure' id='x1-2800624'><span id='calculating-parasitic-components'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 770 --><p class='noindent'><img alt='PIC' height='250' src='images/xgate_par_delay.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 24: </span><span class='content'>Calculating parasitic components</span></figcaption><!-- tex4ht:label?: x1-2800624  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='logical-effort-less-than-'><span class='titlemark'>2.7   </span> <a id='x1-290002.7'></a>Logical Effort less than 1</h4>
<!-- l. 782 --><p class='noindent'>For dynamic gates (where clk is involved), logical effort can be less than 1 - <a href='https://www.youtube.com/watch?v=hef8lHVB6UU'>video</a>. This means that these gates can be faster
than their static CMOS counterparts. The above video demonstrates this with a couple of examples - NAND2 and INV in
dynamic vs CMOS logic. Note that the reference inverter here is the static CMOS (even if you are trying to calculate the
LE of a complex dynamic logic gate, you take the static CMOS inverter as reference). [<a id='x1-29001'></a><a href='#cite.0_abraham_dynamic_cmos_logic_2020'>1</a>] has more notes on dynamic
CMOS. Figure <a href='#calculating-parasitic-components1'>25<!-- tex4ht:ref: fig:dyn_inv  --></a> illustrates an example of logical effort calculation for two implementations of a dynamic
inverter.
</p>
   <figure class='figure' id='x1-2900225'><span id='calculating-parasitic-components1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 789 --><p class='noindent'><img alt='PIC' height='250' src='images/dynamic inverters.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 25: </span><span class='content'>Calculating parasitic components</span></figcaption><!-- tex4ht:label?: x1-2900225  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='velocity-saturated-devices'><span class='titlemark'>2.8   </span> <a id='x1-300002.8'></a>Velocity saturated devices</h4>
<!-- l. 798 --><p class='noindent'>Let’s start with basics of \(I_D vs V_{DS}/V_{GS}\) curves. In long channel devices, once \(V_{GS} &gt; V_TH\), we have two regions of operation - triode and saturation
(not to be cofused with velocity saturation).
</p>
   <div class='eqnarray'>\begin {eqnarray}  \label {eqn:mosfet_transfer_curves} I_{DS} = WC_{ox} (V_{GS} - V_{TH}- V_C(x)) \mu E(x) \\ I_{DS} = WC_{ox} (V_{GS} - V_{TH}- V_C(x)) \mu \frac {\partial V_C(x)}{\partial x}  \end {eqnarray}</div>
<!-- l. 806 --><p class='indent'>   Set of eqns in <span class='cmbx-10'>??</span>, basically are saying that the current in the channel is charge times velocity. We can model the velocity
of the carriers as
</p><!-- l. 811 --><p class='indent'>   \begin {equation}  \label {eqn:vel_model} v = \frac {\mu _{eff}E}{\bigg (1+\bigg (\frac {E}{E_c} \bigg )^n\bigg )^(1/n)}  \end {equation}<a id='x1-30001r25'></a>
</p><!-- l. 813 --><p class='indent'>   In velocity saturation, we see that the charges can only move at a constant speed despite the increase in \(V_{DS}\). Let us pick \(n=1\)
and see how the drai current looks in triode and saturation regions under velocity saturation.
</p>
   <div class='eqnarray'>\begin {eqnarray}  \label {eqn:mosfet_transfer_curves_vel_sat} I_{DS} = WC_{ox} (V_{GS} - V_{TH}- V_C(x)) v \\ I_{DS,lin} = \frac {\mu C_{ox}}{1+(V_{DS}/E_C L)} \frac {W}{L} \bigg ((V_{GS}-V_{TH})V_{DS} - \frac {V^2_{DS}}{2} \bigg ) \\ I_{DS,sat} = WC_{ox} (V_{GS} - V_{TH}- V_{DSat}) v_{sat}  \end {eqnarray}</div>
<!-- l. 824 --><p class='indent'>   Solving for \(V_{DSat}\), we get
</p><!-- l. 826 --><p class='indent'>   \[V_{D,sat} = \frac {(V_{GS}-V_{TH})E_CL}{V_{GS}-V_{TH}+E_CL}\] \[I_{DS,sat} = \frac {\mu C_{ox}}{2}\frac {W}{L}\frac {(V_{GS}-V_{TH})^2}{(V_{GS}-V_{TH})+E_CL}\]
</p><!-- l. 829 --><p class='indent'>   When we calculate logical effort for devices in velocity saturation, we equate the saturation currents (not linear region)
in the N and PMOS. Remember that stacked transistors act as a single transistor of length \(nL\). Figure <a href='#example-of-logical-effort-calculations-in-velocity-saturation'>26<!-- tex4ht:ref: fig:vel_sat_let  --></a> goes through an
example.
</p>
   <figure class='figure' id='x1-3000226'><span id='example-of-logical-effort-calculations-in-velocity-saturation'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 835 --><p class='noindent'><img alt='PIC' height='150' src='images/vel_sat_le_ex.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 26: </span><span class='content'>Example of logical effort calculations in velocity saturation</span></figcaption><!-- tex4ht:label?: x1-3000226  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='limitations-of-logical-effort'><span class='titlemark'>2.9   </span> <a id='x1-310002.9'></a>Limitations of Logical Effort</h4>
<!-- l. 844 --><p class='noindent'>Here are some limitations of the logical effort models [<a id='x1-31001'></a><a href='#cite.0_weste_cmos_2011'>15</a>]
</p><!-- l. 846 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-31003x1'>The model fails to account for the input slope - longer the rise time, longer the propagation delay but we
     can’t model it using logical effort easily
     </li>
<li class='enumerate' id='x1-31005x2'>In an n-input gate, the model assumes that all the signals arrive at the same time at the input. This need not
     be true and can increase/decrease delay depending on xtors being stacked series/parallel
     </li>
<li class='enumerate' id='x1-31007x3'>
     <!-- l. 850 --><p class='noindent'>Parasitics do not model \(C_{gd}\) accurately. This couples the input to the output in an effect known as bootstrapping.
     \(C_{gd}\) can increase the effective gate capacitance that needs to be driven at the input or the parasitic cap that needs
     to be discharged at the output.
</p>
     <figure class='figure' id='x1-3100827'><span id='effect-of-bootstrapping-on-inverter-delay'></span> 
<img alt='PIC' height='150' src='images/bootstrap.png' width='150' />
<figcaption class='caption'><span class='id'>Figure 27: </span><span class='content'>Effect of bootstrapping on inverter delay</span></figcaption><!-- tex4ht:label?: x1-3100827  -->
     </figure>
     <!-- l. 860 --><p class='noindent'>Figure <a href='#effect-of-bootstrapping-on-inverter-delay'>27<!-- tex4ht:ref: fig:bootstrap_ex  --></a> shows an example where in one inverter we consider the effect of \(C_{gd}\) and don’t for the other.
     As the node x goes low, a,c both go high. Node b experiences this rise at a through \(C_{gd}\) and rises (not
     because the PMOS was pulling it up but just by its own bootstraps) intially. After a while, the nodes b,d
     are pulled down since the NMOS turns on. b falls later than d due to the charge on the cap from the
     bootstrapping effect. Similarly, as b falls due to the NMOS discharging it, it tugs on a and makes it drop a bit
     before the PMOS overpowers it and pulls up. Therefore, node a takes longer than c for charging up
     completely.
     </p></li>
<li class='enumerate' id='x1-31010x4'>Paths with non-unform branching or reconvergent fanout (closed loops) are difficult to analyze using this
     technique.</li></ol>
<!-- l. 869 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='fixed-side-loads'><span class='titlemark'>2.10   </span> <a id='x1-320002.10'></a>Fixed side loads</h4>
                                                                                               
                                                                                               
<!-- l. 873 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='reconvergent-fanout-example'><span class='titlemark'>2.11   </span> <a id='x1-330002.11'></a>Reconvergent fanout example</h4>
<!-- l. 875 --><p class='noindent'>How do we address asymmetric branching and reconvergent fanout as shown in figure <a href='#reconvergent-fanout-and-asymmetric-branching'>28<!-- tex4ht:ref: fig:reconvergent_fanout  --></a>?
</p>
   <figure class='figure' id='x1-3300128'><span id='reconvergent-fanout-and-asymmetric-branching'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 879 --><p class='noindent'><img alt='PIC' height='225' src='images/reconvergent_fanout.png' width='225' />
</p>
<figcaption class='caption'><span class='id'>Figure 28: </span><span class='content'>Reconvergent fanout and asymmetric branching</span></figcaption><!-- tex4ht:label?: x1-3300128  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 884 --><p class='indent'>   Note that in figure <a href='#reconvergent-fanout-and-asymmetric-branching'>28<!-- tex4ht:ref: fig:reconvergent_fanout  --></a> \(x_i\) indicates the drive strength as a multiple of unit inverter. In figure <a href='#defining-logical-effort-by-extending-inverter-delay'>18<!-- tex4ht:ref: fig:le_funda  --></a>, we see
that
</p><!-- l. 886 --><p class='indent'>   \[\mathrm {LE} = g = \frac {R_{eq,gate}C_{gate}}{R_{eq,inv}C_{inv}}\]
</p><!-- l. 888 --><p class='indent'>   If we define the denominator as 1, then any arbitrary gate has the drive [<a id='x1-33002'></a><a href='#cite.0_weste_cmos_2011'>15</a>]
</p><!-- l. 890 --><p class='indent'>   \[x_i = \frac {C_{gate}}{g} = \frac {1}{R_{eq,gate}}\]
</p><!-- l. 892 --><p class='indent'>   and the delay can be rewritten in terms of drive as
</p><!-- l. 894 --><p class='indent'>   \[d_i = \frac {C_{out}}{x_i}+p_i\]
</p><!-- l. 896 --><p class='indent'>   Now we can write the delays for each stage in figure <a href='#reconvergent-fanout-and-asymmetric-branching'>28<!-- tex4ht:ref: fig:reconvergent_fanout  --></a>.
</p><!-- l. 898 --><p class='indent'>   \[d_1 = \frac {4}{3}\frac {x_2}{1} + \frac {5}{3}\frac {x_3}{1} + 1\] \[d_{2,2} = \frac {7}{3}\frac {x_4}{x_2} + 2\] \[d_{2,3} = \frac {7}{3}\frac {x_4}{x_3} + 2\] \[d_3 = \frac {x_5+10}{x_4}+3\] \[d_4 = \frac {12}{x_5}+1\]
</p>
   <h4 class='subsectionHead' id='important-lessons-from-this-section'><span class='titlemark'>2.12   </span> <a id='x1-340002.12'></a>Important lessons from this section</h4>
<!-- l. 908 --><p class='noindent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-34002x1'>Logical effort for a given gate is independent of sizing - once we match the equivalent resistance of the gate
     to the inverter, the logical effort doesn’t change.
     </li>
<li class='enumerate' id='x1-34004x2'>Once we have a gate, we cannot change its parasitic delay or the logical effort. The two things we can optimize
     are the fanout for each stage (\(f\)) and the total number of stages. If the total number of stages is fixed and we
     have a known path fanout (\(F\)), then we can only optimize individual stage’s fanout. By this we mean we get to
     choose the sizing of transistors in each gate (note logical effort and normalized parasitic delay do not depend
     on this sizing). Don’t forget about branching while sizing!
     </li>
<li class='enumerate' id='x1-34006x3'>Logical effort of a transmission gate involves slightly involved concepts. First, it makes sense to talk about
     logical effort only of a super gate - some logic gate plus a transmission gate. Second, we need to approximate
     an average resistance by modeling the HL and LH transition resistances for the N and PMOS. Next, we need
     to identify the correct reference inverter, i.e., make sure that the drive strengths (or equivalent resistance)
     is matched between the super gate and the reference inverter. Finally, note that the reference inverter can
     change for parasitic delay calculations.
     </li>
<li class='enumerate' id='x1-34008x4'>Logical effort can be less than 1 for dynamic CMOS which makes them faster than their static CMOS
     counterparts.</li></ol>
                                                                                               
                                                                                               
<!-- l. 926 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='timing'><span class='titlemark'>3   </span> <a id='x1-350003'></a>Timing</h3>
<!-- l. 928 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='types-of-systems'><span class='titlemark'>3.1   </span> <a id='x1-360003.1'></a>Types of systems</h4>
<!-- l. 930 --><p class='noindent'>In sequential ckts, the order of data transfer/switching events matters - changing the order/timing can result in a functional
failure. The different types of synchronous systems are
</p><!-- l. 932 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-36002x1'>Synchronous system - all signals have the same frequency as the local clk but have a known, fixed phase offset.
     This class compromises of most of the register-based systems we study.
     </li>
<li class='enumerate' id='x1-36004x2'>
     <!-- l. 934 --><p class='noindent'>Mesochronous system - the signals have same frequency as the local clock but an unknown phase offset
     (which is still fixed/no change over time). For example, when talking across clk domains (even if they have
     the same frequency), it’s hard to know the phase relationship of the input signal at the receiver’s clk
     domain. We need a synchronizer to synchronize the data in the RX module. In figure <a href='#mesochronous-system'>29<!-- tex4ht:ref: fig:mesosync  --></a>, signals D1 and D2
     are synchronous with clk A but mesochronous with clk B. The variable delay line is used to tune the phase
     of the signal D2 so that it matches up with clk B. </p><figure class='figure' id='x1-3600529'><span id='mesochronous-system'></span> 
 <img alt='PIC' height='150' src='images/mesosync.png' width='150' />
<figcaption class='caption'><span class='id'>Figure 29: </span><span class='content'>Mesochronous system</span></figcaption><!-- tex4ht:label?: x1-3600529  -->
     </figure>
     </li>
<li class='enumerate' id='x1-36007x3'>
     <!-- l. 944 --><p class='noindent'>Plesiosynchronous system - The word “plesio” in Greek means near. The signals are nominally the same
     frequency but due to variations have slight differences in the frequency w.r.t the local clk. This causes a
     phase offset which drifts over time (unlike the mesochronous system where the phase offset was fixed but
     unknown). This typically happens when two modules use their own seprate crystal oscillators - there’s some
     ppm difference in frequencies between the two crystals that can lead to plesiosynchronocity (made up word).
     As shown in figure <a href='#plesiochronous-system'>30<!-- tex4ht:ref: fig:plesiosync  --></a>, the timing recovery module reconstructs the clk from the data sent at clk C1’s rate.
     The clk C3 that it generates is mesochronous to the TX module. A FIFO is used to buffer the data and then
     clocked at C2. If the transmit frequency is faster than C2, then data is dropped (if FIFO is full), and data is
     duplicated in the other case [<a id='x1-36008'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. </p><figure class='figure' id='x1-3600930'><span id='plesiochronous-system'></span> 
 <img alt='PIC' height='150' src='images/plesiosync.png' width='150' />
<figcaption class='caption'><span class='id'>Figure 30: </span><span class='content'>Plesiochronous system</span></figcaption><!-- tex4ht:label?: x1-3600930  -->
     </figure>
     </li>
<li class='enumerate' id='x1-36011x4'>Asynchronous system - the local clk is eliminated and replaced with a handshaking protocol to perform the proper
     ordering of operations. While this can speed up block computations since we don’t have to wait for the clk edge, the
     overhead from the handshaking protocols can result in increased complexity and overhead in communication that can
     reduce overall perfomance.
</li></ol>
<!-- l. 966 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='timing-metrics'><span class='titlemark'>3.2   </span> <a id='x1-370003.2'></a>Timing metrics</h4>
<!-- l. 968 --><p class='noindent'>Ideally, the entire clock period id available for computation in the combinational block. This is not possible in reality due to
the sequencing overhead introduced by latches and registers. Sequencing overhead of for registers include [<a id='x1-37001'></a><a href='#cite.0_weste_cmos_2011'>15</a>]
-
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-37003x1'>The set-up time (\(t_{su}\)) is the time that the data inputs (D input) must be valid before the clock transition (this
     is, the 0 to 1 transition for a positive edge-triggered register) [<a id='x1-37004'></a><a href='#cite.0_rabaey_digital_1996'>11</a>].
     </li>
<li class='enumerate' id='x1-37006x2'>The hold time (\(t_{hold}\)) is the time the data input must remain valid after the clock edge.
     </li>
<li class='enumerate' id='x1-37008x3'>Assuming both setup and hold times are met, the data at the D input is copied to the Q output after a
     worst-case propagation delay (with reference to the clock edge) denoted by \(t_{c-q}\).</li></ol>
<!-- l. 979 --><p class='indent'>   Figure <a href='#left-timing-parameters-definition-for-a-flipflop-right-max-clk-frequency-constraints-ecesequentiallogic'>31<!-- tex4ht:ref: fig:ff_timing_basics  --></a> illustrates the above definitions for an edge-triggered system.
</p>
   <figure class='figure' id='x1-3700931'><span id='left-timing-parameters-definition-for-a-flipflop-right-max-clk-frequency-constraints-ecesequentiallogic'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 983 --><p class='noindent'><img alt='PIC' height='250' src='images/ff_timing_basics.png' width='250' /><img alt='PIC' height='250' src='images/ff_timing_basics2.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 31: </span><span class='content'>(Left) Timing parameters definition for a flip-flop. (Right) Max clk frequency constraints [<a id='x1-37010'></a><a href='#cite.0_ece559_sequential_logic_2009'>2</a>]</span></figcaption><!-- tex4ht:label?: x1-3700931  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 988 --><p class='indent'>   For a flip-flop based system, we calculate the maximum clk frequency by taking the worst case delay in between two
registers. From figure <a href='#left-timing-parameters-definition-for-a-flipflop-right-max-clk-frequency-constraints-ecesequentiallogic'>31<!-- tex4ht:ref: fig:ff_timing_basics  --></a>, we see that
</p><!-- l. 993 --><p class='indent'>   \begin {equation}  \label {eqn:max_clk_ff_no_skew} T_{clk} \geq T_{c-q, reg1} + T_{logic,max} + T_{su, reg2}  \end {equation}<a id='x1-37011r26'></a>
</p><!-- l. 995 --><p class='indent'>   From eqn <a href='#x1-37011r26'>26<!-- tex4ht:ref: eqn:max_clk_ff_no_skew  --></a>, if there are no clock non-idealities, we see that the clk period has to accomodate the clk-q delay of the first
register, the max combinational delay from the blocks in between the two registers, and the setup time for the second
register. Similarly, the hold time of the second register imposes a condition on minimizing the delay from combinational
logic and the clk-q delay of the first register.
</p><!-- l. 1002 --><p class='indent'>   \begin {equation}  \label {eqn:min_hold_no_skew} T_{c-q, reg1} + T_{logic,min} \geq T_{hold, reg2}  \end {equation}<a id='x1-37012r27'></a>
</p><!-- l. 1004 --><p class='indent'>   Note that eqn <a href='#x1-37012r27'>27<!-- tex4ht:ref: eqn:min_hold_no_skew  --></a>, we see that hold time imposes no constraints on the max clk period.
</p><!-- l. 1006 --><p class='indent'>   In figure <a href='#delay-vs-data-arrival-time'>32<!-- tex4ht:ref: fig:ff_delay_vs_data_arrival  --></a>, we see that the actual clk-Q delay, \(t_{CQ}\), depends on when the data arrives w.r.t the clk edge. Say the data
arrives before the clk edge by \(t_{DC}\). If \(t_{DC}\) is large, i.e., data arrives much before the clk edge at input D, the clk-Q
delay is the shortest. It’s lower bound is the contamination delay of the register and increasing \(t_{DC}\) doesn’t
improve this delay any further. Since the total D-to-Q delay, \(t_{DQ}\), is the sum of \(t_{DC}\) and \(t_{CQ}\), it increases linearly in this
regime.
</p>
   <figure class='figure' id='x1-3701332'><span id='delay-vs-data-arrival-time'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1013 --><p class='noindent'><img alt='PIC' height='200' src='images/ff_delay_vs_data_arrival.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 32: </span><span class='content'>Delay vs data arrival time</span></figcaption><!-- tex4ht:label?: x1-3701332  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1018 --><p class='indent'>   When the data starts arriving closer to the clk edge, \(t_{DQ}\) initially starts decreasing due to decreases \(t_{DC}\) but the
actual clk-to-Q delay increases as the data arrives closer and closer to the clk edge. This clk-to-Q delay, \(t_{CQ}\),
dominates the overall delay in this regime. There is a minima in \(t_{DQ}\) between these two regimes where \(t_{CQ}\) has a
slope of -1 [<a id='x1-37014'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. We use this point where \(t_{DQ}\) is minimized to define the setup time \(t_{DC,setup}\) and nominal clk-to-Q delay
\(t_{cq}\).
</p><!-- l. 1022 --><p class='indent'>   In general, the delay times differ for 0 and 1 inputs. [<a href='#cite.0_weste_cmos_2011'>15</a>] notes that the setup time for 0 is longer than the setup time for
1 but the hold time for 0 is shorter than the hold time for 1 (why?).
</p>
   <figure class='figure' id='x1-3701533'><span id='actual-clktoq-delay-vs-data-arrival-time-for-and-inputs'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1028 --><p class='noindent'><img alt='PIC' height='200' src='images/ff_delay_vs_data_arrival2.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 33: </span><span class='content'>Actual clk-to-Q delay vs data arrival time for 0 and 1 inputs</span></figcaption><!-- tex4ht:label?: x1-3701533  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1034 --><p class='indent'>   We define an aperture time, \(t_{af}\), which is the sum of the setup and hold times. During this window, the data at the input
must not transition - otherwise the output can be stuck in a metasable state or take an unbounded time to settle
[<a id='x1-37016'></a><a href='#cite.0_weste_cmos_2011'>15</a>].
</p><!-- l. 1037 --><p class='indent'>   The same analysis can be done for a latch-based system as shown in figure <a href='#delay-vs-data-arrival-time-in-a-latch'>34<!-- tex4ht:ref: fig:latch_delay_vs_data_arrival  --></a>. On the x-axis, we plot the arrival of the
data w.r.t to both the rising and falling clk edges. Note that for a positive level sensitive latch, the falling edge of the clk is
more important. If the data arrives much before the falling edge, \(t_{DQ}\) is independent of \(t_{DCf}\) and only depends on the
contatmination delay through the latch. However, if the data arrives too early, earlier than the rising clk
edge, \(t_{DQ}\) increases linearly with \(t_{DCr}\). On the opposite end, when the data arrives to close to the falling edge, the
clk-to-Q delay starts to rise sharply. We define the setup time at the knee of this curve [<a href='#cite.0_weste_cmos_2011'>15</a>] as shown in figure
<a href='#delay-vs-data-arrival-time-in-a-latch'>34<!-- tex4ht:ref: fig:latch_delay_vs_data_arrival  --></a>.
</p>
   <figure class='figure' id='x1-3701734'><span id='delay-vs-data-arrival-time-in-a-latch'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1045 --><p class='noindent'><img alt='PIC' height='200' src='images/latch_delay_vs_data_arrival.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 34: </span><span class='content'>Delay vs data arrival time in a latch</span></figcaption><!-- tex4ht:label?: x1-3701734  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1050 --><p class='indent'>   Note that all these delays vary with input slope, supply voltage, and temperature.
</p>
   <h4 class='subsectionHead' id='clk-nonidealities'><span class='titlemark'>3.3   </span> <a id='x1-380003.3'></a>Clk non-idealities</h4>
<!-- l. 1054 --><p class='noindent'>Clock skew and clock jitter are the two main kinds of non-idealities. The spatial variation in arrival time of a clock
transition on an integrated circuit is commonly referred to as clock skew [<a id='x1-38001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. Clock skew is caused by static path-length
mismatches in the clock load and by definition skew is constant from cycle to cycle Figure <a href='#positive-clk-skew'>35<!-- tex4ht:ref: fig:clk_skew_ex  --></a> shows example of a positive
clk skew (a negative clk skew is when CLK2 arrives <span class='cmti-10'>before </span>CLK1).
</p>
   <figure class='figure' id='x1-3800235'><span id='positive-clk-skew'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1060 --><p class='noindent'><img alt='PIC' height='250' src='images/clk_skew_ex.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 35: </span><span class='content'>Positive clk skew</span></figcaption><!-- tex4ht:label?: x1-3800235  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1065 --><p class='indent'>   Let us take the example of the positive clk skew from figure <a href='#positive-clk-skew'>35<!-- tex4ht:ref: fig:clk_skew_ex  --></a> to see how eqn <a href='#x1-37011r26'>26<!-- tex4ht:ref: eqn:max_clk_ff_no_skew  --></a> changes. Register 2 now has \(T_{skew}\) more
time to wait before it is triggered, i.e, the clk period can be faster since the skew introduces some delay which makes sure
there is enough time for register 2 to evaluate the correct inputs.
</p><!-- l. 1071 --><p class='indent'>   \begin {equation}  \label {eqn:max_clk_ff_clk_skew} T_{clk} + T_{skew} \geq T_{c-q, reg1} + T_{logic,max} + T_{su, reg2}  \end {equation}<a id='x1-38003r28'></a>
</p><!-- l. 1073 --><p class='indent'>   On the other hand, clk skew at register 2 means that the combinational logic and the clk-q delay from
the first register have to be <span class='cmti-10'>slower </span>to ensure there is no hold time violation. This changes eqn <a href='#x1-37012r27'>27<!-- tex4ht:ref: eqn:min_hold_no_skew  --></a> to the
following
</p><!-- l. 1079 --><p class='indent'>   \begin {equation}  \label {eqn:min_hold_clk_skew} T_{c-q, reg1} + T_{logic,min} \geq T_{hold, reg2} + T_{skew}  \end {equation}<a id='x1-38004r29'></a>
</p><!-- l. 1081 --><p class='indent'>   In case of a negative clk skew, eqn <a href='#x1-38004r29'>29<!-- tex4ht:ref: eqn:min_hold_clk_skew  --></a> holds unconditionally (since the clk edge arrives before the data is settled at the
input of register 2). In case of a positive clk skew, we need to ensure eqn <a href='#x1-38003r28'>28<!-- tex4ht:ref: eqn:max_clk_ff_clk_skew  --></a> is held true.
</p><!-- l. 1083 --><p class='indent'>   [<a id='x1-38005'></a><a href='#cite.0_rabaey_digital_1996'>11</a>] suggests routing in opposite direction (introducing negative clk skew) to avoid disasters - but what does this mean
in physical layout?
</p><!-- l. 1086 --><p class='indent'>   Clock jitter refers to the temporal variation of the clock period at a given point — that is, the clock period can reduce or
expand on a cycle-by-cycle basis. It is strictly a temporal uncertainty measure and is often specified at a given point
on the chip [<a href='#cite.0_rabaey_digital_1996'>11</a>]. Figure <a href='#left-jitter-right-clk-jitter-clk-skew-example'>36<!-- tex4ht:ref: fig:jitter_ex  --></a> shows how the temporal uncertainty in the clk can affect timing in sequential
ckts.
</p>
   <figure class='figure' id='x1-3800636'><span id='left-jitter-right-clk-jitter-clk-skew-example'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1094 --><p class='noindent'><img alt='PIC' height='250' src='images/jitter_ex2.png' width='250' /><img alt='PIC' height='250' src='images/jitter_ex.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 36: </span><span class='content'>(Left) Jitter. (Right) Clk jitter + clk skew example</span></figcaption><!-- tex4ht:label?: x1-3800636  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1099 --><p class='indent'>   From figure <a href='#left-jitter-right-clk-jitter-clk-skew-example'>36<!-- tex4ht:ref: fig:jitter_ex  --></a>, we see that the clk has effectively shrunk by \(2*T_{j}\) (worst case). The delays from the clk-q of register 1, the
max delay from the combinational logic, and the delay from the setup time constraint of register 2, have
lesser time to work with. Assuming the clocks to both registers have the same jitter, we can rewrite eqn
<a href='#x1-37011r26'>26<!-- tex4ht:ref: eqn:max_clk_ff_no_skew  --></a>
</p><!-- l. 1106 --><p class='indent'>   \begin {equation}  \label {eqn:max_clk_ff_clk_jitter} T_{clk} - 2T_{j} \geq T_{c-q, reg1} + T_{logic,max} + T_{su, reg2}  \end {equation}<a id='x1-38007r30'></a>
</p><!-- l. 1108 --><p class='indent'>   In case of hold time, in the worst case, jitter can delay the clk at the second register and speed it up a the first register
(edge 1 to edge 6 in figure <a href='#left-jitter-right-clk-jitter-clk-skew-example'>36<!-- tex4ht:ref: fig:jitter_ex  --></a>). Similar to clk skew, we can rewrite eqn <a href='#x1-37012r27'>27<!-- tex4ht:ref: eqn:min_hold_no_skew  --></a> as follows
</p><!-- l. 1113 --><p class='indent'>   \begin {equation}  \label {eqn:min_hold_clk_jitter2} T_{c-q, reg1} + T_{logic,min} \geq T_{hold, reg2} + 2T_{j}  \end {equation}<a id='x1-38008r31'></a>
</p><!-- l. 1115 --><p class='indent'>   We can now combine the eqns for both clk skew and jitter to arrive at the following
</p>
   <div class='tcolorbox tcolorbox' id='tcolobox-2'>     
<div class='tcolorbox-title'>
   </div> 
<div class='tcolorbox-content'><!-- l. 1124 --><p class='noindent'>\begin {equation}  \label {eqn:max_clk_ff_clk_skew_jitter} T_{clk} +T_{skew} - 2T_{j} \geq T_{c-q, reg1} + T_{logic,max} + T_{su, reg2}  \end {equation}<a id='x1-38009r32'></a>
</p><!-- l. 1129 --><p class='noindent'>\begin {equation}  \label {eqn:min_hold_clk_jitter} T_{c-q, reg1} + T_{logic,min} \geq T_{hold, reg2} + T_{skew} + 2T_{j}  \end {equation}<a id='x1-38010r33'></a>
</p>
 
</div> 
</div>
<!-- l. 1133 --><p class='indent'>   Tips to deal with clk skew and jitter [<a id='x1-38011'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-38013x1'>To minimize skew, have a balanced clk tree. When using routed clock trees, the effective clock load of each
     path that includes wiring as well as transistor loads must be equalized
     </li>
<li class='enumerate' id='x1-38015x2'>The use of local clock grids (instead of routed trees) can reduce skew at the cost of increased capacitive load
     and power dissipation.
     </li>
<li class='enumerate' id='x1-38017x3'>If  data  dependent  clock  load  variations  causes  significant  jitter,  differential  registers  that  have  a  data
     independent clock load should be used - what does this mean?
     </li>
<li class='enumerate' id='x1-38019x4'>If data flows in one direction, route data and clock in opposite directions. This elminates races at the cost of
     perfomance.
     </li>
<li class='enumerate' id='x1-38021x5'>Avoid data dependent noise by shielding clock wires from adjacent signal wires.
     </li>
<li class='enumerate' id='x1-38023x6'>Dummy fills are very common and reduce skew by increasing uniformity. Systematic variations should be
     modeled and compensated for.
                                                                                               
                                                                                               
     </li>
<li class='enumerate' id='x1-38025x7'>Power supply variation is a significant component of jitter as it impacts the cycle to cycle delay through clock
     buffers. High frequency power supply variation can be reduced by addition of on-chip decoupling capacitors
</li></ol>
   <h4 class='subsectionHead' id='race-conditions'><span class='titlemark'>3.4   </span> <a id='x1-390003.4'></a>Race conditions</h4>
<!-- l. 1161 --><p class='noindent'>Race conditions refer to a general class of timing failures that occur because of a “race” between the clock and the input (or
an enable and an input) signals. Let us take an example of a MUX-based register as shown in figure <a href='#example-of-a-race-condition-in-a-muxbased-register'>37<!-- tex4ht:ref: fig:race_condition_ex1  --></a>. When there is an
overlap between clk and its complement, there is a direct path from D to Q - which is not desirable at any state of
operation for a register. We’d ideally want a clear demarcation between sample/hold phase and output driving phase. In
this case, however, the output is dependent of whether the input arrived before or after \(\bar {CLK}\) - there is a race between D and \(\bar {CLK}\)
that decides \(Q\).
</p>
   <figure class='figure' id='x1-3900137'><span id='example-of-a-race-condition-in-a-muxbased-register'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1169 --><p class='noindent'><img alt='PIC' height='250' src='images/race_condition_ex1.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 37: </span><span class='content'>Example of a race condition in a MUX-based register</span></figcaption><!-- tex4ht:label?: x1-3900137  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1174 --><p class='indent'>   This is an example of a race condition. MUX-based registers suffer from this issue. One way to fix is this is to create two
non-overlapping clk phases.
</p>
   <h4 class='subsectionHead' id='latch-timing'><span class='titlemark'>3.5   </span> <a id='x1-400003.5'></a>Latch timing</h4>
<!-- l. 1189 --><p class='noindent'>If a logic block finishes before the clock period, it has to idle till the next input is latched in on the next system clock edge
[<a id='x1-40001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. To make the best use of the latch-based system, we need a two-phase clk. Figure <a href='#basic-idea-behind-a-latchbased-design'>38<!-- tex4ht:ref: fig:latch_time_concept  --></a> demonstrates an example with all
latches.
</p>
   <figure class='figure' id='x1-4000238'><span id='basic-idea-behind-a-latchbased-design'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1194 --><p class='noindent'><img alt='PIC' height='250' src='images/latch_time_concept.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 38: </span><span class='content'>Basic idea behind a latch-based design</span></figcaption><!-- tex4ht:label?: x1-4000238  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1199 --><p class='indent'>   In a register-based system, once the computation of the combinational block between two registers is done with the
computation, it sits idle until the next clk edge (pos or neg). In a latch, however, we don’t have to wait to pass on the result
of the computation to the next stage - we can send it as long as the clk is high (or low). This lets us increase the length of
the critical path, or conversely, make the clock faster!
</p><!-- l. 1204 --><p class='indent'>   Before we dive deeper into this idea, let us first examine how to define setup time and hold time. Let us say we have a
positive latch. The falling edge is the latching edge for such a latch. Therefore, setup time is the time before the latching
edge (falling edge in this case) by which the data input must be stable. Similarly, for some implementations of the latch, the
data must be held for certain time after the falling edge - which is called the hold time. Some implementations have a hold
time of zero. Figure <a href='#setup-and-hold-time-for-a-positive-level-sensitive-latch-technicalbytessetupholdlatch'>39<!-- tex4ht:ref: fig:setup_hold_latch_basics  --></a> demonstrates these ideas.
</p>
   <figure class='figure' id='x1-4000339'><span id='setup-and-hold-time-for-a-positive-level-sensitive-latch-technicalbytessetupholdlatch'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1213 --><p class='noindent'><img alt='PIC' height='250' src='images/setup_hold_latch_basics.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 39: </span><span class='content'>Setup and hold time for a positive level sensitive latch [<a id='x1-40004'></a><a href='#cite.0_technicalbytes_setup_hold_latch_2020'>3</a>]</span></figcaption><!-- tex4ht:label?: x1-4000339  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='slack-passingtime-borrowing'><span class='titlemark'>3.6   </span> <a id='x1-410003.6'></a>Slack passing/Time borrowing</h4>
<!-- l. 1220 --><p class='noindent'>Let us take HW3 Problem 3 from EECS251B (2025) to understand slack passing or time borrowing. In figure <a href='#slack-borrowing-example-problem'>40<!-- tex4ht:ref: fig:slack_borrowing_ex  --></a>, the
combinational block A has a \(t_{pd,A}\) of 2 ns and B has a \(t_{pd,A}\) of 1 ns. For simplicity, setup and hold times for the registers (or latches is
zero) but the clk-q delay is 0.1 ns.
</p>
   <figure class='figure' id='x1-4100140'><span id='slack-borrowing-example-problem'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1226 --><p class='noindent'><img alt='PIC' height='250' src='images/slack_borrowing_ex.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 40: </span><span class='content'>Slack borrowing example problem</span></figcaption><!-- tex4ht:label?: x1-4100140  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1231 --><p class='indent'>   In case where all the 3 sequential blocks are positive edge triggered registers, the max clk frequency is dictated by the
critical path which includes block A.
</p><!-- l. 1233 --><p class='indent'>   \[T_{clk} \geq T_{clk-Q,R1} + T_{pd,A}\]
</p><!-- l. 1235 --><p class='indent'>   Let us replace the middle register with a positive level sensitive latch. For a positive latch, the latching edge is the falling
edge of the clk. Therefore, combinational block A now has additional half cycle to finsih processing. whaterver slack is left
from this 1.5 clk cycles is simply passed on to the next block since the data can be passed immediately after conmputation
(as long as it is done before the latching edge). B still needs to be done at the rising edge of the third clk
cycle.
</p>
   <figure class='figure' id='x1-4100241'><span id='slack-borrowing-example-problem-analysis'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1242 --><p class='noindent'><img alt='PIC' height='250' src='images/slack_borrowing_hw.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 41: </span><span class='content'>Slack borrowing example problem - analysis</span></figcaption><!-- tex4ht:label?: x1-4100241  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1248 --><p class='indent'>   As show in figure <a href='#slack-borrowing-example-problem-analysis'>41<!-- tex4ht:ref: fig:slack_borrowing_hw  --></a>, we can now calculate the max clk frequency as follows
</p><!-- l. 1250 --><p class='indent'>   \[1.5 T_{clk} \geq T_{clk-Q,R1} + T_{pd,A}\] \[2 T_{clk} \geq T_{clk-Q,R1} + T_{clk-Q,L} + T_{pd,A} + T_{pd,B}\]
</p><!-- l. 1253 --><p class='indent'>   Essentially, we exploited the fact that the critical path can take longer to finish computation than 1 clk cycle and this is
what lets us run a faster clk than in the case of a flip-flop-only system. We note two things here, since block A is the critical
path here, we use a positive level sensitive latch. If block B were the critical path, since we need to give that block
additional time to finish, we replace the middle register with a negative latch so that block A can be done within \(0.5 T_{clk}\) and the
other \(1.5 T_{clk}\) can be taken up by the critical path. Along the same lines, the replacement wouldn’t have worked if for
the same setup as in figure <a href='#slack-borrowing-example-problem'>40<!-- tex4ht:ref: fig:slack_borrowing_ex  --></a>, if we used a negative latch in the middle. We can no longer borrow/pass
time.
</p>
   <div class='tcolorbox tcolorbox' id='tcolobox-3'>     
<div class='tcolorbox-title'>
   </div> 
<div class='tcolorbox-content'><!-- l. 1260 --><p class='noindent'>Since critical path needs more time, we need to create conditions to let it take more time than \(T_{clk}\). This decides
the level-sensitivity of the latch. </p> 
</div> 
</div>
<!-- l. 1263 --><p class='indent'>   In a two-phase clk scheme, we give a guardband of \(t_{non-overlap}\) between the two clk phases and this eats into the time that can be
borrowed between stages.
</p>
   <h4 class='subsectionHead' id='ckts-in-feedback'><span class='titlemark'>3.7   </span> <a id='x1-420003.7'></a>Ckts in feedback</h4>
<!-- l. 1270 --><p class='noindent'>Loops may borrow time internally, but the entire computation must be finished within the allocated cycle [<a id='x1-42001'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. Figure <a href='#time-borrowing-in-feedback-vs-openloop'>42<!-- tex4ht:ref: fig:time_borrow_loop1  --></a>
shows a self-bypass loop where time bororwing can happen internally across the half cycles but the entire path must fit in
one clk cycle. Most critical paths occur in such loops - example ALU in a pipelined processor finishes a computation and
then sends the result back to itself before the next operation.
</p>
   <figure class='figure' id='x1-4200242'><span id='time-borrowing-in-feedback-vs-openloop'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1278 --><p class='noindent'><img alt='PIC' height='250' src='images/loops_latch_timing1.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 42: </span><span class='content'>Time borrowing in feedback vs open-loop</span></figcaption><!-- tex4ht:label?: x1-4200242  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1285 --><p class='indent'>   I couldn’t find a lot of notes for this but [<a id='x1-42003'></a><a href='#cite.0_weste_cmos_2011'>15</a>] has some excercise problems on this.
</p>
   <h4 class='subsectionHead' id='selftimed-logic'><span class='titlemark'>3.8   </span> <a id='x1-430003.8'></a>Self-timed logic</h4>
<!-- l. 1290 --><p class='noindent'>Say each combinational block in the pipeline starts the computation when a “START” signal is asserted and can asset a
“DONE” flag when it’s done with the computation. We also assume that there is a “ready-valid” interface between
the different blocks in the timeline so that each block knows when to pick the right data or when to signal
that it is available to read new data. We can implement a self-timed logic-based pipeline as shown in figure
<a href='#selftimed-logic1'>43<!-- tex4ht:ref: fig:self-timed_logic  --></a>.
</p>
   <figure class='figure' id='x1-4300143'><span id='selftimed-logic1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1296 --><p class='noindent'><img alt='PIC' height='150' src='images/self_timed_logic.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 43: </span><span class='content'>Self-timed logic</span></figcaption><!-- tex4ht:label?: x1-4300143  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1301 --><p class='indent'>   Let’s go through how this works
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-43003x1'>When an input arrives, a request (valid) signal is asserted to F1. If F1 is free, it raises an acknowledge (ready)
     signal and the input is transferred from R1 (which could be a FIFO or a buffer of some sort) to F1.
     </li>
<li class='enumerate' id='x1-43005x2'>F1 is then enable by a start signal. Once the computation is done, F1 asserts a done signal.
     </li>
<li class='enumerate' id='x1-43007x3'>A request (valid) signal is then sent to F2 by the handshaking module and the cycle continues.</li></ol>
<!-- l. 1310 --><p class='indent'>   This is essentially a ready-valid interface. It’s advantages over synchronous logic includes
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-43009x1'>Synchronous systems run at the clk frequency that is determined by the worst delay between two registers.
     Self-timed logic, on the other hand, runs at the <span class='cmti-10'>average </span>of delays of all blocks. This can be a substantial boost
     in case of massive ripple adders where the average delay scales \(O(\log N)\) but the worst case delay scales \(O(N)\).
     </li>
<li class='enumerate' id='x1-43011x2'>When not in use, some blocks are shut down automatically which results in power savings.
     </li>
<li class='enumerate' id='x1-43013x3'>Self-timed circuits are more robust to PVT variations since they don’t depend on a global clock distribution.</li></ol>
   <h5 class='subsubsectionHead' id='generating-the-done-signal'><span class='titlemark'>3.8.1   </span> <a id='x1-440003.8.1'></a>Generating the done signal</h5>
<!-- l. 1323 --><p class='noindent'>Here are two ways of generating the done signal
</p><!-- l. 1325 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-44002x1'>
     <!-- l. 1326 --><p class='noindent'>Dual-rail coding: In this approach, we use two bits to indicate if the block is in transition/reset, not done, or
     done. As shown on the left in figure <a href='#left-dualrail-coding-scheme-right-example-of-a-differential-ckt-implementing-the-scheme'>44<!-- tex4ht:ref: fig:dual_rail_coding  --></a>, the state 00 refers to when the combinational block is still
     computing or being reset. Both 01 and 10 can signal a done. This is achieved using a differential ckt shown
     in the same figure. When start is low, the PMOS devices pull up the input of the inverters, resulting in the
     00 state. When the inputs to the combinational block are asserted along with the start signal, one of the two
     pull-down networks evaluates to a high and pulls one of the bits down. This raises the done flag. </p><figure class='figure' id='x1-4400344'><span id='left-dualrail-coding-scheme-right-example-of-a-differential-ckt-implementing-the-scheme'></span> 
 <img alt='PIC' height='150' src='images/dual_coding1.png' width='150' /><img alt='PIC' height='150' src='images/dual_coding2.png' width='150' />
                                                                                               
                                                                                               
<figcaption class='caption'><span class='id'>Figure 44: </span><span class='content'>(Left) Dual-rail coding scheme (Right) Example of a differential ckt implementing the scheme</span></figcaption><!-- tex4ht:label?: x1-4400344  -->
     </figure>
     <!-- l. 1338 --><p class='noindent'>[<a id='x1-44004'></a><a href='#cite.0_rabaey_digital_1996'>11</a>] tells us that the done signal generation is done in series with the combinational block (how?), so the delays
     are added. Note that for an N-bit input, the PDN now has to evaluate all the N-bits to a single bit
     output.
     </p></li>
<li class='enumerate' id='x1-44006x2'>
     <!-- l. 1341 --><p class='noindent'>Replica delay: As the length of the input scales, so does the area and power consumption in the dual-rail coding
     system. In replica delay approach, we simply replicate the delay of the critcical path of the combinational
     block.
</p>
     <figure class='figure' id='x1-4400745'><span id='replica-delay'></span> 
 <img alt='PIC' height='150' src='images/replica_delay.png' width='150' />
<figcaption class='caption'><span class='id'>Figure 45: </span><span class='content'>Replica delay</span></figcaption><!-- tex4ht:label?: x1-4400745  -->
     </figure>
     <!-- l. 1351 --><p class='noindent'>As shown in figure <a href='#replica-delay'>45<!-- tex4ht:ref: fig:replica_delay  --></a>, the start signal is given in parallel to the logic network and the delay module. The delay
     module, irrespective of the inputs, gives the done signal after the worst delay of the logic block. This is a disadvantage
     of this scheme.
     </p></li>
<li class='enumerate' id='x1-44009x3'>
     <!-- l. 1353 --><p class='noindent'>Current sensing: We would ideally like to implement no redundancies (which is the case with the dual-rail coding) and
     generate the done signal with the delay that depends on the input (as opposed to naively the worst case in replica
     delay).
</p>
     <figure class='figure' id='x1-4401046'><span id='generating-done-signal-with-a-current-sensor-that-measures-the-activity-of-the-logic-network'></span> 
 <img alt='PIC' height='150' src='images/current_sensing.png' width='150' />
<figcaption class='caption'><span class='id'>Figure 46: </span><span class='content'>Generating done signal with a current sensor that measures the activity of the logic network</span></figcaption><!-- tex4ht:label?: x1-4401046  -->
     </figure>
     <!-- l. 1363 --><p class='noindent'>In figure <a href='#generating-done-signal-with-a-current-sensor-that-measures-the-activity-of-the-logic-network'>46<!-- tex4ht:ref: fig:current_sensing  --></a>, we implement an analog current sensor to measure the current in the logic block and output a low signal
     if there is no current consumed, or a high signal when the computation is still running. In essence, we get the duration
     of the computation. In case that the inputs do not change for the next cycle, no current is drawn for a static CMOS
     logic - hence, we use a minimum delay generator to handle this case. The current sensor requires careful design to be
     PVT tolerant.
</p>
     </li></ol>
<!-- l. 1371 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='selftimed-signaling'><span class='titlemark'>3.8.2   </span> <a id='x1-450003.8.2'></a>Self-timed signaling</h5>
<!-- l. 1373 --><p class='noindent'>Besides the generation of the completion signals, a self-timed approach also requires a handshaking protocol to logically
order the circuit events avoiding races and hazards. Figure <a href='#handshake-protocol-example'>47<!-- tex4ht:ref: fig:handshake_protocol  --></a> shows a two-phase protocol implemented for a self-timed
logic. The sender loads the data, and generates an event (either a high-to-low or low-to-high transition) on the Req line.
When the receiver is ready, it generates an event on the Ack line. Data is now transferred from the sender to the receiver.
Note that once a req event is generated, the sender can no longer change the data it was holding on the data line. Similarly,
the receiver can only receive data on its active cycle (which starts after generating an event on the Ack line), This
example is a two-phase protocol since only two distinct phases exist - either the sender is active or the receiver.
</p><figure class='figure' id='x1-4500147'><span id='handshake-protocol-example'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1380 --><p class='noindent'><img alt='PIC' height='150' src='images/self_timed_logic_sig_gen.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 47: </span><span class='content'>Handshake protocol example</span></figcaption><!-- tex4ht:label?: x1-4500147  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1385 --><p class='indent'>   An essential component of any handshake protocol is the Muller C-element [<a id='x1-45002'></a><a href='#cite.0_grokipedia_celement'>16</a>]. In his Turing Award lecture
in 1989, Sutherland describes the Muller C-element as an AND element for “events” [<a id='x1-45003'></a><a href='#cite.0_10.1145_63526.63532'>13</a>]. In the standard
C-element, if both the inputs are the same, they are copied to the output. If one of the two inputs is different, the
output retains the previous state. Figure <a href='#left-behavior-of-different-styles-of-the-muller-celement-right-some-implementations'>48<!-- tex4ht:ref: fig:muller_c_element  --></a> shows the other combinations that can be implemented using
inverters.
</p>
   <figure class='figure' id='x1-4500448'><span id='left-behavior-of-different-styles-of-the-muller-celement-right-some-implementations'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1391 --><p class='noindent'><img alt='PIC' height='150' src='images/muller_c_element_inverters.png' width='150' /><img alt='PIC' height='250' src='images/muller_c_element_implementations.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 48: </span><span class='content'>(Left) Behavior of different styles of the Muller C-element [<a id='x1-45005'></a><a href='#cite.0_10.1145_63526.63532'>13</a>] (Right) Some implementations</span></figcaption><!-- tex4ht:label?: x1-4500448  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1396 --><p class='indent'>   How does this relate to “events”? Let’s take the example of the standard C-element (no inversions). Say initially both
the inputs are zero, so the output is zero too. When one of the input changes state, we hold the output - this could be the
Req signal generating an event. We cannot send the data until the receiver generates an event on the Ack line. When an
event is generated on the Ack line, both the inputs match and the output copies them. The truth table is shown in table <a href='#truth-table-of-the-standard-muller-celement'>3<!-- tex4ht:ref: tab:muller_c_element_tt  --></a>.
Since it looks very similar to an SR-latch, one of the ways to implement it is using an SR-latch as shown in figure <a href='#left-behavior-of-different-styles-of-the-muller-celement-right-some-implementations'>48<!-- tex4ht:ref: fig:muller_c_element  --></a>. Unlike
the SR-latch, there is no forbidden state and there is no differentiation between set and reset - both are treated the
same.
</p>
   <div class='table'>
                                                                                               
                                                                                               
<!-- l. 1402 --><p class='indent' id='truth-table-of-the-standard-muller-celement'>   <a id='x1-450063'></a></p><figure class='float'>
                                                                                               
                                                                                               
<figcaption class='caption'><span class='id'>Table 3: </span><span class='content'>Truth table of the standard Muller C-element</span></figcaption><!-- tex4ht:label?: x1-450063  -->
<div class='tabular'> <table class='tabular' id='TBL-4'><colgroup id='TBL-4-1g'><col id='TBL-4-1' /><col id='TBL-4-2' /></colgroup><colgroup id='TBL-4-3g'><col id='TBL-4-3' /></colgroup><tr id='TBL-4-1-' style='vertical-align:baseline;'><td class='td11' id='TBL-4-1-1' style='white-space:nowrap; text-align:center;'>\(A\)</td><td class='td11' id='TBL-4-1-2' style='white-space:nowrap; text-align:center;'>\(B\)</td><td class='td11' id='TBL-4-1-3' style='white-space:nowrap; text-align:center;'>\(F_{n+1}\)</td></tr><tr class='hline'><td></td><td></td><td></td></tr><tr id='TBL-4-2-' style='vertical-align:baseline;'><td class='td11' id='TBL-4-2-1' style='white-space:nowrap; text-align:center;'>0</td><td class='td11' id='TBL-4-2-2' style='white-space:nowrap; text-align:center;'>0</td><td class='td11' id='TBL-4-2-3' style='white-space:nowrap; text-align:center;'>0</td>
</tr><tr id='TBL-4-3-' style='vertical-align:baseline;'><td class='td11' id='TBL-4-3-1' style='white-space:nowrap; text-align:center;'>0</td><td class='td11' id='TBL-4-3-2' style='white-space:nowrap; text-align:center;'>1</td><td class='td11' id='TBL-4-3-3' style='white-space:nowrap; text-align:center;'>\(F_{n}\)</td>
</tr><tr id='TBL-4-4-' style='vertical-align:baseline;'><td class='td11' id='TBL-4-4-1' style='white-space:nowrap; text-align:center;'>1</td><td class='td11' id='TBL-4-4-2' style='white-space:nowrap; text-align:center;'>0</td><td class='td11' id='TBL-4-4-3' style='white-space:nowrap; text-align:center;'>\(F_{n}\)</td>
</tr><tr id='TBL-4-5-' style='vertical-align:baseline;'><td class='td11' id='TBL-4-5-1' style='white-space:nowrap; text-align:center;'>1</td><td class='td11' id='TBL-4-5-2' style='white-space:nowrap; text-align:center;'>1</td><td class='td11' id='TBL-4-5-3' style='white-space:nowrap; text-align:center;'>1</td></tr></table>                                                                                      </div>
                                                                                               
                                                                                               
   </figure>
   </div>
<!-- l. 1416 --><p class='indent'>   Note that since the tranisition direction is important for what flavor of Muller C-element we want to pick from figure <a href='#left-behavior-of-different-styles-of-the-muller-celement-right-some-implementations'>48<!-- tex4ht:ref: fig:muller_c_element  --></a>.
This also means that the initial states should be assigned appropriately otherwise the ckt enters deadlock and we
are permanently blocked from doing anything [<a id='x1-45007'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. This is one of the drawbacks of the two-phase signaling
scheme.
</p><!-- l. 1420 --><p class='indent'>   An alternative approach is to use a four-phase signaling or a return-to-zero (RTZ) scheme. This class of signaling
requires that all controlling signals be brought back to their initial values before the next cycle can be initiated. This is
illustrated in figure <a href='#rtz-scheme'>49<!-- tex4ht:ref: fig:rtz_scheme  --></a>.
</p>
   <figure class='figure' id='x1-4500849'><span id='rtz-scheme'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1425 --><p class='noindent'><img alt='PIC' height='150' src='images/handshake_4p.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 49: </span><span class='content'>RTZ scheme</span></figcaption><!-- tex4ht:label?: x1-4500849  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1430 --><p class='indent'>   The first two phases are similar to the two-phase scheme in figure <a href='#handshake-protocol-example'>47<!-- tex4ht:ref: fig:handshake_protocol  --></a>. However, once the Ack line is asserted, the sender
cannot send the data until both Ack and Req lines are brought back to their original states. This is the primary difference
between the two protocols. The main advantage here is that the directionality of the event (high-to-low or low-to-high)
doesn’t need to be handled by the logic block or the C-element. In the two-phase case, this was necessary and necessiated
the user to set the right initial states to avoid deadlock. In the RTZ protocol, since we always return to the initial state, we
don’t worry about the directionality of the event. In fact, we just care about the high or low levels and not the events
themselves - which makes it similar to how static CMOS is implemented. The drawback is that the RTZ scheme is
slower.
</p>
   <h5 class='subsubsectionHead' id='examples-where-selftimed-logic-is-useful'><span class='titlemark'>3.8.3   </span> <a id='x1-460003.8.3'></a>Examples where self-timed logic is useful</h5>
<!-- l. 1439 --><p class='noindent'>Here are some examples listed in [<a id='x1-46001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]
</p><!-- l. 1441 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-46003x1'>Glitch reduction
     </li>
<li class='enumerate' id='x1-46005x2'>Clock-delayed Domino ckts</li></ol>
<!-- l. 1448 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='synchronizers'><span class='titlemark'>3.9   </span> <a id='x1-470003.9'></a>Synchronizers</h4>
<!-- l. 1450 --><p class='noindent'>Say you have an asynchronous system, like a keyboard, that is sending data at no fixed phase relation w.r.t. the clk of a
synchronous system, like a laptop. The laptop can continuously poll the keyboard at a given frequency to capture the data
the keyboard is sending but depending on this polling rate, the clk frequency, and rise/fall times of the signal, the data sent
by the keyboard could end up in the forbidden state - between \(V_{IH}\) and \(V_{IL}\). We cannot reliably decipher if the keyboard sent a 1
or a 0. An asynchronous signal must be resolved to be either high or low before sending it to a synchronous system. It
doesn’t matter which, even if the keyboard sent a 1 but we decided it was a zero, it is okay as long as the keyboard is polled
again and the decision we make for is consistent when the signal is in in the forbidden state. This decision is made by the
synchronizer.
</p><!-- l. 1456 --><p class='indent'>   It’s been shown that a perfect synchronizer that always delivers a legal answer is impossible [<a href='#cite.0_rabaey_digital_1996'>11</a>]. We can reduce the
synchronization failures by waiting for longer before polling the signal from the asynchronous system. The higher the
sampling rate on the synchronous side, the higher the chance that we might sample metastable voltages or forbidden states.
We call these synchronization errors. The number of errors per second as a function of the wait time can be estimated by
eqn <a href='#x1-47001r34'>34<!-- tex4ht:ref: eqn:sync_error_rate  --></a>
</p><!-- l. 1463 --><p class='indent'>   \begin {equation}  \label {eqn:sync_error_rate} N_{sync}(T) = \frac {(V_{IH}-V_{IL})\exp (-T/\tau )}{V_{swing}}\frac {t_r}{T_{sig}T_\phi }  \end {equation}<a id='x1-47001r34'></a>
</p><!-- l. 1465 --><p class='indent'>   where \(T\) is the wait time, \(V_{swing}\) is the rail-to-rail output value, \(\tau \) is a time constant that is dependent on the strength of the
transistors and their parasitc capacitances, \(T_{sig}\) is the period of the asynchronous signal, and \(T_\phi \) is the sampling period or the
synchronous system’s clk. It is clear from eqn <a href='#x1-47001r34'>34<!-- tex4ht:ref: eqn:sync_error_rate  --></a> that increasing the wait time, \(T\), exponentially decreases the number of
synchronization errors. Therefore, waiting for longer before sampling the asynchronous data can help decrease the error
                                                                                               
                                                                                               
rate. Instead of decreasing the clk frequency, this is achieved by adding delay by cascading multiple synchronizers. This
way the total wait time before the asynchronous signal is sampled is the sum of the delays through all the
synchronizers.
</p><!-- l. 1471 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='metastability'><span class='titlemark'>3.9.1   </span> <a id='x1-480003.9.1'></a>Metastability</h5>
<!-- l. 1473 --><p class='noindent'>The solution space of the cross-coupled inverters has to obey A=B (loop gain). There is a metastable state apart from 0 and
1 that satisfies this condition as seen in figure <a href='#left-hold-stability-right-read-stability'>97<!-- tex4ht:ref: fig:hold_read_stability  --></a>. The metastable state falls in an invalid logic level. If the input changes
during the aperture time (setup+hold time), the output remains at the metastable state before falling to either a 0 or 1
after a certain time. This time is driven by the RC time constant of the inverters and the loop gain at the metastable point
(the xtors are in saturation here). [<a id='x1-48001'></a><a href='#cite.0_weste_cmos_2011'>15</a>] shows that the wait time for the metastable state to drop to one of the two logic
levels increases exponentially with this decreasing loop gain. The feedback latch should have high GBW to resolve
metastability quickly.
</p><!-- l. 1479 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='a-simple-synchronizer'><span class='titlemark'>3.9.2   </span> <a id='x1-490003.9.2'></a>A simple synchronizer</h5>
<!-- l. 1481 --><p class='noindent'>A simple synchronizer is shown in figure <a href='#simple-synchronizer'>50<!-- tex4ht:ref: fig:simple_synchronizer  --></a>. The idea is that if the data arrives during the aperture period (say
with a setup time violation) at F1, despite the intermediate node X being metastable, we can guarantee
to a certain extent that the metastability will resolve before the setup time of F2. There will still be some
synchronization errors since we cannot guarantee that metastability will resolve within the next clk cycle
always.
</p>
   <figure class='figure' id='x1-4900150'><span id='simple-synchronizer'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1487 --><p class='noindent'><img alt='PIC' height='250' src='images/simple_synchronizer.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 50: </span><span class='content'>Simple synchronizer</span></figcaption><!-- tex4ht:label?: x1-4900150  -->
                                                                                               
                                                                                               
   </figure>
   <h5 class='subsubsectionHead' id='gray-codes'><span class='titlemark'>3.9.3   </span> <a id='x1-500003.9.3'></a>Gray codes</h5>
<!-- l. 1495 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='synchronizer-pitfalls'><span class='titlemark'>3.9.4   </span> <a id='x1-510003.9.4'></a>Synchronizer pitfalls</h5>
<!-- l. 1497 --><p class='noindent'>[<a id='x1-51001'></a><a href='#cite.0_weste_cmos_2011'>15</a>] lists a few common pitfalls -
</p><!-- l. 1499 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-51003x1'>Failing to synchronize asynchronous inputs. Even when the clk on the receiver is slow, the propagation
     delay through the combinational logic depends on the input bits (and might, therefore, be longer than the
     contamination delay), which can cause metastability - this is especially more prevalent in multi-bit buses
     where some bits can change to the new values while the others remain in the older ones.
     </li>
<li class='enumerate' id='x1-51005x2'>Never drive two outputs with two synchronizers if you intend for both of these outputs to agree with each
     other. Each synchronizer can resolve the metastability differently and the outputs won’t agree with each other.
     </li>
<li class='enumerate' id='x1-51007x3'>Synchronizers must not accept multi-bit inputs especially when more than one bit can change at a time. Gray
     codes can help alleviate this issue (confirm).</li></ol>
<!-- l. 1506 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='arbiters'><span class='titlemark'>3.10   </span> <a id='x1-520003.10'></a>Arbiters</h4>
<!-- l. 1508 --><p class='noindent'>An arbiter is an element that decides which of the two events has occured first. A synchronizer is an arbiter with one of its
inputs tied to the clk of the synchronous system. A mutual-exclusion circuit is an example where two request signals
are taken as input and depending on which arrived first, the corresponding acknowledge signal is asserted
high.
</p>
   <figure class='figure' id='x1-5200151'><span id='example-of-an-arbiter'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1514 --><p class='noindent'><img alt='PIC' height='250' src='images/arbiter_mutual_exclusion.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 51: </span><span class='content'>Example of an arbiter</span></figcaption><!-- tex4ht:label?: x1-5200151  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1519 --><p class='indent'>   In figure <a href='#example-of-an-arbiter'>51<!-- tex4ht:ref: fig:arbiter_ex1  --></a>, depending on which request arrives first, the cross-coupled NAND gates (similar to an SR-latch)
assert one of the two nodes A or B. Since A and B nodes are the rails for the inverters driving the outputs,
when one of them is asserted, the other inverter is shut down and the PMOS is always asserted to pull the
corresponding acknowledge signal high. In the special case where both the request signals go high at the same
time and the nodes A and B are metastable, the cross-coupled structure makes sure that the output is low
until the metastability evolves such that the nodes A/B are a threshold voltage apart. This is shown in the
timing diagram in the same figure. The 4-xtor structure that follows the cross-coupled SR-latch in figure
<a href='#example-of-an-arbiter'>51<!-- tex4ht:ref: fig:arbiter_ex1  --></a> is also known as a metastability filter [<a id='x1-52002'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. The output is never metasable but can take an arbitrarily
long time - therefore, a synchronizer is needed before feeding the output of the arbiter to a synchronous
system.
</p><!-- l. 1526 --><p class='indent'>   Note that since the request is not synchronized with F2’s clk, we need a synchronizer as shown in figure <a href='#simple-synchronizer'>50<!-- tex4ht:ref: fig:simple_synchronizer  --></a> on the
request’s input at F2. Similarly, the acknowledge input at F1 needs a synchronizer. This is shown in figure
<a href='#another-example-of-an-arbiter'>52<!-- tex4ht:ref: fig:arbiter_ex2  --></a>.
</p>
   <figure class='figure' id='x1-5200352'><span id='another-example-of-an-arbiter'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1532 --><p class='noindent'><img alt='PIC' height='200' src='images/arbiter_sync.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 52: </span><span class='content'>Another example of an arbiter</span></figcaption><!-- tex4ht:label?: x1-5200352  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='retiming'><span class='titlemark'>3.11   </span> <a id='x1-530003.11'></a>Retiming</h4>
<!-- l. 1549 --><p class='noindent'>Here is a link to Prof. John Wawrzynek’s offering of the class - <a href='https://inst.eecs.berkeley.edu/~eecs151/sp23/URL'>SP23</a>. Here’s his lecture on retiming - <a href='https://www.youtube.com/watch?v=q5449BSpIxE&amp;list=PLnocShPlK-FsKivv6BRWf3uHNquZbF-xD&amp;index=12URL'>link</a>. The idea of
retiming is to see if we can reduce the critical path between two registers without changing the functionality of the ckt. By
functionality, we mean that all the data outputs that were coming synchronously before (at a given clk edge) should come
out at the same clk edge. The number of clk cycles overall can increase (usually doesn’t decrease because we’re adding
registers) but at a given cross-section the wavefront of data needs to be the same as before (the data at each wire has to
arrive synchronously).
</p><!-- l. 1553 --><p class='indent'>   Let us take an example of figure <a href='#left-retiming-example-right-another-possible-solution-as-discussed-in-prof-wawrzyneks-class'>53<!-- tex4ht:ref: fig:retiming_ex1  --></a>. The top ckt has a critical path of 5 from the middle register to the output register.
If we move the middle register (we cannot move the output one cos the output needs to be stored in a register), because
there are are two fanout paths for the combinational logic, we need to insert 2 registers so that the functionality of the ckt
doesn’t change. This way, we’ve added 2 registers but haven’t changed teh latency of the ckt but decreases the critical path
by 20%. One interesting thing is that, we can get rid of one register by moving it through the combinational block and
then sizing the register to drive the fanout of 2 output paths. This alternate solution is also shown in figure
<a href='#left-retiming-example-right-another-possible-solution-as-discussed-in-prof-wawrzyneks-class'>53<!-- tex4ht:ref: fig:retiming_ex1  --></a>.
</p>
   <figure class='figure' id='x1-5300153'><span id='left-retiming-example-right-another-possible-solution-as-discussed-in-prof-wawrzyneks-class'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1560 --><p class='noindent'><img alt='PIC' height='150' src='images/retiming_ex1.png' width='150' /><img alt='PIC' height='150' src='images/retiming_ex1b.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 53: </span><span class='content'>(Left) Retiming example (Right) Another possible solution as discussed in Prof. Wawrzynek’s class</span></figcaption><!-- tex4ht:label?: x1-5300153  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1566 --><p class='indent'>   Another example of retiming involves a loop. We move through the logic gates and introduce registers at the inputs of
each gate as we move it from output to input. The NOR gate that sees the output of the feedback loop has a register in the
loop too. How to deal with this? If the register in the loop and the at input of the OR gate have the same initial conditions,
then essentially both have the same data at their D inputs at all times. We can combine them into a single register and
move the feedback to the Q node. This is illustrated in figure <a href='#working-through-the-retiming-example-in-case-of-a-loop'>54<!-- tex4ht:ref: fig:retiming_ex2  --></a>. Once we move it to the output of the NAND gate, we can
push it back further, giving two registers at its input. One of them essentially pops back into the feedback and the
other one shows up at the output of the XOR gate. This is the best we can do in terms of optimizing critical
paths.
</p>
   <figure class='figure' id='x1-5300254'><span id='working-through-the-retiming-example-in-case-of-a-loop'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1576 --><p class='noindent'><img alt='PIC' height='150' src='images/retiming_ex2.png' width='150' /><img alt='PIC' height='150' src='images/retiming_ex2b.png' width='150' /><img alt='PIC' height='150' src='images/retiming_ex2c.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 54: </span><span class='content'>Working through the retiming example in case of a loop</span></figcaption><!-- tex4ht:label?: x1-5300254  -->
                                                                                               
                                                                                               
   </figure>
                                                                                               
                                                                                               
   <h3 class='sectionHead' id='phase-locked-loops'><span class='titlemark'>4   </span> <a id='x1-540004'></a>Phase Locked Loops</h3>
<!-- l. 1587 --><p class='noindent'>Before we dive into PLLs, let’s look at a few other sequential circuits.
</p><!-- l. 1589 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='monstable-ckt'><span class='titlemark'>4.1   </span> <a id='x1-550004.1'></a>Monstable Ckt</h4>
<!-- l. 1591 --><p class='noindent'>A monostable ckt generates a pulse of predetermined width every time it gets triggered by a transtion event. It is called
monostable because the OFF state is the stable one. The trigger causes the ckt to temporarily go into a quasi-stable state
before returning to its stable state after a fixed delay.
</p>
   <figure class='figure' id='x1-5500155'><span id='ckt-to-generate-pulse-of-a-given-width-given-an-external-trigger'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1598 --><p class='noindent'><img alt='PIC' height='150' src='images/monstable_ckt.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 55: </span><span class='content'>Ckt to generate pulse of a given width given an external trigger</span></figcaption><!-- tex4ht:label?: x1-5500155  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1603 --><p class='indent'>   A common implementation of a monostable ckt is shown in figure <a href='#ckt-to-generate-pulse-of-a-given-width-given-an-external-trigger'>55<!-- tex4ht:ref: fig:monostable_ckt  --></a>. A XOR gate outputs low as long as the inputs are
identical. An external trigger passes a copy of itself through a delay block and the output is high as long as the delay \(t_d\)
introduced by the delay block - even if the trigger continues to be high after \(t_d\), the output switches back to low. The delay
can be made tunable with an RC network.
</p>
   <h4 class='subsectionHead' id='astable-ckts-oscillators'><span class='titlemark'>4.2   </span> <a id='x1-560004.2'></a>Astable ckts - Oscillators</h4>
<!-- l. 1608 --><p class='noindent'>An astable ckt has no stable state and oscillates back and forth between two quasi-stable state with a set
frequency.
</p><!-- l. 1610 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='ring-oscillator'><span class='titlemark'>4.2.1   </span> <a id='x1-570004.2.1'></a>Ring Oscillator</h5>
<!-- l. 1612 --><p class='noindent'>A ring oscillator is a circular chain of odd-numbered inverters. If the propagation delay through each inverter
is \(t_p\) and there are N inverters, the total period of the oscillations is \(2\times t_p \times N\). How do we control the frequency of
a ring oscillator? We can add tunable capacitors at the outputs of the inverters but that occupies a large
area.
</p>
   <figure class='figure' id='x1-5700156'><span id='left-currentstarved-inverters-to-make-the-ring-oscillator-a-vco-right-control-voltage-vs-delay'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1620 --><p class='noindent'><img alt='PIC' height='150' src='images/ro_current_starved.png' width='150' /><img alt='PIC' height='150' src='images/current_starved_delay.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 56: </span><span class='content'>(Left) Current-starved inverters to make the ring oscillator a VCO (Right) Control voltage vs delay</span></figcaption><!-- tex4ht:label?: x1-5700156  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1625 --><p class='indent'>   Figure <a href='#left-currentstarved-inverters-to-make-the-ring-oscillator-a-vco-right-control-voltage-vs-delay'>56<!-- tex4ht:ref: fig:ro_current_starved  --></a> shows a modification to the inverter used in the ring oscillator to make it a voltage-controlled oscillator
(VCO). The NMOS M3 can control the high-to-low transition by setting the max discharge current (similar to slew rate)
and therefore, lets us control the frequency of oscillation. To control the rise time, we can add a series PMOS transistor to
M2.
</p>
   <h5 class='subsubsectionHead' id='differential-vco'><span class='titlemark'>4.2.2   </span> <a id='x1-580004.2.2'></a>Differential VCO</h5>
<!-- l. 1631 --><p class='noindent'>We can use a differential amplifier in positive feedback to create an oscillator that can run with even number of stages (each
stage provides 90-degree phase shift). The frequency can be controlled by the tail current source. The differential VCO has
better common-mode noise rejection (like supply noise).
</p>
   <figure class='figure' id='x1-5800157'><span id='differential-vco1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1636 --><p class='noindent'><img alt='PIC' height='200' src='images/differential_vco.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 57: </span><span class='content'>Differential VCO</span></figcaption><!-- tex4ht:label?: x1-5800157  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='basic-concept-of-a-pll'><span class='titlemark'>4.3   </span> <a id='x1-590004.3'></a>Basic concept of a PLL</h4>
<!-- l. 1644 --><p class='noindent'>PLLs are used to generate frequencies of clk as a multiple of an incoming clk. They are also used to synchronize clks
between two chips if they share a single reference clk. A PLL can be represented with a block diagram shown in figure <a href='#block-diagram-of-a-pll'>58<!-- tex4ht:ref: fig:pll_block  --></a>. A
reference clk is generated off-chip (say a crystal oscillator), and is compared to the output of a VCO - which is the local clk
we send to the system. The comparison is done by a phase detector which compares if the local clk is leading
or lagging w.r.t the reference signal. A charge pump then generates an appropriate control signal to tune
the frequency of the VCO. The output control voltage of the charge pump can be jittery and is therefore,
smoothed out by a loop filter (which is a low-pass filter) before feeding it to the VCO. This reduces clock
jitter.
</p>
   <figure class='figure' id='x1-5900158'><span id='block-diagram-of-a-pll'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1652 --><p class='noindent'><img alt='PIC' height='200' src='images/pll_block_diagram.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 58: </span><span class='content'>Block diagram of a PLL</span></figcaption><!-- tex4ht:label?: x1-5900158  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1657 --><p class='indent'>   Lock range defines the range of input frequencies the PLL can maintain its functionality while lock time specifies the
time it takes for the PLL to lock onto a given signal input.
</p>
   <h5 class='subsubsectionHead' id='building-blocks-of-a-pll'><span class='titlemark'>4.3.1   </span> <a id='x1-600004.3.1'></a>Building blocks of a PLL</h5>
<!-- l. 1662 --><p class='noindent'>A VCO can be characterized as a ckt that produced a frequency that is a linear function of the control voltage.
</p><!-- l. 1664 --><p class='indent'>   \[\omega = \omega _0 + K_{VCO}V_{ctrl}\]
</p><!-- l. 1666 --><p class='indent'>   where \(K_{VCO}\) is the gain of the VCO (Hz/V) and \(\omega _0\) is a fixed frequency offset. Phase is just given by the time integral of
frequency - \[\Phi _{out} = \omega _0t + K_{VCO}\int _{-\inf }^{t}V_{ctrl}dt\]
</p><!-- l. 1669 --><p class='indent'>   and the output signal is a sinusoid with \(\omega _0\) as the frequency and \(\Phi _{out}\) as the phase.
</p><!-- l. 1671 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='phase-detector'><span class='titlemark'>4.3.2   </span> <a id='x1-610004.3.2'></a>Phase detector</h5>
<!-- l. 1673 --><p class='noindent'>A XOR gate is the simplest phase detector. Figure <a href='#xor-gate-as-a-phase-detector'>59<!-- tex4ht:ref: fig:xor_pd  --></a> shows how the output of the XOR phase detector is linear with
phase difference between the input and output signal for both lead and lag cases. One disadvantage with
this detecor is that if the local clk at the input is a multiple of the reference clk, the output sent to charge
pump is not different for any multiple, leading to false locked states (we might want it to lock to another
frequency/multiple).
</p>
   <figure class='figure' id='x1-6100159'><span id='xor-gate-as-a-phase-detector'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1679 --><p class='noindent'><img alt='PIC' height='200' src='images/xor_pd.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 59: </span><span class='content'>XOR gate as a phase detector</span></figcaption><!-- tex4ht:label?: x1-6100159  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1684 --><p class='indent'>   A phase-frequency detector (PFD) solves the above issue so that the PLL doesn’t lock to an incorrect multiple of the
reference frequency. It is a state machine with 3 states - UP is high or low, DN is high or low, or the PLL is locked (both
UP/DN are low).
</p>
   <figure class='figure' id='x1-6100260'><span id='phase-frequency-detector-left-phase-difference-detection-right-frequency-difference-detection'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1689 --><p class='noindent'><img alt='PIC' height='200' src='images/pfd_pd.png' width='200' /><img alt='PIC' height='200' src='images/pfd_pd_freq.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 60: </span><span class='content'>Phase Frequency Detector - (Left) Phase difference detection (Right) Frequency difference detection</span></figcaption><!-- tex4ht:label?: x1-6100260  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1694 --><p class='indent'>   Say when A is rising, UP takes on D (which is tied to \(V_{DD}\)) at the rising edge. It remains high till there is a low-to-high
transition on B at which point DN is high momentarily. With both UP and DN high, the RST signal is
pulled high through the AND gate with a delay of the clk-q delay of the B register and the propagation
delay of the AND gate, and both flip-flops are reset. The time for which UP is high is proportional to the
phase difference. This ckt can also act as a frequency error detector. When the frequency of A is higher
than B, the average UP signal is proportional to the frequency error while the average DN signal is close to
zero.
</p>
   <h5 class='subsubsectionHead' id='charge-pump'><span class='titlemark'>4.3.3   </span> <a id='x1-620004.3.3'></a>Charge pump</h5>
<!-- l. 1701 --><p class='noindent'>A simple charge pump is shown in figure <a href='#charge-pump1'>61<!-- tex4ht:ref: fig:charge_pump  --></a>. The capacitor is charged and discharged depending on the
widths of the UP/DN signals. These changes in the control voltage are fed to the VCO through the loop
filter.
</p>
   <figure class='figure' id='x1-6200161'><span id='charge-pump1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1705 --><p class='noindent'><img alt='PIC' height='125' src='images/charge_pump.png' width='125' />
</p>
<figcaption class='caption'><span class='id'>Figure 61: </span><span class='content'>Charge pump</span></figcaption><!-- tex4ht:label?: x1-6200161  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='delay-locked-loops'><span class='titlemark'>4.4   </span> <a id='x1-630004.4'></a>Delay Locked Loops</h4>
<!-- l. 1712 --><p class='noindent'>In the block diagram of a PLL in figure <a href='#block-diagram-of-a-pll'>58<!-- tex4ht:ref: fig:pll_block  --></a>, if we replace the VCO with a voltage-controlled delay line (VCDL), we get a
Delay Locked Loop (DLL). Figure <a href='#delay-locked-loop'>62<!-- tex4ht:ref: fig:dll_block  --></a> shows the schematic of a DLL.
</p>
   <figure class='figure' id='x1-6300162'><span id='delay-locked-loop'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1717 --><p class='noindent'><img alt='PIC' height='200' src='images/dll_block.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 62: </span><span class='content'>Delay Locked Loop</span></figcaption><!-- tex4ht:label?: x1-6300162  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1722 --><p class='indent'>   The VCDL is a block whose delay can be controlled, for example, a current-starved inverter. The idea is to delay the
output clock till it matches up with the reference [<a id='x1-63002'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. The phase detector in this case compares the delay between the
output and reference and generates the UP/DN signal to the charge pump - there is no need for a frequency error
signal.
                                                                                               
                                                                                               
</p>
   <h3 class='sectionHead' id='latches-and-registers'><span class='titlemark'>5   </span> <a id='x1-640005'></a>Latches and Registers</h3>
<!-- l. 1733 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='sequencing-methods'><span class='titlemark'>5.1   </span> <a id='x1-650005.1'></a>Sequencing methods</h4>
<!-- l. 1735 --><p class='noindent'>Latches and registers are static sequencing elements - they orchestrate the flow of data in a pipeline. What are the common
sequencing methods?
</p>
   <figure class='figure' id='x1-6500163'><span id='common-sequencing-methods'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1739 --><p class='noindent'><img alt='PIC' height='150' src='images/sequencing_methods.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 63: </span><span class='content'>Common sequencing methods</span></figcaption><!-- tex4ht:label?: x1-6500163  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1744 --><p class='indent'>   In figure <a href='#common-sequencing-methods'>63<!-- tex4ht:ref: fig:sequencing_methods  --></a>, we see that registers pass the data at the cycle boundary. We will later see that a register is just a cascade
of two latches. The two flip-flops can be replaced by three latches (instead of 4) as shown in the latch-based pipeline.
Finally, we can eliminate the clk and use a pulse-triggered system in our pipeline - this only uses two latches
instead of three. If the pulse is shorter than the delay introduced by the combinational block (which it usually
is), then only one token passes through the pipeline per cycle similar to the other two sequencing methods
[<a id='x1-65002'></a><a href='#cite.0_weste_cmos_2011'>15</a>].
</p>
   <h4 class='subsectionHead' id='static-sequencing-elements'><span class='titlemark'>5.2   </span> <a id='x1-660005.2'></a>Static sequencing elements</h4>
<!-- l. 1751 --><p class='noindent'>How are latches and registers (flip-flops) built? We need to incorporate some kind of <span class='cmti-10'>memory </span>into the system. The simplest
case of memory is achieved using the bistability principle - we have a ckt that has two stable states 0 and 1. A simple
example is two cascaded inverters. Here the data is stored till an external trigger disturbs the equilibrium and moves
it to the complementary state. Extra circuitry is needed to enable control of memory states in figure <a href='#cascaded-inverters'>64<!-- tex4ht:ref: fig:simple_memory  --></a>
[<a id='x1-66001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>].
</p>
   <figure class='figure' id='x1-6600264'><span id='cascaded-inverters'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1758 --><p class='noindent'><img alt='PIC' height='250' src='images/simple memory.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 64: </span><span class='content'>Cascaded inverters</span></figcaption><!-- tex4ht:label?: x1-6600264  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='sr-latch'><span class='titlemark'>5.3   </span> <a id='x1-670005.3'></a>SR Latch</h4>
<!-- l. 1766 --><p class='noindent'>The Set-Reset latch implements memory by implementing the following truth table
</p>
   <figure class='figure' id='x1-6700165'><span id='sr-latch-and-its-truth-table'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1770 --><p class='noindent'><img alt='PIC' height='250' src='images/sr_latch.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 65: </span><span class='content'>SR latch and its truth table</span></figcaption><!-- tex4ht:label?: x1-6700165  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1775 --><p class='indent'>   In figure <a href='#sr-latch-and-its-truth-table'>65<!-- tex4ht:ref: fig:sr_latch  --></a>, the state where S and R are both 1 is forbidden by additional circuitry. When implemented with NAND2
gates, the truth table changes slightly - \(S=R=0\) becomes the forbidden state for the latch. To introduce clk into such a
set-reset topology, we can take the take the cross-coupled inverter pair in figure <a href='#cascaded-inverters'>64<!-- tex4ht:ref: fig:simple_memory  --></a> and modify it as shown
below.
</p>
   <figure class='figure' id='x1-6700266'><span id='clocked-sr-flipflop'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1782 --><p class='noindent'><img alt='PIC' height='150' src='images/clocked_sr_latch.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 66: </span><span class='content'>Clocked SR flip-flop</span></figcaption><!-- tex4ht:label?: x1-6700266  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1788 --><p class='indent'>   Note that in figure <a href='#clocked-sr-flipflop'>66<!-- tex4ht:ref: fig:clocked_sr_ff  --></a>, there are two paths to GND on each side - one through the regular cross-coupled inverter pair -
say M2 and M1, and another through the ratioed inverter pair - say M2, and M6 and M5. In order to facilitate switching
(and introduce positive feedback in the cross-coupled inverters), we need \(Q\) and \(\bar {Q}\) to swing below the switching threshold of the
opposite branch. Example 7.1 in [<a id='x1-67003'></a><a href='#cite.0_rabaey_digital_1996'>11</a>] works out a problem on how to size these transistors to enable proper
switching.
</p>
   <h4 class='subsectionHead' id='muxbased-latches'><span class='titlemark'>5.4   </span> <a id='x1-680005.4'></a>MUX-based latches</h4>
<!-- l. 1796 --><p class='noindent'>One key issue with the SR-latch based flip-flop is that in figure <a href='#clocked-sr-flipflop'>66<!-- tex4ht:ref: fig:clocked_sr_ff  --></a>, the sizing of the devices (especially M5, M6 and their
counterparts) is critical for functionality - not just perfomance. MUX-based latches remove this criticality.
Figure <a href='#positive-latch-using-transmission-gates'>67<!-- tex4ht:ref: fig:mux_latch_ex  --></a> shows implementation of a MUX-based latch where the MUX is implemented using transmission
gates.
</p>
   <figure class='figure' id='x1-6800167'><span id='positive-latch-using-transmission-gates'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1802 --><p class='noindent'><img alt='PIC' height='250' src='images/mux_latch_ex.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 67: </span><span class='content'>Positive latch using transmission gates</span></figcaption><!-- tex4ht:label?: x1-6800167  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1807 --><p class='indent'>   In figure <a href='#positive-latch-using-transmission-gates'>67<!-- tex4ht:ref: fig:mux_latch_ex  --></a>, when CLK is high, the latch is transparent and D is copied to Q. The feeback loop from Q back to the
other input of the MUX is open. When the CLK is low, the output inverter drives the feedback loop and latches the output
similar to the cascaded inverters in figure <a href='#cascaded-inverters'>64<!-- tex4ht:ref: fig:simple_memory  --></a>.
</p>
   <h4 class='subsectionHead' id='leaderfollower-flipflop'><span class='titlemark'>5.5   </span> <a id='x1-690005.5'></a>Leader-Follower Flip-flop</h4>
<!-- l. 1812 --><p class='noindent'>We can use two of the MUX-based latches from above and build an edge-triggered register.
</p>
   <figure class='figure' id='x1-6900168'><span id='a-negative-leader-latch-followed-by-a-positive-follower-latch-can-form-a-positive-edge-triggered-register-'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1816 --><p class='noindent'><img alt='PIC' height='250' src='images/leader-follower_ff.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 68: </span><span class='content'>A negative leader latch followed by a positive follower latch can form a positive edge triggered register </span></figcaption><!-- tex4ht:label?: x1-6900168  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1821 --><p class='indent'>   When the CLK is low, the leader stage is transparent and the input D is passed to the input of the follower stage.
During this period, the follower latch is in <span class='cmti-10'>hold </span>mode and keeps the previous data value using feedback. On the rising edge
of the clk, the leader latch stops sampling the input, and the follower starts sampling the output of the leader latch. Due to
the clk-q delay of the first latch, the follower latch is able to sample the previous data and latch it in at the rising
edge of the clk without “seeing” the refreshed (or invalid) value when the leader latch stops sampling its
input.
</p>
   <figure class='figure' id='x1-6900269'><span id='implementing-a-leaderfollower-flipflop'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1830 --><p class='noindent'><img alt='PIC' height='250' src='images/mux_latch_impl.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 69: </span><span class='content'>Implementing a leader-follower flip-flop</span></figcaption><!-- tex4ht:label?: x1-6900269  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1836 --><p class='indent'>   One implementation of figure <a href='#a-negative-leader-latch-followed-by-a-positive-follower-latch-can-form-a-positive-edge-triggered-register-'>68<!-- tex4ht:ref: fig:leader_follower_ff  --></a> is shown in figure <a href='#implementing-a-leaderfollower-flipflop'>69<!-- tex4ht:ref: fig:leader_follower_ff_impl  --></a>. Note that I2 and I4 are made weaker by picking larger channel
length devices (usually all other devices are min length). Where do setup, hold, and propagation delays come from in this
ckt?
</p><!-- l. 1839 --><p class='indent'>   When clk is low and the leader latch is transparent, D passes through T1, I1 and I2. Why I2? In a bistable system such
as figure <a href='#cascaded-inverters'>64<!-- tex4ht:ref: fig:simple_memory  --></a>, there are only 2 stable points (ignoring the metastable point). To move from one stable point to another, we
need a trigger pulse that at least as wide as the \(2\tau _{inv}\) [<a id='x1-69003'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. Otherwise, the nodes might not settle (since loop gain may fall
below 1) to the new intended state (they might fall back to the previous stable state). <span class='cmbx-10'>Therefore, setup
time comes from</span> \(\tau _{T1} + 2\tau _{inv}\). Note that \(\tau _{T1}\) itself cannot be calculated using logical effort - the input D needs to be
driven by some other gate and then we can compute the delay through that gate and the transmission gate
T1.
</p><!-- l. 1845 --><p class='indent'>   When clk is high, the leader latch is opaque to changes in D and the follower latch samples the output of I1 and I2 loop.
The clk-q delay comes from the delays through transmission gate T2 and the inverter pair of I3 and I4 ([<a href='#cite.0_rabaey_digital_1996'>11</a>] says for
propagation delay you only need to take I3 here, but why?). The clk-q delay is same as the setup time in this case. The
hold time for this ckt is 0 since any changes in D are blocked once the clk is high at the transmission gate
T1.
</p>
   <h4 class='subsectionHead' id='clk-overlap'><span class='titlemark'>5.6   </span> <a id='x1-700005.6'></a>Clk overlap</h4>
<!-- l. 1852 --><p class='noindent'>We assumed so far that clk and \(\bar {clk}\) are non-overlapping. This ensures that the leader and follower latches are on one at a time
and never simultaneously. However, if in figure <a href='#implementing-a-leaderfollower-flipflop'>69<!-- tex4ht:ref: fig:leader_follower_ff_impl  --></a> clk and \(\bar {clk}\) have some overlap, D can be sampled even after the rising edge
(when the clk has settled) and sent to Q. This is called feedthrough [<a id='x1-70001'></a><a href='#cite.0_jacob_sequential_logic_2008'>8</a>]. Luckily, in this transmission gate architecture,
either only the PMOS or NMOS devices are on together at a given clk overlap and never both. Therefore,
the effective resistance of the transmission gates is higher than when both the N and PMOS devices are
on.
</p><!-- l. 1857 --><p class='indent'>   How to generate two-phase non-overlapping clk? We add a guardband by giving a \(t_{non-overlap}\) between each clk
phase. A simple design is to the use the SR-latch from figure <a href='#sr-latch-and-its-truth-table'>65<!-- tex4ht:ref: fig:sr_latch  --></a> and feed it clk and \(\bar {clk}\). Figure <a href='#generating-a-twophase-nonoverlapping-clk'>70<!-- tex4ht:ref: fig:non-overlapping_clk  --></a> shows this
implementation.
</p>
   <figure class='figure' id='x1-7000270'><span id='generating-a-twophase-nonoverlapping-clk'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1862 --><p class='noindent'><img alt='PIC' height='150' src='images/non-overlapping_clk.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 70: </span><span class='content'>Generating a two-phase non-overlapping clk</span></figcaption><!-- tex4ht:label?: x1-7000270  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1867 --><p class='indent'>   In the topology shown in figure <a href='#generating-a-twophase-nonoverlapping-clk'>70<!-- tex4ht:ref: fig:non-overlapping_clk  --></a>, we exploit the fact that for a NOR2 gate, when either of the inputs is 1, the output
becomes zero. Since \(\phi _1\) and \(\phi _2\) are inputs to the opposite NOR2 gates, when one of them is high, the other one is
guaranteed to be low due to the property explained above. We can control the \(t_{non-overlap}\) by sizing the NOR2 gates
[<a id='x1-70003'></a><a href='#cite.0_iitmadras_asynchronous_seq_circuits_2024'>6</a>].
</p>
   <h4 class='subsectionHead' id='dynamic-transmission-gatebased-registers'><span class='titlemark'>5.7   </span> <a id='x1-710005.7'></a>Dynamic Transmission gate-based registers</h4>
<!-- l. 1872 --><p class='noindent'>Instead of using a x-coupled pair of inverters for the memory element, we can use a capacitor to store the state. This is
suceptible to leakage and needs periodic refresh if the memory is held for longer. In figure <a href='#dynamic-transmission-gatebased-register'>71<!-- tex4ht:ref: fig:dynamic_tg_register  --></a>, we see that the input is
sampled onto \(C_1\) which is the sum of the parasitc capacitances of the transmission gate and the input capacitance of the
inverter. The setup time is simply the delay through the xmission gate. The hold time is zero since the xmission gate is off
on the clk edge.
</p>
   <figure class='figure' id='x1-7100171'><span id='dynamic-transmission-gatebased-register'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1878 --><p class='noindent'><img alt='PIC' height='150' src='images/dynamic_tg_register.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 71: </span><span class='content'>Dynamic transmission gate-based register</span></figcaption><!-- tex4ht:label?: x1-7100171  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1882 --><p class='indent'>   In the second phase, the inverters drive the sampled voltage to the output \(Q\). The clk-Q delay is the delay through the two
inverters \(I_{1/2}\) and the xmission gate \(T_2\). This topology is prone to race condtions too since a clk overlap can cause a direct path
from \(D\) to \(Q\). One way to deal with race conditions is to enforce a hold time constraint so that the input is constant even after
the clk edge falls (\(\bar {CLK}\) could still be high!).
</p>
   <h4 class='subsectionHead' id='cmos'><span class='titlemark'>5.8   </span> <a id='x1-720005.8'></a>C2MOS</h4>
<!-- l. 1890 --><p class='noindent'>Unlike static logic which uses a bistable element to store the value of a 0 or 1, dynamic logic uses the charge on a capacitor
to determine a 0 or 1. Since the capacitor can leak, the value stored might need a periodic refresh (hence the name
dynamic). The Clocked CMOS register (C2MOS) is one such leader-follower register which is insensitive to clk
overlap.
</p>
   <figure class='figure' id='x1-7200172'><span id='pos-edge-triggered-cmos-'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1895 --><p class='noindent'><img alt='PIC' height='250' src='images/c2mos_ff.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 72: </span><span class='content'>Pos edge triggered C2MOS </span></figcaption><!-- tex4ht:label?: x1-7200172  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1900 --><p class='indent'>   When CLK is 0, M4 and M3 are on while M7 and M8 are off. So Q holds whaterver value was stored previously. M2 and
M1 act as an inverter stage now and X takes the opposite value of D. When CLK is 1, the leader stage turns off and X is
now sampled and Q is the negation of X.
</p><!-- l. 1903 --><p class='indent'>   Let us look at what happens when clk and \(\bar {clk}\) overlap in a C2MOS register. In figure <a href='#evaluating-what-happens-in-a-clk-overlap-case-in-a-cmos-register'>73<!-- tex4ht:ref: fig:c2mos_clk_overlap  --></a>, for a 0-0 overlap, the PMOS
devices M2 and M4 let X sample the changes in D even after the positive edge of the clk. This is undesirable. Luckily, since
M7 is off, Q is unaffected by changes in X and clk overlap is not a problem. The same thing happens for a 1-1 overlap but
with the complementary devices.
</p>
   <div class='tcolorbox tcolorbox' id='tcolobox-4'>     
<div class='tcolorbox-title'>
   </div> 
<div class='tcolorbox-content'><!-- l. 1908 --><p class='noindent'>Therefore, it can be stated that the C2MOS latch is insensitive to clock overlaps because those overlaps
activate either the pull-up or the pull-down networks of the latches, but never both of them simultaneously.
</p>
 
</div> 
</div>
   <figure class='figure' id='x1-7200273'><span id='evaluating-what-happens-in-a-clk-overlap-case-in-a-cmos-register'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1915 --><p class='noindent'><img alt='PIC' height='250' src='images/c2mos_clk_overlap.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 73: </span><span class='content'>Evaluating what happens in a clk overlap case in a C2MOS register</span></figcaption><!-- tex4ht:label?: x1-7200273  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1920 --><p class='indent'>   Note that, if the rise and fall times of the clock are sufficiently slow, there exists a time slot where both the NMOS and
PMOS transistors are conducting. This creates a path between input and output that can destroy the state of the
circuit [<a id='x1-72003'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. X node can be floating - so we might need a keeper ckt to store the value at this node at all
times.
</p><!-- l. 1925 --><p class='indent'>   What is the logical effort of D in a C2MOS register as shown in figure <a href='#pos-edge-triggered-cmos-'>72<!-- tex4ht:ref: fig:c2mos  --></a>? Since we have stacked transistors - M1 and
M3, and M2 and M4, and assuming no velocity saturation, we can size the devices as shown in figure <a href='#evaluating-what-happens-in-a-clk-overlap-case-in-a-cmos-register1'>74<!-- tex4ht:ref: fig:c2mos_le  --></a>. The corresponding
reference inverter has a PMOS of width 2 units and an NMOS of width 1 unit. Therefore, the logical effort from D to X is \((4+2)/(2+1) = 2\).
Similarly, the logical effort from X to Q is also 2. Since each stage is only active at opposite clk phases,
the total logical effort of a C2MOS block is just 2 (there is no need to multiply individual stage’s logical
effort).
</p>
   <figure class='figure' id='x1-7200474'><span id='evaluating-what-happens-in-a-clk-overlap-case-in-a-cmos-register1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1932 --><p class='noindent'><img alt='PIC' height='150' src='images/c2mos_le_1.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 74: </span><span class='content'>Evaluating what happens in a clk overlap case in a C2MOS register</span></figcaption><!-- tex4ht:label?: x1-7200474  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1937 --><p class='indent'>   What is the setup, hold, and clk-q delays of the C2MOS register in figure <a href='#pos-edge-triggered-cmos-'>72<!-- tex4ht:ref: fig:c2mos  --></a>? When clk is 0 and the leader latch is on,
the delay from D to X is just the delay of the inverter formed by M2 and M1. From our previous logical effort
calculations, we know that this takes \(2\tau _{inv}\) (if \(\tau _{inv}\) is the delay of the reference static CMOS inverter). This is the setup
time. The clk-q delay comes from the second stage - the time it takes for X to get to Q. Since the logical
effort of D and clk are same in the case of C2MOS (at least for the sizing given in figure <a href='#evaluating-what-happens-in-a-clk-overlap-case-in-a-cmos-register1'>74<!-- tex4ht:ref: fig:c2mos_le  --></a>), clk-q delay
is \(2\tau _{inv}\) as well. Finally, for the hold time is zero since the devices M3 and M4 are off when the CLK is high.
Note that in practice a hold time constraint is enforced in case there is a clk overlap. When there is a clk
overlap in the 1-1 state, as seen in figure <a href='#evaluating-what-happens-in-a-clk-overlap-case-in-a-cmos-register'>73<!-- tex4ht:ref: fig:c2mos_clk_overlap  --></a>, the node X can still undergo a 1-to-0 transtion. This cannot
instantly transfer to the output, but as soon as the clk overlap period is done and the PMOS M8 is now on, the
new sampled 0 on the X (which is sampled after the fall of clk edge) is transferred to the output. So, it
makes sense to enforce a hold time condition equal to the clk overlap so that D is stable even after the clk
edge.
</p>
   <h4 class='subsectionHead' id='dualedge-registers'><span class='titlemark'>5.9   </span> <a id='x1-730005.9'></a>Dual-edge registers</h4>
<!-- l. 1948 --><p class='noindent'>Instead of passing the data to the output only at one edge, we can keep the same throughput by passing the
data at both the edges of the clk and reducing the clk frequency by half. This can result in power savings in
the clk distribution network [<a id='x1-73001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. Here two parallel C2MOS registers are used - M1 and M4 are reused to
sample \(D\) in both phases of the clk while the leader stage and the follower stage operate in a complementary
fashion.
</p>
   <figure class='figure' id='x1-7300275'><span id='dualedge-register-using-a-cmos-style-register'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1954 --><p class='noindent'><img alt='PIC' height='150' src='images/dual_edge_register.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 75: </span><span class='content'>Dual-edge register using a C2MOS style register</span></figcaption><!-- tex4ht:label?: x1-7300275  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='true-singlephase-clocked-register-tspcr'><span class='titlemark'>5.10   </span> <a id='x1-740005.10'></a>True Single-Phase Clocked Register (TSPCR)</h4>
<!-- l. 1962 --><p class='noindent'>While C2MOS is tolerant to clk overlap, it is not single phased and the rise and fall times of the clk can affect its operation.
Figure <a href='#left-tspcr-latch-right-tspcr-latch-with-ability-to-implement-any-arbitrary-logic'>76<!-- tex4ht:ref: fig:tspcr_latch  --></a> shows a style of latch that is truly single phase.
</p>
   <figure class='figure' id='x1-7400176'><span id='left-tspcr-latch-right-tspcr-latch-with-ability-to-implement-any-arbitrary-logic'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1967 --><p class='noindent'><img alt='PIC' height='250' src='images/tspcr_latch.png' width='250' /><img alt='PIC' height='250' src='images/tspcr_pun_pdn_latch.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 76: </span><span class='content'>(Left) TSPCR latch. (Right) TSPCR latch with ability to implement any arbitrary logic</span></figcaption><!-- tex4ht:label?: x1-7400176  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1972 --><p class='indent'>   In the case of the positive latch in figure <a href='#left-tspcr-latch-right-tspcr-latch-with-ability-to-implement-any-arbitrary-logic'>76<!-- tex4ht:ref: fig:tspcr_latch  --></a>, when clk is high, the latch is just two cascaded inverters. When
the clk is low, the pull-down network is disabled. Since there are two inverter stages, even if the pull-up
network of the first stage is active, the second stage’s PMOS gate is pulled to high, switching it off. The
opposite happens for the negative latch. We can embed any logic into the PUN and PDN as shown in the same
figure.
</p><!-- l. 1976 --><p class='indent'>   We can make a TSPCR register using the positive and negative latch building blocks. Figure <a href='#_'>77<!-- tex4ht:ref: fig:tspcr_reg  --></a> shows the
implementation - a negative latch followed by a positive latch to capture the data at the positive edge, followed by another
inverter to drive the output stage.
</p>
   <figure class='figure' id='x1-7400277'><span id='_'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 1981 --><p class='noindent'><img alt='PIC' height='250' src='images/tspcr_register.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 77: </span><span class='content'></span></figcaption><!-- tex4ht:label?: x1-7400277  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 1986 --><p class='indent'>   In figure <a href='#_'>77<!-- tex4ht:ref: fig:tspcr_reg  --></a>, when clk is low, X samples the changes in D (its negation to be more precise). The second inverter charges
up Y to \(V_{DD}\). This leaves the third inverter in hold mode since M9 and M8 are off. On the rising edge of the clk, the dynamic
inverter in the second stage evaluates X - if X is high, Y discharges, otherwise Y stays charged to \(V_{DD}\). The third inverter is also
on during this time and Y is passed to the output Q.
</p><!-- l. 1990 --><p class='indent'>   What is the setup, hold, and clk-q delays of the TSPCR register in figure <a href='#_'>77<!-- tex4ht:ref: fig:tspcr_reg  --></a>? The setup time is straightforward - it is
from the delay of the first dynamic inverter (the time taken from D to X) [<a id='x1-74003'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. The propagation delay is from X to output Q
- 2 dynamic and 1 static inverter delay. To understand the hold time, we need to consider what happens at the rising edge
and when D is transitioning from low to high. The NMOS M1 needs a time of \(\tau _{inv}\) to discharge the node X. This forms the hold
time for a “high” input at D. When D is zero, the hold time is zero since X cannot be pulled up after CLK is shuts down
M2.
</p><!-- l. 1997 --><p class='indent'>   Similar to the C2MOS latch, the TSPC latch malfunctions when the slope of the clock is not sufficiently steep. Slow
clocks cause both the NMOS and PMOS clocked transistors to be on simultaneously, resulting in undefined values of the
states and race conditions.
</p>
   <div class='tcolorbox tcolorbox' id='tcolobox-5'>     
<div class='tcolorbox-title'>
   </div> 
<div class='tcolorbox-content'>       <ol class='enumerate1'>
<li class='enumerate' id='x1-74005x1'>Setup time - evaluate time from input to internal node
       </li>
<li class='enumerate' id='x1-74007x2'>clk-q delay - evaluate time from internal node to output
       </li>
<li class='enumerate' id='x1-74009x3'>Hold time - check if there is access from D to internal node - if yes, evaluate that delay, if no, hold
       time is zero
</li></ol>
 
</div> 
</div>
   <h4 class='subsectionHead' id='pulse-registers'><span class='titlemark'>5.11   </span> <a id='x1-750005.11'></a>Pulse Registers</h4>
<!-- l. 2017 --><p class='noindent'>All the registers we’ve seen so far use a leader-follower configuration. Pulse registers use a short pulse that is generated at
the edge of the clk so that the latch is transparent for a very short time window. Race conditions can be avoided by
making the transparent period very short. How do we generate the pulse? A simple pulse generator is shown in
figure
</p>
   <figure class='figure' id='x1-7500178'><span id='a-simple-pulse-generator'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2023 --><p class='noindent'><img alt='PIC' height='150' src='images/simple_pulse_generator.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 78: </span><span class='content'>A simple pulse generator</span></figcaption><!-- tex4ht:label?: x1-7500178  -->
                                                                                               
                                                                                               
   </figure>
   <figure class='figure' id='x1-7500279'><span id='left-glitch-generation-right-register'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2032 --><p class='noindent'><img alt='PIC' height='200' src='images/glitch_generation.png' width='200' /><img alt='PIC' height='200' src='images/pulse_register_ex&#x60;.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 79: </span><span class='content'>(Left) Glitch generation (Right) Register</span></figcaption><!-- tex4ht:label?: x1-7500279  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2037 --><p class='indent'>   On the left figuure in figure <a href='#left-glitch-generation-right-register'>79<!-- tex4ht:ref: fig:pulse_register_ex  --></a>, we see that when CLK is low, X is high. When the clk is about to rise, there is a brief
period when both the inputs of the AND gate are high. The AND gate outputs a high signal and the CLKG signal is high.
This turns on the PD NMOS and X (and CLKG) to low. The length of the pulse is controlled by the delay through the
AND gate and the two inverters [<a id='x1-75003'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. There is also a delay between the clk edge and the glitch signal that is equal to the
delay through the AND gate and the two inverters. The register used in the example in figure <a href='#left-glitch-generation-right-register'>79<!-- tex4ht:ref: fig:pulse_register_ex  --></a> is TSPCR positive
latch.
</p><!-- l. 2043 --><p class='indent'>   If we measure the setup time from the rising edge of the glitch (as opposed to the clk), the setup time is
essentially zero. The hold time is equal to the delay through the AND gate and the two invereters (which
is equal to the length of the pulse). The clk-q delay is delay across two invereters in the TSPCR positive
latch.
</p>
   <div class='tcolorbox tcolorbox' id='tcolobox-6'>     
<div class='tcolorbox-title'>
   </div> 
<div class='tcolorbox-content'><!-- l. 2048 --><p class='noindent'>[<a href='#cite.0_rabaey_digital_1996'>11</a>] notes that a negative setup time can be achieved if the delay from input to output is smaller than the
transparency window. </p> 
</div> 
</div>
<!-- l. 2051 --><p class='indent'>   This just means the data can arrive after the glitch’s rising edge since the latch is still transparent and can make it to
the output since the delay is smaller than the glitch length.
</p><!-- l. 2053 --><p class='indent'>   We can combine the pulse generator and the latching module into a single block - know as the Partovi pulsed latch. The
cross-coupled inverters at the output make sure the output state is retained.
</p>
   <figure class='figure' id='x1-7500480'><span id='partovi-pulsed-latch'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2057 --><p class='noindent'><img alt='PIC' height='200' src='images/partovi_pulsed_latch.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 80: </span><span class='content'>Partovi pulsed latch</span></figcaption><!-- tex4ht:label?: x1-7500480  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2062 --><p class='indent'>   Pulsed latches offer greater speed than conventional registers at the cost of increased hold time. Since there are fewer
clked elements, the power consumption is reduced as well. However, pulsed latches are not suitable when there is no logic
block between the pipeline stages. We need some some element that can introduce delay to essentially meet hold time
constraints. One such block is the clocked deracer - which is just a clocked buffer that adds delay between two pipeline
stages as shown in figure <a href='#clocked-deracer'>81<!-- tex4ht:ref: fig:clked_deracer  --></a>.
</p>
   <figure class='figure' id='x1-7500581'><span id='clocked-deracer'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2068 --><p class='noindent'><img alt='PIC' height='200' src='images/clked_deracer.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 81: </span><span class='content'>Clocked deracer</span></figcaption><!-- tex4ht:label?: x1-7500581  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='sense-amplifier-based-registers'><span class='titlemark'>5.12   </span> <a id='x1-760005.12'></a>Sense Amplifier based Registers</h4>
<!-- l. 2076 --><p class='noindent'>Yet another technique to build a register is using sense amplifers. In a digital design sense, they accept a small input signal
and convert it to a rail-to-rail output. In figure <a href='#sense-amplifer-based-register'>82<!-- tex4ht:ref: fig:sense_amp_register_ex  --></a>, there is a cross-coupled inverter pair (M5-M8) whose outputs, L1 and
L2, are precharged to \(V_{DD}\) during the low-phase of the clk using M9 and M10.
</p>
   <figure class='figure' id='x1-7600182'><span id='sense-amplifer-based-register'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2082 --><p class='noindent'><img alt='PIC' height='200' src='images/sense_amp_register.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 82: </span><span class='content'>Sense amplifer based register</span></figcaption><!-- tex4ht:label?: x1-7600182  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2087 --><p class='indent'>   This means M7 and M8 are turned off and the xcoupled NAND2s hold the previous state. M1 is also turned off when clk
is low so that any differential input cannot affect the stored state. When the clk is high, M1-M6 behave as a differential
amplifer and the difference between the inputs is amplified at the output nodes L1 and L2. The cross-coupled invereter
stage flips accordingly.Why do we need M4 here?
</p>
   <figure class='figure' id='x1-7600283'><span id='need-for-the-m-xtor'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2093 --><p class='noindent'><img alt='PIC' height='200' src='images/sense_amp_register_m4.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 83: </span><span class='content'>Need for the M4 xtor</span></figcaption><!-- tex4ht:label?: x1-7600283  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2099 --><p class='indent'>   Referring to figure <a href='#need-for-the-m-xtor'>83<!-- tex4ht:ref: fig:sense_amp_register_m4  --></a>, say the inputs at M2 and M3 were initially 1 and 0. If the inputs change after the positive <span class='cmti-10'>edge </span>of
the clk, as shown in the same figure, and if M4 was absent, M2 would turn off and this would let the inverter pair at the top
to charge the drain node at L3 (leakage currents) and flip the state of the NAND FFs. M4 provides a shorting path for the
leakage so that when the inputs change, there is path for the leakage current to not affect the high-impedance
node.
</p>
   <h4 class='subsectionHead' id='enabling-logic-in-latches-and-registers'><span class='titlemark'>5.13   </span> <a id='x1-770005.13'></a>Enabling logic in latches and registers</h4>
<!-- l. 2108 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='reset'><span class='titlemark'>5.13.1   </span> <a id='x1-780005.13.1'></a>Reset</h5>
<!-- l. 2110 --><p class='noindent'>Most practical sequencing elements require a reset signal to enter a known initial state on startup and ensure deterministic
behavior. A synchronous reset waits for the clk to reset the state while an asynchronous reset immediately resets the current
state.
</p>
   <figure class='figure' id='x1-7800184'><span id='examples-of-asynchronous-reset-bottom-and-synchronous-reset-top-latches'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2116 --><p class='noindent'><img alt='PIC' height='200' src='images/reset_latches.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 84: </span><span class='content'>Examples of asynchronous reset (bottom) and synchronous reset (top) latches</span></figcaption><!-- tex4ht:label?: x1-7800184  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2121 --><p class='indent'>   The tristate NAND gate in the asynchronous reset case in figure <a href='#examples-of-asynchronous-reset-bottom-and-synchronous-reset-top-latches'>84<!-- tex4ht:ref: fig:reset_latches  --></a> can be constructed with a NAND gate in series with
a clocked transmission gate [<a id='x1-78002'></a><a href='#cite.0_weste_cmos_2011'>15</a>].
</p>
   <h5 class='subsubsectionHead' id='enable'><span class='titlemark'>5.13.2   </span> <a id='x1-790005.13.2'></a>Enable</h5>
<!-- l. 2127 --><p class='noindent'>When enable en is low, the element retains its state independently of the clock. In figure <a href='#examples-of-how-to-add-enable-into-latches-or-registers'>85<!-- tex4ht:ref: fig:enable_latches  --></a>, we see this can be achieved
either using a MUX or a clock gating scheme. The MUX-based scheme adds area and delay while the clk gating scheme
does not add any delay from input to output and saves power because the clk’s activity factor is 0 when disabled. The AND
gata can introduce clk skew, however.
</p>
   <figure class='figure' id='x1-7900185'><span id='examples-of-how-to-add-enable-into-latches-or-registers'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2133 --><p class='noindent'><img alt='PIC' height='200' src='images/enable_latch.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 85: </span><span class='content'>Examples of how to add “enable” into latches or registers</span></figcaption><!-- tex4ht:label?: x1-7900185  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='dual-edgetriggered-flipflops'><span class='titlemark'>5.14   </span> <a id='x1-800005.14'></a>Dual edge-triggered flip-flops</h4>
<!-- l. 2140 --><p class='noindent'>While a dual edge-triggered (DET) register can double throughput, it is sensitive to duty cycle - which becomes a clk skew.
A simple way to a DET register is to use a rising and falling edge registers in parallel as shown in figure
<a href='#det-register-with-two-parallel-registers-and-its-xtorlevel-implementation'>86<!-- tex4ht:ref: fig:det_register_ex1  --></a>.
</p>
   <figure class='figure' id='x1-8000186'><span id='det-register-with-two-parallel-registers-and-its-xtorlevel-implementation'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2146 --><p class='noindent'><img alt='PIC' height='100' src='images/det_register1.png' width='100' /><img alt='PIC' height='100' src='images/det_register1_xtor.png' width='100' />
</p>
<figcaption class='caption'><span class='id'>Figure 86: </span><span class='content'>DET register with two parallel registers - and its xtor-level implementation</span></figcaption><!-- tex4ht:label?: x1-8000186  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2151 --><p class='indent'>   Another way is to generate pulses at the rising and falling clk edges and then use a pulsed latch.
</p>
   <figure class='figure' id='x1-8000287'><span id='det-register-with-pulsed-latches-and-its-xtorlevel-implementation'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2155 --><p class='noindent'><img alt='PIC' height='100' src='images/pulse_det_ex.png' width='100' /><img alt='PIC' height='100' src='images/pulse_det_ex_xtor.png' width='100' />
</p>
<figcaption class='caption'><span class='id'>Figure 87: </span><span class='content'>DET register with pulsed latches - and its xtor-level implementation</span></figcaption><!-- tex4ht:label?: x1-8000287  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='schmitt-trigger'><span class='titlemark'>5.15   </span> <a id='x1-810005.15'></a>Schmitt Trigger</h4>
<!-- l. 2162 --><p class='noindent'>A Schmitt trigger has the following properties [<a id='x1-81001'></a><a href='#cite.0_weste_cmos_2011'>15</a>]
</p><!-- l. 2164 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-81003x1'>Responds to a slow changing time input with a fast output transitioning
     </li>
<li class='enumerate' id='x1-81005x2'>Difference in switching threshold for rising vs falling edges</li></ol>
<!-- l. 2169 --><p class='indent'>   Figure <a href='#noninverting-schmitt-trigger'>88<!-- tex4ht:ref: fig:schmitt_trigger_concept  --></a> illustrates a conceptual block diagram of a Schmitt trigger. When the voltage is rising but below \(V_{M+}\), the trigger
outputs a zero. As the input rises above the positive threshold, the trigger quickly turns on and outputs a 1. If the signal
starts falling, there is no change till the falling signal falls below the negative threshold, \(V_{M-}\), which could be different from \(V_{M+}\),
and the output is now a zero.
</p>
   <figure class='figure' id='x1-8100688'><span id='noninverting-schmitt-trigger'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2175 --><p class='noindent'><img alt='PIC' height='250' src='images/schmitt_trigger_concept.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 88: </span><span class='content'>Non-inverting Schmitt trigger</span></figcaption><!-- tex4ht:label?: x1-8100688  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2180 --><p class='indent'>   This inherent hysteresis between the rising and falling thresholds is a fundamental characteristic of a Schmitt trigger. A
CMOS implementation is shown in figure <a href='#cmos-schmitt-trigger'>89<!-- tex4ht:ref: fig:schmitt_trigger_cmos  --></a>.
</p>
   <figure class='figure' id='x1-8100789'><span id='cmos-schmitt-trigger'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2184 --><p class='noindent'><img alt='PIC' height='250' src='images/schmitt_trigger_cmos.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 89: </span><span class='content'>CMOS Schmitt trigger</span></figcaption><!-- tex4ht:label?: x1-8100789  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2190 --><p class='indent'>   Let’s say the input is initial zero in figure <a href='#cmos-schmitt-trigger'>89<!-- tex4ht:ref: fig:schmitt_trigger_cmos  --></a>. The node X is pulled to high and the inverter at the output makes the
output 0. This turns on M4 and shuts off M3. This changes the switching threshold of the first inverter to \(k_{M1}/(k_{M2}+k_{m4})\) - which makes it
harder to switch states by increasing the \(V_{in}\) that is needed on M1 to overpower the two PMOS transistors. Once the switch
does happen at node X, the feedback loop of the inverter causes the transistor M4 to shut off and turns on M3. Now for a
falling input, M2 has to overcome the pull-down of the two NMOS devices M1 and M3 and the switching
threshold is different from the rising one due to different ratios. This is the cause of the hysteresis in a Schmitt
trigger.
</p>
   <figure class='figure' id='x1-8100890'><span id='inverting-cmos-schmitt-trigger'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2198 --><p class='noindent'><img alt='PIC' height='150' src='images/schmitt_trigger_cmos2.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 90: </span><span class='content'>Inverting CMOS Schmitt trigger</span></figcaption><!-- tex4ht:label?: x1-8100890  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2203 --><p class='indent'>   Figure <a href='#inverting-cmos-schmitt-trigger'>90<!-- tex4ht:ref: fig:schmitt_trigger_cmos2  --></a> shows an inverting Schmitt trigger. When the input is 0, M3 and M4 are on and act pull the output to 1. This
turns off M6 but M5 is on and pulls the node X to \(V_{DD}-V_{th,n}\). As the input increases, M1 starts turning on sinking more current along
M1 and M5 path. The voltage at node X keeps falling and this increases the overdrive on M2 as its gate voltage is
increasing while the source voltage is dropping. At some point, \(V_{in} &gt; V_x + V_{th,n}\) and the device M2 turns on, sharply pulling down the
output node to GND. This turns off M3 and and turns on M6. The node between M5 and M6 is \(V_{th,p}\). Further increasing \(V_{in}\)
doesn’t change the output. The same mechanism is applied in reverse for a falling input and the hysteresis
comes from the difference in threshold voltages of M5 and M6 along with the pull-up and pull-down networks
[<a id='x1-81009'></a><a href='#cite.0_computer_electronics_cmos_schmitt_2024'>5</a>].
</p>
   <h4 class='subsectionHead' id='pipelining'><span class='titlemark'>5.16   </span> <a id='x1-820005.16'></a>Pipelining</h4>
<!-- l. 2210 --><p class='noindent'>In a system with sequential and combinational blocks, the delay through a large combinational block can often be a
bottleneck to higher clk speeds. Say you have a combinational block made of \(n\) blocks, each of the same delay. Say there is a
register at its input and its output. The total delay is given by the sum of the setup, hold, clk-q times, and
the delay through the \(n\) combinational blocks. In pipelining, we increase the throughput by adding registers
between the \(n\) combinational blocks, so that the delay between two consecutive registers is now decrease \(n\)
fold (assuming register related delays are much smaller)! We can also load the next instructions as the first
instruction makes it way through the pipeline. The result is that we can run at a higher clk speed, and despite
the result now taking \(n\) clk cycles, the functional throughput increases since we are also loading the next
instructions.
</p><!-- l. 2218 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='noracmos-for-pipelining'><span class='titlemark'>5.16.1   </span> <a id='x1-830005.16.1'></a>NORA-CMOS for pipelining</h5>
<!-- l. 2220 --><p class='noindent'>No-race pipelining can be implemented with some additional constraints on C2MOS latches. In a C2MOS latch, the
internal node is affected by the input when there is clk overlap, but this effect does not transfer to the output
stage. However, if there is an inversion in sign due to the logic implemented in the pipeline, the inversion can
cause the other half of the output stage (which is <span class='cmbx-10'>NOT </span>disconneted) to respond and change the output
stage.
</p>
   <figure class='figure' id='x1-8300191'><span id='inverter-causes-a-race-condtion-in-cmosbased-pipeliningng'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2228 --><p class='noindent'><img alt='PIC' height='150' src='images/nora_c2mos_ex.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 91: </span><span class='content'>Inverter causes a race condtion in C2MOS-based pipeliningng</span></figcaption><!-- tex4ht:label?: x1-8300191  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2233 --><p class='indent'>   In figure <a href='#inverter-causes-a-race-condtion-in-cmosbased-pipeliningng'>91<!-- tex4ht:ref: fig:nora_c2mos_ex  --></a>, without the inverter, the output stage would still have the PMOS half connected to the output - but this is
not affected by any change in the input. However, with the sign inversion that is introduced by the inverter, the output
PMOS pull up can respond to changes in the input after the clk edge. We elminate this issue by imposing a constraint
that the combinational block implemented in any pipeline stage (between a pair of C2MOS latches) are all
non-inverting.
</p><!-- l. 2237 --><p class='indent'>   We can extend this idea in developing a NORA-CMOS logic, where we use dynamic logic based combinational block and
C2MOS latches. The logic and latch are both clocked such that they’re simultaneously in either evaluation or hold
(precharge) mode [<a id='x1-83002'></a><a href='#cite.0_rabaey_digital_1996'>11</a>].
</p>
   <figure class='figure' id='x1-8300392'><span id='left-clk-module-right-clk-module'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2242 --><p class='noindent'><img alt='PIC' height='150' src='images/clk_mod.png' width='150' /><img alt='PIC' height='150' src='images/clk_bar_mod.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 92: </span><span class='content'>(Left) Clk module (Right) \(\bar {Clk}\) module</span></figcaption><!-- tex4ht:label?: x1-8300392  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2248 --><p class='indent'>   From figure <a href='#left-clk-module-right-clk-module'>92<!-- tex4ht:ref: fig:nora_c2mos_clk_module  --></a>, we define a clk module when the block is in evaluation phase when clk is high and its complement when
clk is low. A NORA data path consists of alternating clk and \(\bar {clk}\) modules.
                                                                                               
                                                                                               
</p>
   <h3 class='sectionHead' id='sram'><span class='titlemark'>6   </span> <a id='x1-840006'></a>SRAM</h3>
<!-- l. 2262 --><p class='noindent'>Static RAMs use a memory cell with internal feedback that retains its value as long as power is applied [<a id='x1-84001'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. It has the
following properties
</p><!-- l. 2265 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-84003x1'>Denser than flip-flops
     </li>
<li class='enumerate' id='x1-84005x2'>Faster and easier to use than DRAM</li></ol>
<!-- l. 2270 --><p class='indent'>   Hence, SRAM is used for register banks. A SRAM cell needs to be able to read and write data and to hold the data as
long as the power is applied.
</p><!-- l. 2273 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='tsram'><span class='titlemark'>6.1   </span> <a id='x1-850006.1'></a>6T-SRAM</h4>
<!-- l. 2275 --><p class='noindent'>A standard 6T-SRAM cell (from now on we’ll just refer to this as SRAM cell) is shown figure <a href='#a-standard-tsram-cell'>93<!-- tex4ht:ref: fig:6t_sram_cell  --></a>. It consists of a weak
cross-coupled inverter pair holding the memory similar to figure <a href='#cascaded-inverters'>64<!-- tex4ht:ref: fig:simple_memory  --></a>.
</p>
   <figure class='figure' id='x1-8500193'><span id='a-standard-tsram-cell'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2280 --><p class='noindent'><img alt='PIC' height='250' src='images/6t_sram.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 93: </span><span class='content'>A standard 6T-SRAM cell</span></figcaption><!-- tex4ht:label?: x1-8500193  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='read-operation-and-nominal-device-sizing'><span class='titlemark'>6.2   </span> <a id='x1-860006.2'></a>READ operation and nominal device sizing</h4>
<!-- l. 2287 --><p class='noindent'>Let us assume that Q stores a 0 initially in the SRAM cell. A READ operation starts with charging the bit and \(\bar {bit}\) both to
high. The word line is then assserted. Let us now see what all devices are on. D2 and P1 are OFF while A1,
A2, D1, and P2 are ON. Since \(Q_b\) and \(\bar {bit}\) are both at 1, there is no discharge on that side of the cell. On the
opposite side, A1 is trying to pull bit to high - but if it succeeds, the state of the cell flips and we have a
destructive READ operation. To prevent this, D1 is sized larger (stronger drive, lower resistance) than A1. The
momentary increase in the voltage at node Q is sensed by a differential sense amplifier at the end of the bit line
column.
</p><!-- l. 2293 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='write-operation-and-nominal-device-sizing'><span class='titlemark'>6.3   </span> <a id='x1-870006.3'></a>WRITE operation and nominal device sizing</h4>
<!-- l. 2295 --><p class='noindent'>A WRITE operation starts with charging the bit and \(\bar {bit}\) to the desired values, and then asserting the word line. Assume Q is
initially 0 and we wish to write a 1 through bit. bit is precharged to high (and \(\bar {bit}\) to low) and word line is asserted. In the
current setup, A1, A2, D1, and P2 are ON, and P1 and D2 are OFF. D1 is actively pulling Q to GND. From a READ
perspective, we designed D1 to be stronger than A1. Therefore, the WRITE operation has to start at the \(Q_b\) side
[<a id='x1-87001'></a><a href='#cite.0_weste_cmos_2011'>15</a>].
</p>
   <div class='tcolorbox tcolorbox' id='tcolobox-7'>     
<div class='tcolorbox-title'>
   </div> 
<div class='tcolorbox-content'><!-- l. 2301 --><p class='noindent'>Nominally, WRITE operation always starts at the column line (bit or \(\bar {bit})\) which holds zero. This is true for
writing either 0 or 1 to the SRAM cell. </p> 
</div> 
</div>
<!-- l. 2304 --><p class='indent'>   From \(Q_b\) side, A2 needs to overpower P2 so that a zero can be written into this node. Therefore, A2 is sized bigger than
the pull-up device P2.
</p><!-- l. 2306 --><p class='indent'>   In a WRITE-optimized SRAM, however, we size both the pull-up and pull-down transistors smaller than the access
transistors. This comes at the cost of read stability, however. There is a conflict between an SRAM cell optimized for READ
vs WRITE.
</p>
   <figure class='figure' id='x1-8700294'><span id='read-vs-write-optimized-tsram-cells'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2311 --><p class='noindent'><img alt='PIC' height='150' src='images/read_vs_write_optimized_sram.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 94: </span><span class='content'>READ vs WRITE optimized 6T-SRAM cells</span></figcaption><!-- tex4ht:label?: x1-8700294  -->
                                                                                               
                                                                                               
   </figure>
   <div class='tcolorbox tcolorbox' id='tcolobox-8'>     
<div class='tcolorbox-title'>
   </div> 
<div class='tcolorbox-content'><!-- l. 2318 --><p class='noindent'>Nominally, for good READ stability and WRITABILITY, sizing of the transistors is PD \(&gt;\) AC \(&gt;\) PU. </p> 
</div> 
</div>
   <h4 class='subsectionHead' id='switching-threshold-of-an-inverter'><span class='titlemark'>6.4   </span> <a id='x1-880006.4'></a>Switching threshold of an inverter</h4>
<!-- l. 2324 --><p class='noindent'>The switching threshold of an inverter is defined as the point where \(V_{in} = V_{out}\) [<a id='x1-88001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. Figure <a href='#vtc-of-a-static-cmos-inverter'>95<!-- tex4ht:ref: fig:vtc_inverter  --></a> shows the VTC of a static CMOS
inverter. At the switching threshold, \(V_M\), both the NMOS and PMOS are in saturation.
</p>
   <figure class='figure' id='x1-8800295'><span id='vtc-of-a-static-cmos-inverter'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2329 --><p class='noindent'><img alt='PIC' height='150' src='images/vtc_inverter.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 95: </span><span class='content'>VTC of a static CMOS inverter</span></figcaption><!-- tex4ht:label?: x1-8800295  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2334 --><p class='indent'>   If \(V_{DD} &gt;&gt; V_{th,n/p}\) then we can approximate the threshold voltage for a velocity saturated devices as follows [<a id='x1-88003'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]
</p><!-- l. 2339 --><p class='indent'>   \begin {equation}  \label {eqn:vm_vel_sat} V_M = \frac {rV_{DD}}{1+r}  \end {equation}<a id='x1-88004r35'></a>
</p><!-- l. 2341 --><p class='indent'>   where \(r = (v_{sat,p}W_P/v_{sat,n}W_N)\) for the given inverter. In long channel devices without velocity saturation, eqn <a href='#x1-88004r35'>35<!-- tex4ht:ref: eqn:vm_vel_sat  --></a> changes to
</p><!-- l. 2346 --><p class='indent'>   \begin {equation}  \label {eqn:vm_long_channel} V_M = \frac {V_{th,n}+r(V_{DD}+V_{th,p})}{1+r}  \end {equation}<a id='x1-88005r36'></a>
</p><!-- l. 2348 --><p class='indent'>   where \(r = \sqrt {-k_p/k_n}\). [<a href='#cite.0_rabaey_digital_1996'>11</a>] notes that \(V_M\) is relatively insensitive to \(W_P/W_N\) in an inverter (he does through an example simulation). Increasing
the width of PMOS moves \(V_M\) towards \(V_{DD}\) while increasing the NMOS moves it towards GND. If the input has a noisy 0 value, an
asymmetric inverter with \(V_M\) shifted towards \(V_{DD}\) would be more robust in preventing erroneous values to pass
through.
</p><!-- l. 2351 --><p class='indent'>   Quick notes on scaling effects on \(V_M\) -
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-88007x1'>As oxide thickness decerases, so does \(V_{th}\) (because the gate can invert the channel easier than with a thicker
     oxide). A good PMOS is a device with smaller \(V_{th}\). Figure <a href='#left-process-variations-and-impact-on-vtc-right-impact-of-vdd-scaling-on-inverter-vtc'>96<!-- tex4ht:ref: fig:good_v_bad_CMOS  --></a> shows the impact of process corners on VTC of the
     inverter. A good PMOS and a bad NMOS combination moves the VTC right because of the higher \(V_{th}\) of the
     NMOS and vice-versa for the complementary case.
     </li>
<li class='enumerate' id='x1-88009x2'>
     <!-- l. 2356 --><p class='noindent'>In the transition region (where both N and PMOS are in saturation), we ideally want an infinite gain. As
     supply voltage decreases, we see that this gain actually increases in the transition region. However, as the
     supply falls below the threshold voltage of the devices, they start to deviate significantly from the VTC of
     an inverter behavior. At around \(V_{DD,min} \approx 2-4 \frac {kT}{q}\), the device no longer behaves like an ideal inverter. This behavior is
     summarized in figure <a href='#left-process-variations-and-impact-on-vtc-right-impact-of-vdd-scaling-on-inverter-vtc'>96<!-- tex4ht:ref: fig:good_v_bad_CMOS  --></a>. </p><figure class='figure' id='x1-8801096'><span id='left-process-variations-and-impact-on-vtc-right-impact-of-vdd-scaling-on-inverter-vtc'></span> 
 <img alt='PIC' height='125' src='images/good_v_bad_cmos.png' width='125' /><img alt='PIC' height='250' src='images/vdd_scaling_inverter.png' width='250' />
<figcaption class='caption'><span class='id'>Figure 96: </span><span class='content'>(Left) Process variations and impact on VTC (Right) Impact of \(V_{DD}\) scaling on inverter VTC</span></figcaption><!-- tex4ht:label?: x1-8801096  -->
     </figure>
     </li></ol>
   <h4 class='subsectionHead' id='stability'><span class='titlemark'>6.5   </span> <a id='x1-890006.5'></a>Stability</h4>
<!-- l. 2371 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='hold-stability'><span class='titlemark'>6.5.1   </span> <a id='x1-900006.5.1'></a>HOLD stability</h5>
<!-- l. 2372 --><p class='noindent'>When the access transistors are OFF (word line is low), the cross-coupled inverters hold the state in the memory cell.
However, noise can disturb the cell and switch the state. The maximum noise allowed at the input of the cross-coupled pair
before it switches states is called static noise margin.
</p>
   <figure class='figure' id='x1-9000197'><span id='left-hold-stability-right-read-stability'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2377 --><p class='noindent'><img alt='PIC' height='150' src='images/hold_stability.png' width='150' /><img alt='PIC' height='150' src='images/read_stability.png' width='150' /><img alt='PIC' height='150' src='images/write_stability.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 97: </span><span class='content'>(Left) Hold stability (Right) READ stability</span></figcaption><!-- tex4ht:label?: x1-9000197  -->
                                                                                               
                                                                                               
   </figure>
   <h5 class='subsubsectionHead' id='read-stability'><span class='titlemark'>6.5.2   </span> <a id='x1-910006.5.2'></a>READ stability</h5>
<!-- l. 2385 --><p class='noindent'>For a READ operation, since both the bitlines are precharged to \(V_{DD}\), the VTC curves are different from the regular inverter
VTC. Assume we’re analyzing only side at a time (i.e., don’t take that both BL and \(\bar {BL}\) are precharged and then you’re
sweeping V1, just take V1 without the access transistor and precharged BL). Then V2 starts off the same but goes only as
low as the resistor divider between the access and pull down transistors allows. Similarly, for the other curve. As seen in
figure <a href='#left-hold-stability-right-read-stability'>97<!-- tex4ht:ref: fig:hold_read_stability  --></a>, this decreases the size of the maximum square that can be drawn in the butterfly curve - the read noise margin is
lower than the static noise margin. In fact, the read noise margin depends on how low the resistor divider
between the access and pull down transistors lets you pull to GND. We can do the following to improve
this
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-91002x1'>Increase the size of the pull down transistor compared to the access transistor
     </li>
<li class='enumerate' id='x1-91004x2'>Increase \(V_{DD}\) of the cross-coupled inverter cell (not the WL voltage) or conversely, decrease the WL voltage
     </li>
<li class='enumerate' id='x1-91006x3'>Increasing \(V_t\) of the devices can also help since that pushes the turning on/off of the NMOS (or PMOS) to a
     higher voltage, moving the knee of the VTC to the right - increasing the size of the square that can be drawn.</li></ol>
<!-- l. 2397 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='write-stability'><span class='titlemark'>6.5.3   </span> <a id='x1-920006.5.3'></a>WRITE stability</h5>
<!-- l. 2399 --><p class='noindent'>For the WRITE margin, we do a similar simulation as the read stability, except one of the bitlines is pulling to GND. Let’s
say the the side of V2 is still pulling to a logic 1, then the VTC curve of V2 when V1 is swept is the same as before.
However, now when we sweep V2 and try to measure V1, the access transistor is trying to pull that node to GND while the
pull up transistor is trying to pull up to \(V_{DD}\). The resistor divider between the pull up and the access transistor sets this voltage
somewhere between GND and \(V_{DD}\). Ideally, we would want the access transistor to pull this node to GND as soon as possible -
even V2 is close to 0 if possible! As V2 increases, it shuts down the pull up PMOS and pulling down is easier since both the
access transistor and the pull down transistor are trying to send V1 to zero. The smallest square - unlike in
READ/HOLD where it was the largest square - defines the write static margin as shown in figure <a href='#left-hold-stability-right-read-stability'>97<!-- tex4ht:ref: fig:hold_read_stability  --></a>. This is just so
that we have a pessimistic estimate of the write margin w.r.t to noise. WRITE margin can be improved
by
</p><!-- l. 2406 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-92002x1'>Increasing the size of the access transistor, or decreasing the size of the pull up transistor
                                                                                               
                                                                                               
     </li>
<li class='enumerate' id='x1-92004x2'>Increasing word line voltage (to make the access transistor stronger)</li></ol>
<!-- l. 2433 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='read-assists'><span class='titlemark'>6.6   </span> <a id='x1-930006.6'></a>READ assists</h4>
<!-- l. 2435 --><p class='noindent'>Here are some techniques that help with READ operation
</p><!-- l. 2437 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-93002x1'>Pulsed wordline as opposed to the word line being always ON helps read stability without flipping the bits
     </li>
<li class='enumerate' id='x1-93004x2'>Decreasing bitline voltage (or pulsed bitline) compared to the \(V_{DD}\) of the cell to reduce the read current through
     the cell and helping read stability
     </li>
<li class='enumerate' id='x1-93006x3'>Lowering wordline voltage to weaken the access transistor
     </li>
<li class='enumerate' id='x1-93008x4'>Raising cell \(V_{DD}\) or decreasing the \(V_{SS}\) of the SRAM cell to make the cross-coupled pair stronger</li></ol>
<!-- l. 2446 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='write-assists'><span class='titlemark'>6.7   </span> <a id='x1-940006.7'></a>WRITE assists</h4>
<!-- l. 2449 --><p class='noindent'>Here are some techniques that help with WRITE operation
</p><!-- l. 2451 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-94002x1'>Driving bitline to negative voltage
     </li>
<li class='enumerate' id='x1-94004x2'>Raising the wordline to make it stronger
                                                                                               
                                                                                               
     </li>
<li class='enumerate' id='x1-94006x3'>Floating the cell \(V_{DD}\) or GND during write operations - decreases the switching threshold
     </li>
<li class='enumerate' id='x1-94008x4'>Lowering the cell \(V_{DD}\) during write to decrease the switching threshold of the inverters</li></ol>
<!-- l. 2459 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='how-do-we-implement-these-assist-ckts'><span class='titlemark'>6.8   </span> <a id='x1-950006.8'></a>How do we implement these assist ckts?</h4>
<!-- l. 2463 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='negative-rail-generation'><span class='titlemark'>6.8.1   </span> <a id='x1-960006.8.1'></a>Negative rail generation</h5>
<!-- l. 2464 --><p class='noindent'>We follow the analysis in [<a id='x1-96001'></a><a href='#cite.0_kester_switched_capacitor_2006'>9</a>] to create a negative supply voltage using switched cap ckts. Figure <a href='#left-switched-cap-inverter-right-basics-of-charge-distribution'>98<!-- tex4ht:ref: fig:switch_cap_inverter  --></a> shows the basics of
charge redistribution which arises from charge conservation. In a simple voltage inverter, a clk phase charges C1 to \(V_{IN}\). In the
next phase, C1 is connected to C1 but in reverse polarity.
</p>
   <figure class='figure' id='x1-9600298'><span id='left-switched-cap-inverter-right-basics-of-charge-distribution'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2470 --><p class='noindent'><img alt='PIC' height='200' src='images/switch_cap_inverter.png' width='200' /><img alt='PIC' height='200' src='images/charge_redistribution.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 98: </span><span class='content'>(Left) Switched cap inverter (Right) Basics of charge distribution.</span></figcaption><!-- tex4ht:label?: x1-9600298  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2475 --><p class='indent'>   Say the capacitor C2 is intially discharged, we can apply the charge conservation eqn as follows
</p><!-- l. 2477 --><p class='indent'>   \[ C_1(-V_{IN}) + 0 = (C_1 + C_2)V_{OUT} \] \[V_{OUT} = -V_{IN}\frac {C_1}{C_1+C_2}\]
</p><!-- l. 2480 --><p class='indent'>   The negative sign on the LHS comes from the fact that initially the GND reference was on the bottom plate, but during
the second phase, the refernce is switched to the top plate, which makes \(V_1 = -V_{IN}\) in figure <a href='#left-switched-cap-inverter-right-basics-of-charge-distribution'>98<!-- tex4ht:ref: fig:switch_cap_inverter  --></a>. After n such cycles we have the
following output voltage
</p><!-- l. 2486 --><p class='indent'>   \begin {equation}  \label {eqn:switch_cap_inv1} V_{OUT} = -V_{IN} \bigg ( \frac {C_1}{C_1+C_2} + \frac {C_1C_2}{(C_1+C_2)^2} + \cdots + \frac {C_1C_2^{n-1}}{(C_1+C_2)^n}\bigg )  \end {equation}<a id='x1-96003r37'></a>
</p><!-- l. 2488 --><p class='indent'>   In eqn <a href='#x1-96003r37'>37<!-- tex4ht:ref: eqn:switch_cap_inv1  --></a>, if we tend the number of cycles to infinite, we get \(V_{OUT} \approx -V_{IN}\).
</p>
   <h5 class='subsubsectionHead' id='higher-than-vdd-rail-generation'><span class='titlemark'>6.8.2   </span> <a id='x1-970006.8.2'></a>Higher than \(V_{DD}\) rail generation</h5>
<!-- l. 2492 --><p class='noindent'>We can implement a voltage doubler using the ckt in figure <a href='#voltage-doubler'>99<!-- tex4ht:ref: fig:switch_cap_doubler  --></a>. The first phase of the clk is similar to the one before whre
C1 is charged to \(V_{IN}\). In the second phase, the capacitor C1 is now in series with C2. At steady state, this acts as a second
battery with a voltage drop \(V_{IN}\) across it and therefore, \(V_{OUT} = 2V_{IN}\).
</p>
   <figure class='figure' id='x1-9700199'><span id='voltage-doubler'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2498 --><p class='noindent'><img alt='PIC' height='200' src='images/voltage_doubler.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 99: </span><span class='content'>Voltage doubler</span></figcaption><!-- tex4ht:label?: x1-9700199  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2503 --><p class='indent'>   We can stack up n such capacitors to make a voltage multiplier [<a id='x1-97002'></a><a href='#cite.0_generic_step_up_down_converter_2024'>4</a>]. We can also switch the input and output to make a
voltage halver/divider. </p><figure class='figure' id='x1-97003100'><span id='voltage-multiplier-vout-nvin'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2506 --><p class='noindent'><img alt='PIC' height='200' src='images/voltage_multiplier.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 100: </span><span class='content'>Voltage multiplier \(V_{OUT} = nV_{IN}\)</span></figcaption><!-- tex4ht:label?: x1-97003100  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2511 --><p class='indent'>   These kind of switched cap ckts need a closed loop feedback to control the clk phases and duty cycles to regulate voltage
at the output.
</p>
   <h5 class='subsubsectionHead' id='level-converter'><span class='titlemark'>6.8.3   </span> <a id='x1-980006.8.3'></a>Level Converter</h5>
<!-- l. 2518 --><p class='noindent'>Say we have two power domains \(V_{DDL}\) and \(V_{DDH}\). When an inverter from the lower supply is connected to the higher supply, the
second inverter is never fully OFF (especially the PMOS) as the driving lower \(V_{DD}\) inverter cannot reach the same logic high
that is needed for \(V_{DDH}\). This is illustrated on the left in figure <a href='#left-problem-with-a-lower-vddl-inverter-driving-a-higher-vddh-one-right-level-converter-ckt'>101<!-- tex4ht:ref: fig:level_converter_issue  --></a>.
</p>
   <figure class='figure' id='x1-98001101'><span id='left-problem-with-a-lower-vddl-inverter-driving-a-higher-vddh-one-right-level-converter-ckt'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2523 --><p class='noindent'><img alt='PIC' height='200' src='images/level_conversion_issue.png' width='200' /><img alt='PIC' height='200' src='images/level_converter.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 101: </span><span class='content'>(Left) Problem with a lower \(V_{DDL}\) inverter driving a higher \(V_{DDH}\) one (Right) Level converter ckt</span></figcaption><!-- tex4ht:label?: x1-98001101  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2528 --><p class='indent'>   We need a level converter that can take the input from the first inverted and drive the second inverter. The ckt on the
right in figure <a href='#left-problem-with-a-lower-vddl-inverter-driving-a-higher-vddh-one-right-level-converter-ckt'>101<!-- tex4ht:ref: fig:level_converter_issue  --></a> does this. Say IN = 0, then the NMOS on the right is off and the NMOS on the left is weakly turned on,
it pulls the gate of the PMOS on the right low, turning it on. The drain node of this PMOS goes high (\(V_{DDH}\)), turning off the
PMOS on the left. The output inverter is now driven to \(V_{DDH}\) at its input and OUT = 0. Say IN = 1, then the NMOS on the left
is off and the NMOS on the right starts pulling its drain to GND. This turns on the PMOS on the left and it pulls its drain
to \(V_{DDH}\), effectively shutting off the PMOS on the right. The input to the output inverter is GND and OUT is \(V_{DDH}\). In
both cases, we made use of the fact that the NMOS can pull to GND effectively (a bit weakly compared to
\(V_{DDH}\)).
</p><!-- l. 2534 --><p class='indent'>   Note that in the other case when an inverter in \(V_{DDH}\) supply drives an inverter in \(V_{DDL}\) domain, the latter inverter can switch
faster than when driven in its own domain. This speed up <span class='cmti-10'>may </span>cause hold time violations and need to be considered when
doing timing calculations. Level converters cost delay and power. [<a id='x1-98002'></a><a href='#cite.0_Saberi2025LevelShifterAnalysis'>12</a>] does an analysis for the delay and power consumption
of a level shifter as shown in figure <a href='#left-problem-with-a-lower-vddl-inverter-driving-a-higher-vddh-one-right-level-converter-ckt'>101<!-- tex4ht:ref: fig:level_converter_issue  --></a>. When there is a transition from \(V_{DDL}\) to 0 at the input, the corresponding node \(Q_2\) sees
contention from N2 pulling the node down vs P2 pull the node up. N2 turns on in saturation while P2 in triode. N2 stays in
saturation till \(V_{DS}\) across it drops below its overdrive and then enters triode. On the other hand, P2 was in triode and
therefore, it reachers a peak current as \(V_{SD}\) increases across it, and then drops because \(Q_1\) (\(V_{SG}\)) is discharging. The
maximum current from P2 is delivered when \(V_{SD} = 1/3\times V^*\), it’s overdrive voltage. We define the contention factor at node \(Q_2\)
as
</p><!-- l. 2546 --><p class='indent'>   \begin {equation}  \label {eqn:level_converter_contention} k = \frac {I_{P2,max}}{I_{N2,sat}} = \frac {1}{3} \frac {\beta _P}{\beta _N} \bigg (\frac {V_{DDH}-|V_{th,P}|}{V_{DDL}-V_{th,N}}\bigg )  \end {equation}<a id='x1-98003r38'></a>
</p>
   <figure class='figure' id='x1-98004102'><span id='level-converter-delay-and-power-analysis-in-saberilevelshifteranalysis'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2552 --><p class='noindent'><img alt='PIC' height='350' src='images/level_converter2.png' width='350' />
</p>
<figcaption class='caption'><span class='id'>Figure 102: </span><span class='content'>Level converter delay and power analysis in [<a id='x1-98005'></a><a href='#cite.0_Saberi2025LevelShifterAnalysis'>12</a>]</span></figcaption><!-- tex4ht:label?: x1-98004102  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2557 --><p class='indent'>   Note that as the difference between \(V_{DDH}\) and \(V_{DDL}\) increases, so does the contention factor in eqn <a href='#x1-98003r38'>38<!-- tex4ht:ref: eqn:level_converter_contention  --></a>. If we assume \(k\) is usually
smaller than 1 (in a well-designed converter) and that \(V_{th,p}/V_{DDH}\) is also not greater than 0.25, then we can simplify the delay and
power consumed as follows
</p><!-- l. 2563 --><p class='indent'>   \begin {equation}  \label {eqn:level_converter_delay} t_d \approx \frac {C_L}{\beta _P(V_{DDH}-V_{th,P})} \times \ln \big (\frac {1}{1-k}\big )  \end {equation}<a id='x1-98006r39'></a>
</p><!-- l. 2568 --><p class='indent'>   \begin {equation}  \label {eqn:level_converter_powery} P \approx 2fC_L \times \bigg (1 + \ln \frac {1}{1-k} +\frac {V_{th,p}}{V_{DDH}} \bigg )  \end {equation}<a id='x1-98007r40'></a>
</p><!-- l. 2570 --><p class='indent'>   As expected, increasing contention increases delay and power consumption - especially from short circuit current
(term with \(k\) in it). When contention is close to zero, the power consumed is simply \(2fC_LV_{DDH}^2\) and the delay is almost
zero.
</p>
   <h5 class='subsubsectionHead' id='pulse-width-modulation'><span class='titlemark'>6.8.4   </span> <a id='x1-990006.8.4'></a>Pulse width modulation</h5>
<!-- l. 2577 --><p class='noindent'>How to give dead time in ckts?
</p><!-- l. 2580 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='pvt-corners'><span class='titlemark'>6.9   </span> <a id='x1-1000006.9'></a>PVT corners</h4>
<!-- l. 2582 --><p class='noindent'>How do process corners affect SRAM READ/WRITE operations and stability?
</p><!-- l. 2584 --><p class='indent'>   How does temperature affect them?
</p><!-- l. 2586 --><p class='indent'>   How does changing supply voltage affect them?
</p><!-- l. 2588 --><p class='indent'>   How does clk frequency (if at all) affects them?
</p><!-- l. 2595 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='row-circuitry'><span class='titlemark'>6.10   </span> <a id='x1-1010006.10'></a>Row circuitry</h4>
<!-- l. 2597 --><p class='noindent'>Row circuitry has word line drivers and row decoders. Address is decoded in the decoders and then the corresponding
wordline is driven. Let us take a simple case for a row decoder. We have 4 rows, meaning we have 2-bit row address. A
simpled decoder made of inverters and NAND gates is shown in figure <a href='#a-simple-row-decoder-implementation'>103<!-- tex4ht:ref: fig:row_decoder  --></a>.
</p>
   <figure class='figure' id='x1-101001103'><span id='a-simple-row-decoder-implementation'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2605 --><p class='noindent'><img alt='PIC' height='150' src='images/row_decoder.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 103: </span><span class='content'>A simple row decoder implementation</span></figcaption><!-- tex4ht:label?: x1-101001103  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2611 --><p class='indent'>   For larger addresses, the decoder becomes slower due to large fanout of the inverters. We can break the decoding into
more stages and add a predecoding stage. For an n-bit address, from the above implementation, we’d need an N-input
NAND gate where several NAND gates share utmost 3 inputs - say between two NAND4 gates, the first three
inputs are A0, A1, A2, but the last input could be A3 and its complement split between the pair of them.
This is a waste of area - we can reduce this redundancy by adding a predecoding stage which converts the
addresses into blocks of 1-hot encoded codes that drives the smaller fan-in NAND gates. This idea is shown
in figure <a href='#top-regular-to-decoder-bottom-predecoder-of-blocks-of-tohot-decoder-followed-by-nand-gates'>104<!-- tex4ht:ref: fig:row_predecoder  --></a>. Predecoding doesn’t save much path effort but saves area due to implementation of smaller
gates.
</p>
   <figure class='figure' id='x1-101002104'><span id='top-regular-to-decoder-bottom-predecoder-of-blocks-of-tohot-decoder-followed-by-nand-gates'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2619 --><p class='noindent'><img alt='PIC' height='150' src='images/predecoder.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 104: </span><span class='content'>(Top) Regular 4-to-16 decoder. (Bottom) Predecoder of 2 blocks of 1-to-4-hot decoder followed by 4
NAND2 gates</span></figcaption><!-- tex4ht:label?: x1-101002104  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2624 --><p class='indent'>   Placing a buffer between the decoder and word lines saves a large amount of dynamic power at a small cost of delay [<a id='x1-101003'></a><a href='#cite.0_weste_cmos_2011'>15</a>].
The critical path for a READ operation involves the decoder driving the wordline and the SRAM cell that pulls the bitline
(or its complement) to create the small signal differential voltage. Figure <a href='#critical-path-during-read'>105<!-- tex4ht:ref: fig:read_crit_path  --></a> shows a \(2^n\)- word, \(2^m\)-bit memory with a total
storage of \(2^{n+m}\) bits. Let us calculate the delay from the address line to the bitline. Assuming the unit inverter has a PMOS to
NMOS ratio of 2:1 and the decoder is an n-input NAND gate, the logical effort from the address to wordline is
(n+2)/3. Let us assume that the access transistor and the pull-down transistor are unit sized. They are in
series when pulling down the bitline, therefore, the logical effort is 2. If we assume the wire capacitance per
cell on the bitline is another unit sized transistor, the decoder NAND gate sees this wire and two gates -
a total of 3C for each cell. This represents a fanout of 3/\(C_{in}\) for the address to wordline path, where \(C_{in}\) is the
input capacitance of the n-input NAND gate (which depends on sizing). Note that for an individual stage’s
fanout, we consider the on-path capacitance and then include the off-path efforts in the branching effort
term.
</p>
   <figure class='figure' id='x1-101004105'><span id='critical-path-during-read'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2636 --><p class='noindent'><img alt='PIC' height='150' src='images/read_sram_crit_path.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 105: </span><span class='content'>Critical path during READ</span></figcaption><!-- tex4ht:label?: x1-101004105  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2641 --><p class='indent'>   But the branching effort is calculated just from the capacitance of driving one cell among all the other
cells - \(2^m\). The parasitic capacitance is just the n-input NAND gate’s capacitance and is equal to n [<a id='x1-101005'></a><a href='#cite.0_weste_cmos_2011'>15</a>]. The
total bitline capacitance is \(2^n C\) (1C from diffusion of access transistor and 1C from the wire/cell) while the
drive of the pull down network formed by the access and pull-down transistors is 2R. Therefore, the total
parastic delay is \(2^{n+1}RC/3RC = 2^{n+1}/3\). Assume that the load seen at the output of the bitline is \(C_L\), fanout for this stage is \(C_L/2\). Total
delay is given by Finally, the branching effort of the SRAM cell is \(2^n\) since the other cells do not drive the
bitline.
</p><!-- l. 2654 --><p class='indent'>   \begin {equation}  \label {eqn:le_sram} \begin {split} F_1 &amp;= LE_1FO_1B_1 = \frac {n+2}{3}\frac {3}{C_{in}}2^m = 2^m \frac {n+2}{C_{in}} \\ F_2 &amp;= LE_2FO_2B_2 = 2\frac {C_L}{2}2^n = 2^nC_L\\ P &amp;=P_1 + P_2 = n + \frac {2^{n+1}}{3} \\ D &amp;= F_1F_2 + P = 2^{m+n}\frac {n+2}{3}\frac {C_L}{C_{in}} + n + \frac {2^{n+1}}{3} \end {split}  \end {equation}<a id='x1-101006r41'></a>
</p><!-- l. 2656 --><p class='indent'>   From eqn <a href='#x1-101006r41'>41<!-- tex4ht:ref: eqn:le_sram  --></a>, we see that the total delay depends on the total size of the SRAM, \(2^{m+n}\), and the number of words
\(n\).
</p>
   <h4 class='subsectionHead' id='column-circuitry'><span class='titlemark'>6.11   </span> <a id='x1-1020006.11'></a>Column circuitry</h4>
<!-- l. 2661 --><p class='noindent'>The column circuitry consists of the bitline conditioning circuitry, the write driver, the bit line sensing circuitry, and the
column multiplexers. A memory array is organized by \(m\) words \(\times \) \(n\) bits. A lot of parasitics and long wire delays can make the
FO4 delay of a column driver unacceptably large.
</p><!-- l. 2665 --><p class='indent'>   For bitline conditioning (precharging), we can use a simple PMOS switch to pull both the lines up to \(V_{DD}\). Column
multiplexers are similar to row decoders.
</p><!-- l. 2669 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='sense-amplifier'><span class='titlemark'>6.11.1   </span> <a id='x1-1030006.11.1'></a>Sense Amplifier</h5>
<!-- l. 2672 --><p class='noindent'>In a READ operation, we want to read small voltage swings between the bitlines withouth flipping the cell. We use a sense
amplifier to achieve this. While the sense amplifier is doing its job, we can turn off the word line to prevent any further
distrubance in the cell and improve read stability. There are several ways to implement a sense amplifier
and each one performs better in one area vs the other - like dynamic power dissipation, speed, sensitivity,
etc.
</p><!-- l. 2678 --><p class='indent'>   One particular class of sense amplifiers uses differential flip-flops. In figure <a href='#right-senseamplifier-flipflop-left-similar-design-but-replaces-the-srlatch-follower-stage-to-make-it-faster'>106<!-- tex4ht:ref: fig:saf_ff  --></a>, on the right, we see a sense-amplifer
flip-flop which takes a differential input and returns a rail-to-rail differential output. When clk is low, the
nodes \(X\) and \(\bar {X}\) are precharged. When the clk rises, one of the two nodes is pulled down by the input pair. The
cross-coupled PMOS at the top acts as a keeper on the other node to hold its value (while it lets the other node
disconnect from \(V_{DD})\). The output of the differential amplifier is latched by the follower SR-latch to drive Q and its
complement. The equalizing transistor between the two branches makes sure that when the CLK is high, any
changes in D and its complement are equalized. The delay through the cross-coupled SR latch can be a
bottleneck.
</p>
   <figure class='figure' id='x1-103001106'><span id='right-senseamplifier-flipflop-left-similar-design-but-replaces-the-srlatch-follower-stage-to-make-it-faster'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2685 --><p class='noindent'><img alt='PIC' height='250' src='images/saf_ff.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 106: </span><span class='content'>(Right) Sense-amplifier flip-flop. (Left) Similar design but replaces the SR-latch follower stage to make
it faster</span></figcaption><!-- tex4ht:label?: x1-103001106  -->
                                                                                               
                                                                                               
   </figure>
                                                                                               
                                                                                               
   <h3 class='sectionHead' id='power-energy-and-delay'><span class='titlemark'>7   </span> <a id='x1-1040007'></a>Power, Energy, and Delay</h3>
<!-- l. 2698 --><p class='noindent'>The power dissipation of a CMOS circuit is instead dominated by the dynamic dissipation resulting from charging and
discharging capacitances [<a id='x1-104001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>].
</p><!-- l. 2700 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='charging-and-discharging-a-capacitor'><span class='titlemark'>7.1   </span> <a id='x1-1050007.1'></a>Charging and discharging a capacitor</h4>
<!-- l. 2702 --><p class='noindent'>Let’s take the example of a capacitor charging by a PMOS from 0 to \(V_{DD}\) as shown in figure <a href='#capacitor-charging'>107<!-- tex4ht:ref: fig:cap_charging  --></a>.
</p>
   <figure class='figure' id='x1-105001107'><span id='capacitor-charging'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2706 --><p class='noindent'><img alt='PIC' height='175' src='images/cap_charging.png' width='175' />
</p>
<figcaption class='caption'><span class='id'>Figure 107: </span><span class='content'>Capacitor charging</span></figcaption><!-- tex4ht:label?: x1-105001107  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2714 --><p class='indent'>   \begin {equation}  \label {eqn:cap_charge} E_{charge} = \int _{0}^{\infty } i_{DS}(t)V_{DD} dt = V_{DD} \int _{0}^{\infty } C_L \frac {dv_{out}}{dt} dt = V_{DD} C_L \int _{0}^{V_{DD}} dv_{out} = C_LV^2_{DD}  \end {equation}<a id='x1-105002r42'></a>
</p><!-- l. 2716 --><p class='indent'>   Since charging happens with a constant voltage across the capacitor, we can pull out \(V_{DD}\) in eqn <a href='#x1-105002r42'>42<!-- tex4ht:ref: eqn:cap_charge  --></a>. It takes \(C_L V^2_{DD}\) energy to
charge a capacitor. Let’s look at discharging the cap from \(V_{DD}\) to 0 V.
</p><!-- l. 2723 --><p class='indent'>   \begin {equation}  \label {eqn:cap_discharge} E_{stored} = \int _{0}^{\infty } i_{DS}(t)v_{out} dt = C_L \int _{0}^{V_{DD}} v_{out}dv_{out} = C_LV^2_{DD}/2  \end {equation}<a id='x1-105003r43'></a>
</p><!-- l. 2725 --><p class='indent'>   From eqn <a href='#x1-105003r43'>43<!-- tex4ht:ref: eqn:cap_discharge  --></a>, we see that the total energy stored on the cap is just \(C_LV^2_{DD}/2\) - half of what it took to charge it to the same
voltage. This shows the energy of \(C_LV^2_{DD}/2\) was disippated by the PMOS when charging the capacitor - and this is true
irrespective of the size/resistance of the PMOS [<a id='x1-105004'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. We therefore conclude that for each switching cycle (low to
high plus high to low), a total energy of \(C_LV^2_{DD}\) is used from the power supply. The dynamic power consumption is
therefore
</p>
   <div class='eqnarray'>\begin {eqnarray}  \label {eqn:pow_dyn1} P_{dyn} = C_LV^2_{DD}f  \end {eqnarray}</div>
<!-- l. 2735 --><p class='indent'>   where \(f\) is the clk frequency. We see that increasing clk frequency linearly increases power consumption.
</p>
   <h5 class='subsubsectionHead' id='activity-factor'><span class='titlemark'>7.1.1   </span> <a id='x1-1060007.1.1'></a>Activity factor</h5>
<!-- l. 2739 --><p class='noindent'>Activity factor of a logic gate can be estimated by calculating the switching probability at its output, given some known
probability of inputs switching. Glitches can increase the activity factor of a gate.
</p><!-- l. 2742 --><p class='indent'>   If \(P_i\) is the probability that node \(i\) is 1, then \(\bar {P_i} = 1-P_i\) is the probability of the node being at 0. Since the activity factor is the
probability of a transiation from 0 to 1 (one cycle it’s 0 <span class='cmbx-10'>and </span>the next cycle it’s 1, hence the multiplication of the
probabilities), we can write
</p><!-- l. 2745 --><p class='indent'>   \[\alpha _i = P_i \bar {P_i}\]
</p><!-- l. 2747 --><p class='indent'>   Let us work out a couple of examples assuming each input node has a switching probability of 0.5 in figure
<a href='#activity-factor1'>108<!-- tex4ht:ref: fig:activity_factor  --></a>.
</p>
   <figure class='figure' id='x1-106001108'><span id='activity-factor1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2751 --><p class='noindent'><img alt='PIC' height='350' src='images/activity_factor_ex.png' width='350' />
</p>
<figcaption class='caption'><span class='id'>Figure 108: </span><span class='content'>Activity factor</span></figcaption><!-- tex4ht:label?: x1-106001108  -->
                                                                                               
                                                                                               
   </figure>
   <figure class='figure' id='x1-106002109'><span id='solutions-to-the-example'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2758 --><p class='noindent'><img alt='PIC' height='250' src='images/activity_factor_ex1.png' width='250' /><img alt='PIC' height='250' src='images/activity_factor_ex2.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 109: </span><span class='content'>Solutions to the example</span></figcaption><!-- tex4ht:label?: x1-106002109  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2763 --><p class='indent'>   As seen in figure <a href='#solutions-to-the-example'>109<!-- tex4ht:ref: fig:activity_factor_sol  --></a>, the key idea is to find the probability that each output node is at 1 in one cycle and 0
in the next, and since these are uncorrelated, the probability of switching is just the product of these two
probabilities.
</p>
   <h5 class='subsubsectionHead' id='example-transistor-sizing-for-minimum-energy'><span class='titlemark'>7.1.2   </span> <a id='x1-1070007.1.2'></a>Example - transistor sizing for minimum energy</h5>
<!-- l. 2773 --><p class='noindent'>Let us work through an example for sizing that minimizes energy. In figure <a href='#example-system-to-optimize-for-energy-consumption'>110<!-- tex4ht:ref: fig:energy_min_xtor_sizing_ex  --></a>, the total delay can be given
by
</p><!-- l. 2778 --><p class='indent'>   \begin {equation}  \label {eqn:inv_chain_delay_emin} t_p = t_{p0}\bigg ( \bigg ( 1+ \frac {f}{\gamma } \bigg ) + \bigg ( 1 + \frac {F}{f\gamma }\bigg ) \bigg )  \end {equation}<a id='x1-107001r44'></a>
</p><!-- l. 2780 --><p class='indent'>   where \(F = C_{ext}/C_{g1}\), the overall effective fanout of the ckt, \(t_{p0}\) is the intrinsic delay of min sized inverter.
</p>
   <figure class='figure' id='x1-107002110'><span id='example-system-to-optimize-for-energy-consumption'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2784 --><p class='noindent'><img alt='PIC' height='175' src='images/min_energy_xtor_sizing.png' width='175' />
</p>
<figcaption class='caption'><span class='id'>Figure 110: </span><span class='content'>Example system to optimize for energy consumption</span></figcaption><!-- tex4ht:label?: x1-107002110  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2790 --><p class='indent'>   The total energy consumption can be given by
</p><!-- l. 2796 --><p class='indent'>   \begin {equation}  \label {eqn:inv_chain_emin} E = V^2_{DD} C_{g1}((1+\gamma )(1+f)+F)  \end {equation}<a id='x1-107003r45'></a>
</p><!-- l. 2798 --><p class='indent'>   From eqns <a href='#x1-107001r44'>44<!-- tex4ht:ref: eqn:inv_chain_delay_emin  --></a> and <a href='#x1-107003r45'>45<!-- tex4ht:ref: eqn:inv_chain_emin  --></a>, and the fact that the intrinsic delay \(t_{p0}\) is proportional to
</p><!-- l. 2803 --><p class='indent'>   \begin {equation}  \label {eqn:tp_vdd} t_{p0} \propto \frac {V_{DD}}{V_{DD}-V^*}  \end {equation}<a id='x1-107004r46'></a>
</p><!-- l. 2805 --><p class='indent'>   where \(V^* = V_{T}-V_{DSsat}/2\), we can derive a relationship between \(V_{DD}\) and the fanout for the first inverter \(f\) given a minimum bound for
performance. Say we want the delay across the two inverters in figure <a href='#example-system-to-optimize-for-energy-consumption'>110<!-- tex4ht:ref: fig:energy_min_xtor_sizing_ex  --></a> to be no larger than delay with \(f=1\) at \(V_{DD} = V_{ref}\), then we have
(for \(\gamma = 1\))
</p><!-- l. 2811 --><p class='indent'>   \begin {equation}  \label {eqn:emin_delay_min} \frac {t_p}{t_{pref}} = \frac {t_{p0}\bigg (2+f+\frac {F}{f}\bigg )}{t_{p0ref} (3+F)} = \bigg (\frac {V_{DD}}{V_{ref}}\bigg ) \bigg (\frac {V_{ref}-V^*}{V_{DD}-V^*}\bigg ) \Bigg (\frac {2+f+\frac {F}{f}}{3+F}\Bigg ) = 1  \end {equation}<a id='x1-107005r47'></a>
</p><!-- l. 2816 --><p class='indent'>   \begin {equation}  \label {eqn:emin_min} \frac {E}{E_{pref}} = \bigg (\frac {V_{DD}}{V_{ref}}\bigg )^2 \bigg (\frac {2+2f+F}{4+F}\bigg )  \end {equation}<a id='x1-107006r48'></a>
</p><!-- l. 2818 --><p class='indent'>   From figure <a href='#left-vdd-vs-f-for-different-values-of-f-right-normalized-energy-consumption-vs-f-for-different-f'>111<!-- tex4ht:ref: fig:min_xtor_sizing_ex  --></a>, we see that for different values of effective Fanout \(F\), increasing the size of the inverter initially decreases
the energy consumed. This happens till \(f = \sqrt {F}\) (two-stage optimal fanout per stage as seen in fig <a href='#example-of-inverter-chain-sizing-using-optimal-fanout'>16<!-- tex4ht:ref: fig:opt_fanout_ex  --></a>) and increasing the size of the
second inverter deteriorates delay, which then needs to be compensated by increasing \(V_{DD}\), which in turn increases the energy
consumption.
</p>
   <figure class='figure' id='x1-107007111'><span id='left-vdd-vs-f-for-different-values-of-f-right-normalized-energy-consumption-vs-f-for-different-f'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2824 --><p class='noindent'><img alt='PIC' height='350' src='images/emin_sizing_plots.png' width='350' />
</p>
<figcaption class='caption'><span class='id'>Figure 111: </span><span class='content'>(Left) \(V_{DD}\) vs \(f\) for different values of \(F\). (Right) Normalized energy consumption vs \(f\) for different \(F\).</span></figcaption><!-- tex4ht:label?: x1-107007111  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2829 --><p class='indent'>   We note the following points [<a id='x1-107008'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-107010x1'>Device sizing and supply voltage reduction are effective ways to reduce energy consumption, especially for
     larger effective fanout networks.
     </li>
<li class='enumerate' id='x1-107012x2'>Oversizing the transistors beyond the optimal value comes at a hefty penalty in terms of energy (and delay
     too).
     </li>
<li class='enumerate' id='x1-107014x3'>For larger \(F\), if we let optimize for the delay as well the energy (as opposed to constraining the ratio to 1 in
     eqn <a href='#x1-107005r47'>47<!-- tex4ht:ref: eqn:emin_delay_min  --></a>), we see that \(f_{opt}\) is smaller for energy minimization than \(f_{opt}\) for delay minimization.</li></ol>
   <h5 class='subsubsectionHead' id='clk-gating'><span class='titlemark'>7.1.3   </span> <a id='x1-1080007.1.3'></a>Clk gating</h5>
<!-- l. 2840 --><p class='noindent'>Since CLK network has high activity factor and fanout, switching it off to blocks that are not being used saves a lot of
power. We can use a clk enable signal to AND the clk signal - this is called CLk gating. The clk enable signal must be
robust and not prone to glitches.
</p>
   <figure class='figure' id='x1-108001112'><span id='clk-gating-examples'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2845 --><p class='noindent'><img alt='PIC' height='150' src='images/clk_gating2.png' width='150' /><img alt='PIC' height='200' src='images/clk_gating.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 112: </span><span class='content'>Clk gating examples</span></figcaption><!-- tex4ht:label?: x1-108001112  -->
                                                                                               
                                                                                               
   </figure>
   <h5 class='subsubsectionHead' id='state-retention-registers'><span class='titlemark'>7.1.4   </span> <a id='x1-1090007.1.4'></a>State retention registers</h5>
<!-- l. 2852 --><p class='noindent'>Before turning off the system, we’d like to store its state. Figure <a href='#state-retention-ckt'>113<!-- tex4ht:ref: fig:balloon_ckt  --></a> shows a balloon ckt that uses a sample and hold ckt
made of cross-coupled inverters. These inverters are made with min-sized, high-Vt or thick-oxide xtors to minimize
lkg.
</p>
   <figure class='figure' id='x1-109001113'><span id='state-retention-ckt'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2858 --><p class='noindent'><img alt='PIC' height='150' src='images/balloon_ckt.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 113: </span><span class='content'>State retention ckt</span></figcaption><!-- tex4ht:label?: x1-109001113  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='short-ckt-power-dissipation'><span class='titlemark'>7.2   </span> <a id='x1-1100007.2'></a>Short ckt power dissipation</h4>
<!-- l. 2866 --><p class='noindent'>Since the rise and fall timnes are finite, there exits a window (of length \(t_{sc}\)) during the inverter operation where both the
NMOS and PMOS devices are on - leading to a short ckt from \(V_{DD}\) to GND. If the peak short ckt current is \(I_{peak}\), we can
approximate the average power consumption as
</p><!-- l. 2872 --><p class='indent'>   \begin {equation}  \label {eqn:short_ckt_power} P_{sc} = t_{sc}V_{DD}I_{peak}f  \end {equation}<a id='x1-110001r49'></a>
</p><!-- l. 2874 --><p class='indent'>   where \(f\) is the clk frequency. The value of \(t_{sc}\) depends on the threshold voltages of the devices along with the slopes of the
input waveforms. \(I_{peak}\) is a strong function of the input and <span class='cmti-10'>output </span>slopes. If the load cap at the output is too small, the output
changes fast causing the \(V_{DS}\) across one of the devices to be equal to \(V_{DD}\) during the short time when both devices are on. This
increases \(I_{peak}\) but \(t_{sc}\) is small for the same input slope.
</p><!-- l. 2878 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='static-consumption'><span class='titlemark'>7.3   </span> <a id='x1-1110007.3'></a>Static consumption</h4>
<!-- l. 2880 --><p class='noindent'>Static consumption refers to the leakage current when the inverter is off. Increasing temperature increases leakage, hence,
static dissipation.
</p><!-- l. 2882 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='energydelay-product'><span class='titlemark'>7.4   </span> <a id='x1-1120007.4'></a>Energy-Delay product</h4>
<!-- l. 2884 --><p class='noindent'>We can first try minimizing energy (or power-delay product) by itself. Minimizing power is not interesting by iteself since it
comes with huge delay penalties and consequently, increased losses through leakage (leakage energy is increased due to
longer delays).
</p>
   <figure class='figure' id='x1-112001114'><span id='minimizing-energy'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2889 --><p class='noindent'><img alt='PIC' height='200' src='images/energy_min_plots.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 114: </span><span class='content'>Minimizing energy</span></figcaption><!-- tex4ht:label?: x1-112001114  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2894 --><p class='indent'>   In figure <a href='#minimizing-energy'>114<!-- tex4ht:ref: fig:energy_min  --></a> we see that for higher speeds, we need to increase the supply (to increase the drive current) but also have
to decrease \(V_{th}\). This is especially true for the left plot because switching energy dominates while on the right plot,
where the activity factor is low, the leakage power dominates. In this case, the threshold voltage needs to be
increased to reduce the leakge losses. Increasing temperature also increases leakage so we need a higher threshold
voltage.
</p><!-- l. 2900 --><p class='indent'>   One of the performance metrics that capatures the trade-off between performance and energy consumption is the
energy-delay product
</p><!-- l. 2905 --><p class='indent'>   \begin {equation}  \label {eqn:edp} \mathrm {EDP} = \frac {C_L V^2_{DD}}{2}t_p  \end {equation}<a id='x1-112002r50'></a>
</p><!-- l. 2907 --><p class='indent'>   If we assume the same behavior for \(t_p\) as eqn <a href='#x1-107004r46'>46<!-- tex4ht:ref: eqn:tp_vdd  --></a>, we can derive a relationship for EDP with the supply
voltage
</p><!-- l. 2912 --><p class='indent'>   \begin {equation}  \label {eqn:edp_vdd} \mathrm {EDP} \propto \frac {C_L V^3_{DD}}{2(V_{DD}-V^*)}  \end {equation}<a id='x1-112003r51'></a>
</p><!-- l. 2914 --><p class='indent'>   Setting the derivative to 0 in eqn <a href='#x1-112003r51'>51<!-- tex4ht:ref: eqn:edp_vdd  --></a>, we see that the optimal \(V_{DD,opt} = 1.5 V^*\) wherw \(V^* = V_{th} + V_{DSAT}/2\).
</p>
   <figure class='figure' id='x1-112004115'><span id='optimal-vdd-for-minimizing-energydelay-product'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2918 --><p class='noindent'><img alt='PIC' height='175' src='images/edp_opt_vdd.png' width='175' />
</p>
<figcaption class='caption'><span class='id'>Figure 115: </span><span class='content'>Optimal \(V_{DD}\) for minimizing energy-delay product</span></figcaption><!-- tex4ht:label?: x1-112004115  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2923 --><p class='indent'>   Note that in eqn <a href='#x1-112003r51'>51<!-- tex4ht:ref: eqn:edp_vdd  --></a>, we considered leakage to be negligible. Hence, the eqn suggest decreasing \(V_{th}\) improves EDP. This is
not true, however.
</p>
   <h5 class='subsubsectionHead' id='gate-sizing-under-a-delay-constraint'><span class='titlemark'>7.4.1   </span> <a id='x1-1130007.4.1'></a>Gate sizing under a delay constraint</h5>
<!-- l. 2931 --><p class='noindent'>We can tradeoff some delay to make considerable energy savings. Let us work through an example to understand how we
can do this given we know the activity factors at the inputs [<a id='x1-113001'></a><a href='#cite.0_weste_cmos_2011'>15</a>].
</p><!-- l. 2937 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='interconnects'><span class='titlemark'>7.5   </span> <a id='x1-1140007.5'></a>Interconnects</h4>
<!-- l. 2939 --><p class='noindent'>Figure <a href='#different-interconnect-models'>116<!-- tex4ht:ref: fig:interconnect_models  --></a> shows the 3 most common models used to model long wires. [<a href='#cite.0_weste_cmos_2011'>15</a>] states that the L-model is a poor choice
because a large number of segments are required for accurate results (why?). The \(\pi \)-model gives better results and so
does the T-model but its the latter is harder to solve by hand. Any inductance is modeled in series to the
resistance.
</p>
   <figure class='figure' id='x1-114001116'><span id='different-interconnect-models'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2945 --><p class='noindent'><img alt='PIC' height='175' src='images/interconnect_models.png' width='175' />
</p>
<figcaption class='caption'><span class='id'>Figure 116: </span><span class='content'>Different interconnect models</span></figcaption><!-- tex4ht:label?: x1-114001116  -->
                                                                                               
                                                                                               
   </figure>
   <h5 class='subsubsectionHead' id='skin-effect'><span class='titlemark'>7.5.1   </span> <a id='x1-1150007.5.1'></a>Skin effect</h5>
<!-- l. 2951 --><p class='noindent'>At high frequencies, currents tend to flow primarily on the surface of the conductor with current density falling
exponentially with depth into the conductor [<a id='x1-115001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. A very hand-wavy explanation states that this is due to the magnetic
fields generated within the conductor cause eddy currents, which peak at the center of the conductor, and then cancel out
the original AC (can read up more later). The skin depth, \(\delta \), is defined as the depth where the current falls off to \(1/e\) of its
nominal value
</p><!-- l. 2958 --><p class='indent'>   \begin {equation}  \label {eqn:skin_depth} \delta = \sqrt {\frac {\rho }{\pi f \mu }}  \end {equation}<a id='x1-115002r52'></a>
</p><!-- l. 2960 --><p class='indent'>   where \(\mu \) is the permeability of the surrounding dielectric (not the conductor). Note that skin effect is more predominant
in wider wires (like the clk signal)
</p><!-- l. 2963 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='distributed-rc-line'><span class='titlemark'>7.5.2   </span> <a id='x1-1160007.5.2'></a>Distributed RC line</h5>
<!-- l. 2965 --><p class='noindent'>Instead of the lumped RC model, we can model the interconnect more accurately by discretizing the resistance and
capacitance of the wire into infinitesimal chunks as shown in figure <a href='#distributed-interconnect-model'>117<!-- tex4ht:ref: fig:distributed_model  --></a>.
</p>
   <figure class='figure' id='x1-116001117'><span id='distributed-interconnect-model'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 2970 --><p class='noindent'><img alt='PIC' height='200' src='images/distributed_model.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 117: </span><span class='content'>Distributed interconnect model</span></figcaption><!-- tex4ht:label?: x1-116001117  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 2975 --><p class='indent'>   We can model the voltage any node \(i\), when \(\Delta L \rightarrow 0\), as
</p><!-- l. 2980 --><p class='indent'>   \begin {equation}  \label {eqn:distributed_model_rc} rc \frac {\partial V}{ \partial t} = \frac {\partial ^2 V}{\partial t^2}  \end {equation}<a id='x1-116002r53'></a>
</p><!-- l. 2982 --><p class='indent'>   Luckily, we do not need to know the solution of the diffusion eqn above in eqn <a href='#x1-116002r53'>53<!-- tex4ht:ref: eqn:distributed_model_rc  --></a>. We can model the effective resistance
and capacitance by tweaking the lumped model as shown in table <a href='#x1-116002r7.5.2'>7.5.2<!-- tex4ht:ref: tab:distributed_vs_lumped  --></a>.
</p>
   <div class='table'>
                                                                                               
                                                                                               
<!-- l. 2987 --><p class='indent' id='step-response-of-lumped-vs-distributed-rc-network'>   <a id='x1-1160034'></a></p><figure class='float'>
                                                                                               
                                                                                               
<figcaption class='caption'><span class='id'>Table 4: </span><span class='content'>Step response of lumped vs distributed RC network</span></figcaption><!-- tex4ht:label?: x1-1160034  -->
<div class='tabular'> <table class='tabular' id='TBL-5'><colgroup id='TBL-5-1g'><col id='TBL-5-1' /></colgroup><colgroup id='TBL-5-2g'><col id='TBL-5-2' /></colgroup><colgroup id='TBL-5-3g'><col id='TBL-5-3' /></colgroup><tr class='hline'><td></td><td></td><td></td></tr><tr id='TBL-5-1-' style='vertical-align:baseline;'><td class='td11' id='TBL-5-1-1' style='white-space:nowrap; text-align:center;'><span class='cmbx-10'>Voltage range</span></td><td class='td11' id='TBL-5-1-2' style='white-space:nowrap; text-align:center;'><span class='cmbx-10'>Lumped</span> \(RC\) <span class='cmbx-10'>network</span></td><td class='td11' id='TBL-5-1-3' style='white-space:nowrap; text-align:center;'><span class='cmbx-10'>Distributed</span> \(RC\) <span class='cmbx-10'>network</span></td>
</tr><tr class='hline'><td></td><td></td><td></td></tr><tr id='TBL-5-2-' style='vertical-align:baseline;'><td class='td11' id='TBL-5-2-1' style='white-space:nowrap; text-align:center;'>       \(0 \rightarrow 50\%~(t_p)\)       </td><td class='td11' id='TBL-5-2-2' style='white-space:nowrap; text-align:center;'>         \(0.69\,RC\)         </td><td class='td11' id='TBL-5-2-3' style='white-space:nowrap; text-align:center;'>          \(0.38\,RC\)          </td></tr><tr class='hline'><td></td><td></td><td></td></tr><tr id='TBL-5-3-' style='vertical-align:baseline;'><td class='td11' id='TBL-5-3-1' style='white-space:nowrap; text-align:center;'>  \(0 \rightarrow 63\%~(\tau )\) </td><td class='td11' id='TBL-5-3-2' style='white-space:nowrap; text-align:center;'>  \(RC\) </td><td class='td11' id='TBL-5-3-3' style='white-space:nowrap; text-align:center;'>  \(0.5\,RC\)</td>
</tr><tr class='hline'><td></td><td></td><td></td></tr><tr id='TBL-5-4-' style='vertical-align:baseline;'><td class='td11' id='TBL-5-4-1' style='white-space:nowrap; text-align:center;'>       \(10\% \rightarrow 90\%~(t_r)\)       </td><td class='td11' id='TBL-5-4-2' style='white-space:nowrap; text-align:center;'>         \(2.2\,RC\)         </td><td class='td11' id='TBL-5-4-3' style='white-space:nowrap; text-align:center;'>          \(0.9\,RC\)          </td>
</tr><tr class='hline'><td></td><td></td><td></td></tr><tr id='TBL-5-5-' style='vertical-align:baseline;'><td class='td11' id='TBL-5-5-1' style='white-space:nowrap; text-align:center;'>       \(0\% \rightarrow 90\%\)       </td><td class='td11' id='TBL-5-5-2' style='white-space:nowrap; text-align:center;'>         \(2.3\,RC\)         </td><td class='td11' id='TBL-5-5-3' style='white-space:nowrap; text-align:center;'>          \(1.0\,RC\)          </td>
</tr><tr class='hline'><td></td><td></td><td></td></tr></table>                                                                               </div>
                                                                                               
                                                                                               
   </figure>
   </div>
<!-- l. 3003 --><p class='indent'>   In general, we need a more accurate model for interconnects only when they dominate the gate delays or the rise/fall
times of the input.
</p>
   <h4 class='subsectionHead' id='elmore-delay'><span class='titlemark'>7.6   </span> <a id='x1-1170007.6'></a>Elmore Delay</h4>
<!-- l. 3007 --><p class='noindent'>We illustrate Elmore delay through examples. In figure <a href='#example-of-elmore-delay-using-a-secondorder-rc-ckt'>118<!-- tex4ht:ref: fig:elmore_ex1  --></a>, the delay can be estimated as follows
</p><!-- l. 3009 --><p class='indent'>
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-117002x1'>Consider the cap \(C_1\). It sees an effective resistance of \(R_1\). The delay is, therefore, estimated as \(R_1C_1\) (ignore a factor of
     \(\ln 2\)).
     </li>
<li class='enumerate' id='x1-117004x2'>Now, disregard \(C_1\) and only look at \(C_2\). The effective resistance to charge this capacitor is \(R_1 + R_2\). So the delay is computed
     as, \((R_1+R_2)C_2\).
     </li>
<li class='enumerate' id='x1-117006x3'>The total delay from the source to \(V_{out}\) is, therefore, \(R_1C_1 + (R_1+R_2)C_2\).</li></ol>
   <figure class='figure' id='x1-117007118'><span id='example-of-elmore-delay-using-a-secondorder-rc-ckt'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 3017 --><p class='noindent'><img alt='PIC' height='175' src='images/elmore_delay_ex1.png' width='175' />
</p>
<figcaption class='caption'><span class='id'>Figure 118: </span><span class='content'>Example of Elmore delay using a second-order RC ckt</span></figcaption><!-- tex4ht:label?: x1-117007118  -->
                                                                                               
                                                                                               
   </figure>
   <h5 class='subsubsectionHead' id='branched-ckts'><span class='titlemark'>7.6.1   </span> <a id='x1-1180007.6.1'></a>Branched ckts</h5>
<!-- l. 3024 --><p class='noindent'>Let’s work through another example [<a id='x1-118001'></a><a href='#cite.0_mercier2020elmore'>10</a>]. In figure <a href='#example-of-elmore-delay-in-a-branched-ckt'>119<!-- tex4ht:ref: fig:elmore_ex2  --></a>, there are two paths - one of which is the path of interest from
source to \(V_{out}\). Assume all caps were initially charged to \(V_{DD}\).
</p>
   <figure class='figure' id='x1-118002119'><span id='example-of-elmore-delay-in-a-branched-ckt'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 3029 --><p class='noindent'><img alt='PIC' height='200' src='images/elmore_delay_ex2.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 119: </span><span class='content'>Example of Elmore delay in a branched ckt</span></figcaption><!-- tex4ht:label?: x1-118002119  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 3034 --><p class='indent'>   In the video, Prof. Patrick Mercier, calculates the Elmore delay in the following manner
     </p><ol class='enumerate1'>
<li class='enumerate' id='x1-118004x1'>Node 3 delay - \(C(R_{13}+R_{12}+R_{11})\), node 2 delay \(C(R_{12}+R_{11})\), node 1 \(CR_{11}\)
     </li>
<li class='enumerate' id='x1-118006x2'>Node 4 does contribute to drop at \(V_{out}\) - because it discharges through \(R_2\) and \(R_{11}\). However, he argues that in the
     Elmore delay model we only consider the “shared=path”, and therefore, the delay related to \(V_{out}\) is \(CR_{11}\). \(R_2\) affects the
     discharge of node 4 but the current through \(R_{11}\) is what affects the discharge at the output node 3.
     </li>
<li class='enumerate' id='x1-118008x3'>The total Elmore delay is \(C(R_{13}+R_{12}+R_{11}) + C(R_{12}+R_{11}) + CR_{11} + CR_{11}\).
     </li>
<li class='enumerate' id='x1-118010x4'>Similarly, the delay to node 4 is \(C(R_{11}+R_2) + (C+C+C)R_{11}\). The resistances \(R_{12}\) and \(R_{13}\) are not in the shared path, and hence, are not
     considered in delay calculations.</li></ol>
<!-- l. 3044 --><p class='indent'>   Note that this is just a model for calculating the delay. Example 6.5 illustrates this in [<a id='x1-118011'></a><a href='#cite.0_weste_cmos_2011'>15</a>].
</p>
   <h4 class='subsectionHead' id='transmission-line'><span class='titlemark'>7.7   </span> <a id='x1-1190007.7'></a>Transmission line</h4>
<!-- l. 3048 --><p class='noindent'>Similar to the distributed RC model, for high-frequency applications, we can use the lossy transmission line model as shown
in figure <a href='#lossy-transmission-line'>120<!-- tex4ht:ref: fig:lossy_xmission_line  --></a>. In this model, the signal travels as a wave along the transmission line, as opposed to diffusing in the
distributed RC model.
</p>
   <figure class='figure' id='x1-119001120'><span id='lossy-transmission-line'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 3055 --><p class='noindent'><img alt='PIC' height='250' src='images/lossy_xmission_line.png' width='250' />
</p>
<figcaption class='caption'><span class='id'>Figure 120: </span><span class='content'>Lossy transmission line</span></figcaption><!-- tex4ht:label?: x1-119001120  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 3060 --><p class='indent'>   Let us start off with the ideal case where the resistance of the line and the leakage conductance are zero. This is called a
lossless transmission line [<a id='x1-119002'></a><a href='#cite.0_rabaey_digital_1996'>11</a>].
</p><!-- l. 3065 --><p class='indent'>   \begin {equation}  \label {eqn:lossless_xmission_line} \frac {\partial ^2 v}{\partial x^2} = lc \frac {\partial ^2 v}{\partial t^2} = \frac {1}{\nu ^2}\frac {\partial ^2 v}{\partial t^2}  \end {equation}<a id='x1-119003r54'></a>
</p><!-- l. 3067 --><p class='indent'>   A step input travel in a lossless transmission line at the speed \(\nu \) given by
</p><!-- l. 3072 --><p class='indent'>   \begin {equation}  \label {eqn:lossless_xmission_speed} \nu = \frac {1}{\sqrt {lc}} = \frac {c_0}{\epsilon _r \mu _r}  \end {equation}<a id='x1-119004r55'></a>
</p><!-- l. 3074 --><p class='indent'>   where \(\epsilon _r\) and \(\mu _r\) are the properties of the surrounding media (not the conductor). We can define a characteristic impedance \(Z_0\)
of the wire
</p><!-- l. 3079 --><p class='indent'>   \begin {equation}  \label {eqn:lossless_xmission_characteristic_impedance} Z_0 = \sqrt {\frac {l}{c}} = \frac {\sqrt {\epsilon _r\mu _r}}{c_0c}  \end {equation}<a id='x1-119005r56'></a>
</p><!-- l. 3081 --><p class='indent'>   From eqn <a href='#x1-119005r56'>56<!-- tex4ht:ref: eqn:lossless_xmission_characteristic_impedance  --></a>, we see that the characteristic impedance of a transmission line only depends on the geometry of
the conducting wire, and the properties of the dielectric medium surrounding it, but is independent of the
length of the wire and the frequency of the signal [<a href='#cite.0_rabaey_digital_1996'>11</a>]. What this means is that an arbitrary length wire,
has the same impedance across all frequencies for a lossless system. This makes the design of the driver ckt
simpler.
</p>
   <h5 class='subsubsectionHead' id='termination'><span class='titlemark'>7.7.1   </span> <a id='x1-1200007.7.1'></a>Termination</h5>
<!-- l. 3087 --><p class='noindent'>Since the signal now behaves like a wave, the boundary conditions affect the reflection at the edges of the wire. We define
reflection coefficient as
</p><!-- l. 3093 --><p class='indent'>   \begin {equation}  \label {eqn:reflection_coeff} \rho = \frac {V_{refl}}{V_{inc}} = \frac {R-Z_0}{R+Z_0}  \end {equation}<a id='x1-120001r57'></a>
</p><!-- l. 3095 --><p class='indent'>   where \(R\) is the value of the termination resistance and \(Z_0\) is the characteristic impedance [<a href='#cite.0_rabaey_digital_1996'>11</a>]. The total voltage and currnts
at the termination end are the sum of the incident and reflected waveforms
</p><!-- l. 3098 --><p class='indent'>   \[V = V_{inc}(1+\rho )\] \[I = I_{inc}(1-\rho )\]
</p>
   <figure class='figure' id='x1-120002121'><span id='different-kinds-of-termination'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 3103 --><p class='noindent'><img alt='PIC' height='200' src='images/reflection_types.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 121: </span><span class='content'>Different kinds of termination</span></figcaption><!-- tex4ht:label?: x1-120002121  -->
                                                                                               
                                                                                               
   </figure>
<!-- l. 3108 --><p class='indent'>   We examine three cases as shown in figure <a href='#different-kinds-of-termination'>121<!-- tex4ht:ref: fig:reflection_types  --></a>. When the termination resistance \(R = Z_0\), then the reflection coefficient drops to
zero. This means the waveform is no longer reflected. When we set \(R=0\) (short circuit to GND), we’re forcing the
termination to be a node, \(\rho = -1\) and the total voltage at the edge is zero. Similarly, if we set the termination
resistance to infinity (open ckt) then the curent is forced to be zero and the voltage is <span class='cmti-10'>twice </span>as the incident wave
(\(\rho = 1\)).
</p>
   <h5 class='subsubsectionHead' id='capacitive-termination'><span class='titlemark'>7.7.2   </span> <a id='x1-1210007.7.2'></a>Capacitive termination</h5>
<!-- l. 3114 --><p class='noindent'>Loads in CMOS ckts are mostly capacitive. We can then rewrite the reflection coefficient from eqn <a href='#x1-120001r57'>57<!-- tex4ht:ref: eqn:reflection_coeff  --></a> as
</p><!-- l. 3120 --><p class='indent'>   \begin {equation}  \label {eqn:reflection_coeff_cap} \rho = \frac {V_{refl}}{V_{inc}} = \frac {\frac {1}{sC}-Z_0}{\frac {1}{sC}+Z_0} = \frac {1-sCZ_0}{1+scZ0}  \end {equation}<a id='x1-121001r58'></a>
</p><!-- l. 3122 --><p class='indent'>   From eqn <a href='#x1-121001r58'>58<!-- tex4ht:ref: eqn:reflection_coeff_cap  --></a>, we see that the reflection coefficient, hence the current and voltage waveforms, have a zero and a pole at \(CZ_0\).
The inverse Laplace transform gives a \(-\delta (t)\) and hence, we see that the voltage at the source dips then rises back to meet the
voltage at the load as shown in figure <a href='#capacitive-termination1'>122<!-- tex4ht:ref: fig:capacitive_termination  --></a>. The destination reaches twice the input in this case since the real part of the
impedance is open ckt (capacitive load).
</p><!-- l. 3126 --><p class='indent'>   \[v(t) = -\delta (t) + \frac {2}{CZ_0} \exp (-t/CZ_0)u(t)\]
</p>
   <figure class='figure' id='x1-121002122'><span id='capacitive-termination1'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 3130 --><p class='noindent'><img alt='PIC' height='200' src='images/capacitive_termination.png' width='200' />
</p>
<figcaption class='caption'><span class='id'>Figure 122: </span><span class='content'>Capacitive termination</span></figcaption><!-- tex4ht:label?: x1-121002122  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='interconnect-engineering'><span class='titlemark'>7.8   </span> <a id='x1-1220007.8'></a>Interconnect engineering</h4>
<!-- l. 3137 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='wire-rebufferingrepeaters'><span class='titlemark'>7.8.1   </span> <a id='x1-1230007.8.1'></a>Wire rebuffering/Repeaters</h5>
<!-- l. 3138 --><p class='noindent'>The RC delay of a line is proportional to \(l^2\). The delay can be reduced by cutting the wire short and adding repeaters or
buffers. If there are N segments, the delay is reduced by 1/N. This, of course, comes with the cost of power and
area.
</p><!-- l. 3141 --><p class='noindent'>
</p>
   <h5 class='subsubsectionHead' id='regenerators'><span class='titlemark'>7.8.2   </span> <a id='x1-1240007.8.2'></a>Regenerators</h5>
<!-- l. 3143 --><p class='noindent'>Intsead of using repeaters, we can also use regenerators/boosters to improve the delay across long wires. A regenerator
detects a ‘0’or ‘1’ transition on the wire and accelerates it. Figure <a href='#regenerator'>123<!-- tex4ht:ref: fig:regenerator  --></a> shows an implementation. The NAND gate
labelled L has a switching threshold closer to GND so that when it detects a rising edge on the wire, it
quickly pulls the output to high, and similarly for the gate labelled H. We tradeoff delay with reduced noise
margins.
</p>
   <figure class='figure' id='x1-124001123'><span id='regenerator'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 3151 --><p class='noindent'><img alt='PIC' height='150' src='images/regenerator.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 123: </span><span class='content'>Regenerator</span></figcaption><!-- tex4ht:label?: x1-124001123  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='power-gating'><span class='titlemark'>7.9   </span> <a id='x1-1250007.9'></a>Power gating</h4>
<!-- l. 3159 --><p class='noindent'>The best way to save power in sleep mode is by turning off the supply to the logic block as shown in figure <a href='#power-gating-system'>124<!-- tex4ht:ref: fig:power_gating  --></a>. The header
switch should be large to prevent any resistive drops during active operation but shouldn’t introduce too much parasitc
delays. It should also have low leakage during sleep (higher Vt devices can also be used, for example). Usually, we use
several parallel switches by maximizing \(I_{on}/I_{off}\) for each device.
</p><!-- l. 3163 --><p class='indent'>   During the power down phase, to prevent the logical states taking any forbidden values (or even state change), we use
output isolators to set the correct output values for necessary for the downstream logic.
</p>
   <figure class='figure' id='x1-125001124'><span id='power-gating-system'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 3167 --><p class='noindent'><img alt='PIC' height='150' src='images/power_gating.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 124: </span><span class='content'>Power gating system</span></figcaption><!-- tex4ht:label?: x1-125001124  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='dvfs'><span class='titlemark'>7.10   </span> <a id='x1-1260007.10'></a>DVFS</h4>
<!-- l. 3175 --><p class='noindent'>DVFS stands for dynamic voltage and frequency scaling. The DVFS controller changes the supply voltage and clk frequency
depending on the workload and temperature of the die as shown in figure <a href='#dvfs-system'>125<!-- tex4ht:ref: fig:dvfs  --></a>. A switching regulator does the voltage
scaling and a PLL does the frequency scaling. This saves a lot of power when the system has lighter workloads.
Subthreshold lkg and gate lkg also decrease with decreased supply.
</p>
   <figure class='figure' id='x1-126001125'><span id='dvfs-system'></span> 

                                                                                               
                                                                                               

                                                                                               
                                                                                               
<!-- l. 3183 --><p class='noindent'><img alt='PIC' height='150' src='images/dvfs.png' width='150' />
</p>
<figcaption class='caption'><span class='id'>Figure 125: </span><span class='content'>DVFS system</span></figcaption><!-- tex4ht:label?: x1-126001125  -->
                                                                                               
                                                                                               
   </figure>
   <h4 class='subsectionHead' id='multivt-cells'><span class='titlemark'>7.11   </span> <a id='x1-1270007.11'></a>Multi-Vt cells</h4>
<!-- l. 3191 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='pvt-corners1'><span class='titlemark'>7.12   </span> <a id='x1-1280007.12'></a>PVT corners</h4>
<!-- l. 3193 --><p class='noindent'>Speed is roughly proportional to the supply voltage, so decreasing the supply decreases speed [<a id='x1-128001'></a><a href='#cite.0_rabaey_digital_1996'>11</a>]. We’ve seen in table <a href='#temperature-dependence-of-key-mosfet-parameters'>1<!-- tex4ht:ref: tab:temp_dependence  --></a>
that increasing temperature decreases drive current while increasing leakage. For devices, most important variations are
channel length and threshold voltage changes. For interconnects, metal line dimensions and dielectric spacing affects their
impedance, and hence, delay and losses.
                                                                                               
                                                                                               
</p><!-- l. 3203 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='verilog-basics'><span class='titlemark'>8   </span> <a id='x1-1290008'></a>Verilog Basics</h3>
<!-- l. 3205 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='blocking-vs-nonblocking-assignments'><span class='titlemark'>8.1   </span> <a id='x1-1300008.1'></a>Blocking vs Non-blocking assignments</h4>
<!-- l. 3207 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='always-blocks'><span class='titlemark'>8.2   </span> <a id='x1-1310008.2'></a>always  blocks</h4>
                                                                                               
                                                                                               
<!-- l. 3212 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='adders-and-multipliers'><span class='titlemark'>9   </span> <a id='x1-1320009'></a>Adders and Multipliers</h3>
<!-- l. 3214 --><p class='noindent'>We’ll only consider
                                                                                               
                                                                                               
</p><!-- l. 3221 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='dynamic-logic'><span class='titlemark'>10   </span> <a id='x1-13300010'></a>Dynamic Logic</h3>
<!-- l. 3225 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='domino-logic'><span class='titlemark'>10.1   </span> <a id='x1-13400010.1'></a>Domino logic</h4>
<!-- l. 3227 --><p class='noindent'>
</p>
   <h4 class='subsectionHead' id='keeper-circuit'><span class='titlemark'>10.2   </span> <a id='x1-13500010.2'></a>Keeper circuit</h4>
<!-- l. 3230 --><p class='noindent'>
</p>
   <h3 class='sectionHead' id='references'><a id='x1-136000'></a>References</h3>
<!-- l. 3230 --><p class='noindent'>
     </p><dl class='thebibliography'><dt class='thebibliography' id='X0-abraham_dynamic_cmos_logic_2020'>
 [1]  </dt><dd class='thebibliography' id='bib-1'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_abraham_dynamic_cmos_logic_2020'></a>Jacob        Abraham.        <span class='cmti-10'>Dynamic       CMOS       Logic</span>.        Tech.        rep.        Lecture        notes,
     available at <a class='url' href='https://www.cerc.utexas.edu/~jaa/vlsi/lectures/12-1.pdf'><span class='cmtt-10'>https://www.cerc.utexas.edu/~jaa/vlsi/lectures/12-1.pdf</span></a>. Department of Electrical and
     Computer Engineering, The University of Texas at Austin, Oct. 2020.
     </p></dd><dt class='thebibliography' id='X0-ece559_sequential_logic_2009'>
 [2]  </dt><dd class='thebibliography' id='bib-2'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_ece559_sequential_logic_2009'></a>Jacob        Abraham.        <span class='cmti-10'>Sequential       Logic</span>.        Tech.        rep.        Lecture        notes,        available
     at   <a class='url' href='https://engineering.purdue.edu/~vlsi/ECE559_Fall09/Notes/SequentialLogic.pdf'><span class='cmtt-10'>https://engineering.purdue.edu/~vlsi/ECE559_Fall09/Notes/SequentialLogic.pdf</span></a>.   School   of
     Electrical and Computer Engineering, Purdue University, Oct. 2009.
     </p></dd><dt class='thebibliography' id='X0-technicalbytes_setup_hold_latch_2020'>
 [3]  </dt><dd class='thebibliography' id='bib-3'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_technicalbytes_setup_hold_latch_2020'></a>Technical  Bytes.  <span class='cmti-10'>Setup  and  Hold  Time  of  a  Latch</span>.  <a class='url' href='https://www.youtube.com/watch?v=vr-C4eajc1w'><span class='cmtt-10'>https://www.youtube.com/watch?v=vr-C4eajc1w</span></a>.
     YouTube video, published March 14, 2020. Accessed: August 16, 2025. Mar. 2020.
     </p></dd><dt class='thebibliography' id='X0-generic_step_up_down_converter_2024'>
 [4]  </dt><dd class='thebibliography' id='bib-4'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_generic_step_up_down_converter_2024'></a>PE             Channel.             <span class='cmti-10'>PE           #22:           Generic           Step-Up/Down           Switched
     Capacitor Converter</span>. <a class='url' href='https://www.youtube.com/watch?v=eKKePDowF4c'><span class='cmtt-10'>https://www.youtube.com/watch?v=eKKePDowF4c</span></a>. YouTube video. Accessed: August
     22, 2025. Apr. 2024.
     </p></dd><dt class='thebibliography' id='X0-computer_electronics_cmos_schmitt_2024'>
 [5]  </dt><dd class='thebibliography' id='bib-5'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_computer_electronics_cmos_schmitt_2024'></a>Computer&amp;Electronics.           <span class='cmti-10'>CMOS         Schmitt         trigger         and         its         application</span>.
     <a class='url' href='https://www.youtube.com/watch?v=0WSm7NBRnao'><span class='cmtt-10'>https://www.youtube.com/watch?v=0WSm7NBRnao</span></a>. YouTube video, published February 15, 2024. Accessed:
     August 22, 2025. Feb. 2024.
                                                                                               
                                                                                               
     </p></dd><dt class='thebibliography' id='X0-iitmadras_asynchronous_seq_circuits_2024'>
 [6]  </dt><dd class='thebibliography' id='bib-6'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_iitmadras_asynchronous_seq_circuits_2024'></a>IIT         Madras         -         BS         in         Electronic         Systems.         <span class='cmti-10'>W12_L8_Asynchronous
     sequential circuits</span>. <a class='url' href='https://www.youtube.com/watch?v=4yupVArzdOk'><span class='cmtt-10'>https://www.youtube.com/watch?v=4yupVArzdOk</span></a>. YouTube video, published April 12,
     2024. Accessed: August 14, 2025. Apr. 2024.
     </p></dd><dt class='thebibliography' id='X0-horowitz_logical_effort_revisited_1998'>
 [7]  </dt><dd class='thebibliography' id='bib-7'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_horowitz_logical_effort_revisited_1998'></a>Mark                        Horowitz.                        <span class='cmti-10'>Logical                     Effort                     Revisited</span>.
     Tech. rep. Available at <a class='url' href='https://ctho.org/toread/forclass/18-722/logicaleffort/LERevisited.pdf'><span class='cmtt-10'>https://ctho.org/toread/forclass/18-722/logicaleffort/LERevisited.pdf</span></a>.
     Stanford University, EE371 Course Handout, 1998.
     </p></dd><dt class='thebibliography' id='X0-jacob_sequential_logic_2008'>
 [8]  </dt><dd class='thebibliography' id='bib-8'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_jacob_sequential_logic_2008'></a>Bruce Jacob. <span class='cmti-10'>Sequential Logic: Lecture/s 12-15, ENEE 359a Digital VLSI Design</span>. Tech. rep. Lecture notes,
     available at <a class='url' href='http://classweb.ece.umd.edu/enee359a.S2008/enee359a-sequential.pdf'><span class='cmtt-10'>http://classweb.ece.umd.edu/enee359a.S2008/enee359a-sequential.pdf</span></a>. Department of
     Electrical and Computer Engineering, University of Maryland, 2008.
     </p></dd><dt class='thebibliography' id='X0-kester_switched_capacitor_2006'>
 [9]  </dt><dd class='thebibliography' id='bib-9'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_kester_switched_capacitor_2006'></a>Walt Kester, Brian Erisman, and Gurjit Thandi. “Switched Capacitor Voltage Converters”. In: <span class='cmti-10'>Practical
     Design Techniques for Power and Thermal Management</span>. Section 4. Analog Devices, Inc., 2006, pp. 4.1–4.23.
     <span class='cmcsc-10'><span class='small-caps'>url</span></span>: <a class='url' href='https://www.analog.com/media/en/training-seminars/design-handbooks/Practical-Design-Techniques-Power-Thermal/Section4.pdf'><span class='cmtt-10'>https://www.analog.com/media/en/training-seminars/design-handbooks/Practical-Design-Techniques-Power-Thermal/Section4.pdf</span></a>.
     </p></dd><dt class='thebibliography' id='X0-mercier2020elmore'>
[10]  </dt><dd class='thebibliography' id='bib-10'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_mercier2020elmore'></a>Patrick                                                          Mercier.                                                          <span class='cmti-10'>ECE
     165 - Lecture 5: Elmore Delay Analysis</span>. <a class='url' href='https://www.youtube.com/watch?v=DXGXNqL4QyU'><span class='cmtt-10'>https://www.youtube.com/watch?v=DXGXNqL4QyU</span></a>. UC San Diego
     Digital Integrated Circuit Design, Lecture 5. 2020.
     </p></dd><dt class='thebibliography' id='X0-rabaey_digital_1996'>
[11]  </dt><dd class='thebibliography' id='bib-11'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_rabaey_digital_1996'></a>Jan M. Rabaey. <span class='cmti-10'>Digital Integrated Circuits: A Design Perspective</span>. Available at <a class='url' href='https://booksonweb.wordpress.com/wp-content/uploads/2011/11/digital-integrated-circuits-a-design-perspective-by-jan-m-rabaey.pdf'><span class='cmtt-10'>https://booksonweb.wordpress.com/wp-content/uploads/2011/11/digital-integrated-circuits-a-design-perspective-by-jan-m-rabaey.pdf</span></a>.
     Englewood Cliffs, NJ: Prentice Hall, 1996. <span class='cmcsc-10'><span class='small-caps'>isbn</span></span>: 0131786091.
     </p></dd><dt class='thebibliography' id='X0-Saberi2025LevelShifterAnalysis'>
[12]  </dt><dd class='thebibliography' id='bib-12'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_Saberi2025LevelShifterAnalysis'></a>Mehdi Saberi, Alexandre Schmid, et al. “Analysis of Power Consumption and Propagation Delay in Voltage
     Level Shifters”. In: <span class='cmti-10'>IEEE Journal / Brief (exact venue from IEEE Xplore) </span>(2025). Standard 0.18-<span class='tcrm-1000'>µ</span>m CMOS
     implementation; verify journal, volume, number, pages, and full author list from IEEE Xplore.
     </p></dd><dt class='thebibliography' id='X0-10.1145_63526.63532'>
[13]  </dt><dd class='thebibliography' id='bib-13'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_10.1145_63526.63532'></a>I. E. Sutherland. “Micropipelines”. In: <span class='cmti-10'>Commun. ACM </span>32.6 (June 1989), pp. 720–738. <span class='cmcsc-10'><span class='small-caps'>issn</span></span>: 0001-0782. <span class='cmcsc-10'><span class='small-caps'>doi</span></span>:
     <a href='https://doi.org/10.1145/63526.63532'>10.1145/63526.63532</a>. <span class='cmcsc-10'><span class='small-caps'>url</span></span>: <a class='url' href='https://doi.org/10.1145/63526.63532'><span class='cmtt-10'>https://doi.org/10.1145/63526.63532</span></a>.
     </p></dd><dt class='thebibliography' id='X0-sutherland_logical_effort_ch1'>
[14]  </dt><dd class='thebibliography' id='bib-14'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_sutherland_logical_effort_ch1'></a>Ivan Sutherland, Bob Sproull, and David Harris. “The Method of Logical Effort”. In: <span class='cmti-10'>Logical Effort: Designing
     Fast  CMOS  Circuits</span>.  Available  at  <a class='url' href='https://my.eng.utah.edu/~cs6710/handouts/Sutherland_Ch1.pdf'><span class='cmtt-10'>https://my.eng.utah.edu/~cs6710/handouts/Sutherland_Ch1.pdf</span></a>.
     Morgan Kaufmann, 1999. Chap. 1.
     </p></dd><dt class='thebibliography' id='X0-weste_cmos_2011'>
[15]  </dt><dd class='thebibliography' id='bib-15'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_weste_cmos_2011'></a>Neil H. E. Weste and David Money Harris. <span class='cmti-10'>CMOS VLSI Design: A Circuits and Systems Perspective</span>. 4th.
     Boston: Addison-Wesley, 2011. <span class='cmcsc-10'><span class='small-caps'>isbn</span></span>: 978-0-13-608055-4.
     </p></dd><dt class='thebibliography' id='X0-grokipedia_celement'>
[16]  </dt><dd class='thebibliography' id='bib-16'>
     <!-- l. 3230 --><p class='noindent'><a id='cite.0_grokipedia_celement'></a>xAI. <span class='cmti-10'>C-element</span>. Accessed: 2025-12-24. 2025. <span class='cmcsc-10'><span class='small-caps'>url</span></span>: <a class='url' href='https://grokipedia.com/page/C-element#c-element'><span class='cmtt-10'>https://grokipedia.com/page/C-element#c-element</span></a>.</p></dd></dl>
    
</body> 
</html>